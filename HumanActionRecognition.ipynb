{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "HumanActionRecognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJ8SitTVFVe7"
      },
      "source": [
        "## Recogninsing human actions using 3D CNN\n",
        "\n",
        "Recognizing human actions is one of most popular computer vision method which finds mutiple applications in lots of fields such as video surveillance, customer attributes, shopping behavior analysis.\n",
        "\n",
        "In our final project, we consider the automated recognition of human actions in some videos. We proposed to build up a 3D CNN model for action recognition. In order to capture motion information from multiple adjacent frames, we proposed to extract features from both spatial and temporal dimensions. Based on this feature extractor, a 3D convolutional neural network will be built up. This CNN will generates multiple channels of information and performs convolution and subsampling separately. The final feature representation is obtained by conbining information from all channels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dCtMz1AuW0d"
      },
      "source": [
        "## Implementation details\n",
        "---\n",
        "Completed tasks\n",
        "1. Implemented for the UFC dataset \n",
        "2. Implemented regularisation using SIFT and MEHI features\n",
        "3. Used a Hardwired layer that extracts features from frames\n",
        "4. Implemented 5 CNN models with similar structure but different kernel size\n",
        "5. Tried ensembles of this 4, different combinations and compared the results\n",
        "6. Used swift activation function for better results\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_psFP7pi_cLE"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeSU5Ha99-zY",
        "outputId": "2722fcf2-a4d8-44d7-f3ba-92180323d1a6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZD-jrQpZz0jb",
        "outputId": "fee7ad79-a4d1-4272-edff-5ffeaa6d43a8"
      },
      "source": [
        "!pip install opencv-python==3.4.2.16\n",
        "!pip install opencv-contrib-python==3.4.2.16\n",
        "# #Installing these libraries is important since, the newer versions have removed these libraries"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting opencv-python==3.4.2.16\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/7d/5042b668a8ed41d2a80b8c172f5efcd572e3c046c75ae029407e19b7fc68/opencv_python-3.4.2.16-cp36-cp36m-manylinux1_x86_64.whl (25.0MB)\n",
            "\u001b[K     |████████████████████████████████| 25.0MB 122kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python==3.4.2.16) (1.18.5)\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: opencv-python\n",
            "  Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "Successfully installed opencv-python-3.4.2.16\n",
            "Collecting opencv-contrib-python==3.4.2.16\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/f1/66330f4042c4fb3b2d77a159db8e8916d9cdecc29bc8c1f56bc7f8a9bec9/opencv_contrib_python-3.4.2.16-cp36-cp36m-manylinux1_x86_64.whl (30.6MB)\n",
            "\u001b[K     |████████████████████████████████| 30.6MB 76kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-contrib-python==3.4.2.16) (1.18.5)\n",
            "Installing collected packages: opencv-contrib-python\n",
            "  Found existing installation: opencv-contrib-python 4.1.2.30\n",
            "    Uninstalling opencv-contrib-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-contrib-python-4.1.2.30\n",
            "Successfully installed opencv-contrib-python-3.4.2.16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4VYBINXFVe7",
        "outputId": "9cb028f0-99b8-483e-9557-703fb2f787ee"
      },
      "source": [
        "# Import standard and supportive libraries\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import model_selection\n",
        "from sklearn import preprocessing\n",
        "from tensorflow.python.client import device_lib\n",
        "from tensorflow import keras\n",
        "# from sklearn.cluster import KMeans\n",
        "from sklearn import preprocessing\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler \n",
        "from sklearn.decomposition import PCA\n",
        "import pickle\n",
        "\n",
        "def get_available_devices():\n",
        "    local_device_protos = device_lib.list_local_devices()\n",
        "    return [x.name for x in local_device_protos]\n",
        "\n",
        "print(\"Available devices for trainning:\", get_available_devices())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Available devices for trainning: ['/device:CPU:0', '/device:XLA_CPU:0', '/device:XLA_GPU:0', '/device:GPU:0']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HL5HaTjwFVe8",
        "outputId": "22a08469-668b-4d5f-d092-383208117405"
      },
      "source": [
        "#Try to use tensorflow in GPU\n",
        "config_tf = tf.compat.v1.ConfigProto(log_device_placement=True)\n",
        "config_tf.gpu_options.allow_growth = True\n",
        "session = tf.compat.v1.Session(config=config_tf)\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "# Import models and layers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers.core import Dense, Flatten, Activation, Flatten, Dropout\n",
        "from keras.layers.convolutional import Conv3D, MaxPooling3D\n",
        "\n",
        "# Import utilities\n",
        "from keras.optimizers import SGD,RMSprop\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.utils import np_utils, generic_utils\n",
        "from tensorflow.compat.v1.keras.backend import set_session\n",
        "from keras import backend as K\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "\n",
        "set_session(session)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UKndVPxhJd-"
      },
      "source": [
        "# LAYER 1, HARDWIRED LAYER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MYiw19QWNex"
      },
      "source": [
        "def H1_layer(file_id):\n",
        "\n",
        "  inflation = 1\n",
        "  # image attributes\n",
        "  #80, 60 is the Image dimensions and 9 is the number of frames\n",
        "  img_r, img_c, img_d = 80, 60, 9\n",
        "\n",
        "  capture = cv2.VideoCapture(file_id)\n",
        "  fps = capture.get(cv2.CAP_PROP_FPS)\n",
        "  # print(\"Frames per second using video.get(cv2.CAP_PROP_FPS): {0}\".format(fps))\n",
        "  for j in range(inflation):\n",
        "      frame_list = []\n",
        "      grey_list = []\n",
        "      horz_grad_list = []\n",
        "      vert_grad_list = []\n",
        "      horz_flow_list = []\n",
        "      vert_flow_list = []\n",
        "\n",
        "      flow_calc = False\n",
        "      prvs = None\n",
        "      for i in range(img_d):\n",
        "          # print(i)\n",
        "          success, frame = capture.read()\n",
        "          frame = cv2.resize(frame,(img_r,img_c),interpolation=cv2.INTER_AREA)\n",
        "          gray =  cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "          sobelx64f = cv2.Sobel(gray,cv2.CV_64F,1,0,ksize= -1)\n",
        "          abs_sobel64f = np.absolute(sobelx64f)\n",
        "          vert_grad = np.uint8(abs_sobel64f)\n",
        "\n",
        "          sobelx64f = cv2.Sobel(gray,cv2.CV_64F,0,1,ksize= -1)\n",
        "          abs_sobel64f = np.absolute(sobelx64f)\n",
        "          horz_grad = np.uint8(abs_sobel64f)\n",
        "\n",
        "          next = gray\n",
        "          if (flow_calc):\n",
        "            hsv = np.zeros_like(prvs)\n",
        "            hsv[...,1] = 255\n",
        "            # ret, frame2 = capture.read()\n",
        "            # next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
        "            flow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "\n",
        "            horz_flow = cv2.normalize(flow[...,0], None, 0, 255, cv2.NORM_MINMAX)     \n",
        "            vert_flow = cv2.normalize(flow[...,1], None, 0, 255, cv2.NORM_MINMAX)\n",
        "            horz_flow = horz_flow.astype('uint8')\n",
        "            vert_flow = vert_flow.astype('uint8')\n",
        "\n",
        "            horz_flow_list.append(horz_flow)\n",
        "            vert_flow_list.append(vert_flow)\n",
        "          \n",
        "          flow_calc = True\n",
        "          prvs = gray\n",
        "\n",
        "          frame_list.append(frame)\n",
        "          grey_list.append(gray)\n",
        "          horz_grad_list.append(horz_grad)\n",
        "          vert_grad_list.append(vert_grad)\n",
        "          \n",
        "\n",
        "      cv2.destroyAllWindows()\n",
        "      # ipt = np.asarray(frame_list)\n",
        "      # ipt = np.rollaxis(np.rollaxis(ipt,2,0),2,1)\n",
        "\n",
        "      ipt_g = np.asarray(grey_list)\n",
        "      ipt_g = np.rollaxis(ipt_g,2,1)\n",
        "      ipt = ipt_g\n",
        "\n",
        "      ipt_hg = np.asarray(horz_grad_list)\n",
        "      ipt_hg = np.rollaxis(ipt_hg,2,1)\n",
        "\n",
        "      ipt_vg = np.asarray(vert_grad_list)\n",
        "      ipt_vg = np.rollaxis(ipt_vg,2,1)\n",
        "\n",
        "      ipt_hf = np.asarray(horz_flow_list)\n",
        "      ipt_hf = np.rollaxis(ipt_hf,2,1)\n",
        "\n",
        "      ipt_vf = np.asarray(vert_flow_list)\n",
        "      ipt_vf = np.rollaxis(ipt_vf,2,1)\n",
        "\n",
        "      # ipt_g = np.concatenate((ipt_g, ipt_hg))\n",
        "      # ipt_g = np.concatenate((ipt_g, ipt_vg))\n",
        "      # ipt_g = np.concatenate((ipt_g, ipt_hf))\n",
        "      # ipt_g = np.concatenate((ipt_g, ipt_vf))\n",
        "\n",
        "      # Training_set.append(ipt)\n",
        "      num_feature_maps = np.array([ipt.shape[0],ipt_hg.shape[0],ipt_vg.shape[0],ipt_hf.shape[0],ipt_vf.shape[0]])\n",
        "      # print(ipt_g.shape,ipt.shape,ipt_hg.shape,ipt_vg.shape,ipt_hf.shape,ipt_vf.shape)\n",
        "  capture.release()\n",
        "\n",
        "  return ipt_g,ipt_hg,ipt_vg,ipt_hf,ipt_vf\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaJytcHpIRe8"
      },
      "source": [
        "# Training_set = {}\n",
        "def apply_H1(dirname,split_val=0.2,KTH=True,num_frames=9):\n",
        "  if (KTH):\n",
        "    actions = ['boxing','handclapping','handwaving','jogging','running','walking']\n",
        "  else:\n",
        "    actions = [\"ApplyEyeMakeup\",\"Basketball\",\"Diving\",\"HorseRiding\",\"PizzaTossing\",\"Rowing\"]\n",
        "  Training_set = {}\n",
        "  Training_set['M1'] = []\n",
        "  Training_set['M2'] = []\n",
        "  Training_set['M3'] = []\n",
        "  Training_set['M4'] = []\n",
        "  Training_set['M5'] = []\n",
        "  Train_y = []\n",
        "  Test_set = {}\n",
        "  Test_set['M1'] = []\n",
        "  Test_set['M2'] = []\n",
        "  Test_set['M3'] = []\n",
        "  Test_set['M4'] = []\n",
        "  Test_set['M5'] = []\n",
        "  Test_y = []\n",
        "  action_class = 0\n",
        "  for action in actions:\n",
        "    raw_input_dir = os.listdir(dirname+action)\n",
        "    print(action,'loading...')\n",
        "    total_samples = len(raw_input_dir)\n",
        "    test_samples = int(total_samples*split_val)\n",
        "    test_counter = 0\n",
        "    for file_name in raw_input_dir:\n",
        "      file_id = dirname + action + '/' + file_name\n",
        "      m1,m2,m3,m4,m5 = H1_layer(file_id)\n",
        "      if (test_counter < test_samples):\n",
        "        Test_set['M1'].append(m1)\n",
        "        Test_set['M2'].append(m2)\n",
        "        Test_set['M3'].append(m3)\n",
        "        Test_set['M4'].append(m4)\n",
        "        Test_set['M5'].append(m5)\n",
        "        Test_y.append(action_class)\n",
        "        test_counter = test_counter + 1\n",
        "        # print('added in test set',test_counter,test_samples,total_samples)\n",
        "      else:\n",
        "        Training_set['M1'].append(m1)\n",
        "        Training_set['M2'].append(m2)\n",
        "        Training_set['M3'].append(m3)\n",
        "        Training_set['M4'].append(m4)\n",
        "        Training_set['M5'].append(m5)\n",
        "        Train_y.append(action_class)\n",
        "    print(action,'loaded')\n",
        "    action_class = action_class + 1\n",
        "  # Training_set = np.array(Training_set)\n",
        "  return Training_set,Test_set,Train_y,Test_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5U5FmdnCmPg4"
      },
      "source": [
        "## Preprocessing the channels\n",
        "\n",
        "Resulting channels obtained are M1,M2,M3,M4,M5 are processed and reshaped"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWnfKzlkkuxo"
      },
      "source": [
        "def provide_channels(Training_set):\n",
        "  M1_set = np.array(Training_set['M1'])\n",
        "  M2_set = np.array(Training_set['M2'])\n",
        "  M3_set = np.array(Training_set['M3'])\n",
        "  M4_set = np.array(Training_set['M4'])\n",
        "  M5_set = np.array(Training_set['M5'])\n",
        "  # print(\"The resulting dataset shapes\")\n",
        "  # print(M1_set.shape,M2_set.shape,M3_set.shape,M4_set.shape,M5_set.shape)\n",
        "\n",
        "  M1_set = M1_set.astype('float32')\n",
        "  M1_set -= np.mean(M1_set)\n",
        "  M1_set /= np.max(M1_set)\n",
        "  # print(M1_set.shape)\n",
        "  M2_set = M2_set.astype('float32')\n",
        "  M2_set -= np.mean(M2_set)\n",
        "  M2_set /= np.max(M2_set)\n",
        "  # print(M2_set.shape)\n",
        "  M3_set = M3_set.astype('float32')\n",
        "  M3_set -= np.mean(M3_set)\n",
        "  M3_set /= np.max(M3_set)\n",
        "  # print(M3_set.shape)\n",
        "  M4_set = M4_set.astype('float32')\n",
        "  M4_set -= np.mean(M4_set)\n",
        "  M4_set /= np.max(M4_set)\n",
        "  # print(M4_set.shape)\n",
        "  M5_set = M5_set.astype('float32')\n",
        "  M5_set -= np.mean(M5_set)\n",
        "  M5_set /= np.max(M5_set)\n",
        "  # print(M5_set.shape)\n",
        "\n",
        "  M1_set = M1_set.astype('float32')\n",
        "  M1_set -= np.mean(M1_set)\n",
        "  M1_set /= np.max(M1_set)\n",
        "  # print(M1_set.shape)\n",
        "  M2_set = M2_set.astype('float32')\n",
        "  M2_set -= np.mean(M2_set)\n",
        "  M2_set /= np.max(M2_set)\n",
        "  # print(M2_set.shape)\n",
        "  M3_set = M3_set.astype('float32')\n",
        "  M3_set -= np.mean(M3_set)\n",
        "  M3_set /= np.max(M3_set)\n",
        "  # print(M3_set.shape)\n",
        "  M4_set = M4_set.astype('float32')\n",
        "  M4_set -= np.mean(M4_set)\n",
        "  M4_set /= np.max(M4_set)\n",
        "  # print(M4_set.shape)\n",
        "  M5_set = M5_set.astype('float32')\n",
        "  M5_set -= np.mean(M5_set)\n",
        "  M5_set /= np.max(M5_set)\n",
        "  # print(M5_set.shape)\n",
        "\n",
        "  M1_set = M1_set.reshape((M1_set.shape[0],1,M1_set.shape[1],M1_set.shape[2],M1_set.shape[3]))\n",
        "  # print(M1_set.shape)\n",
        "  M2_set = M2_set.reshape((M2_set.shape[0],1,M2_set.shape[1],M2_set.shape[2],M2_set.shape[3]))\n",
        "  # print(M2_set.shape)\n",
        "  M3_set = M3_set.reshape((M3_set.shape[0],1,M3_set.shape[1],M3_set.shape[2],M3_set.shape[3]))\n",
        "  # print(M3_set.shape)\n",
        "  M4_set = M4_set.reshape((M4_set.shape[0],1,M4_set.shape[1],M4_set.shape[2],M4_set.shape[3]))\n",
        "  # print(M4_set.shape)\n",
        "  M5_set = M5_set.reshape((M5_set.shape[0],1,M5_set.shape[1],M5_set.shape[2],M5_set.shape[3]))\n",
        "  # print(M5_set.shape)\n",
        "\n",
        "  return M1_set,M2_set,M3_set,M4_set,M5_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foGGh_BQ-27m"
      },
      "source": [
        "## Dataset preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_NJuYv76OSa",
        "outputId": "77f0fed9-4255-48f0-b1f2-6a927e34dd69"
      },
      "source": [
        "dirname_ufc = '/content/drive/MyDrive/ML_CSP774/Theory_project/3D-CNN Activity Recognition/UFC_Data_unzip/A/'\n",
        "Train_ufc,Test_ufc,Train_ufc_y,Test_ufc_y = apply_H1(dirname_ufc,0,False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ApplyEyeMakeup loading...\n",
            "ApplyEyeMakeup loaded\n",
            "Basketball loading...\n",
            "Basketball loaded\n",
            "Diving loading...\n",
            "Diving loaded\n",
            "HorseRiding loading...\n",
            "HorseRiding loaded\n",
            "PizzaTossing loading...\n",
            "PizzaTossing loaded\n",
            "Rowing loading...\n",
            "Rowing loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcyPRZJalGCy",
        "outputId": "bed36611-7883-4d9b-cdea-7fad0a1d2685"
      },
      "source": [
        "M1_ufc,M2_ufc,M3_ufc,M4_ufc,M5_ufc = provide_channels(Train_ufc)\n",
        "# M1_ufct,M2_ufct,M3_ufct,M4_ufct,M5_ufct = provide_channels(Test_ufc)\n",
        "Train_ufc_y = np.array(Train_ufc_y)\n",
        "Train_ufc_y = np_utils.to_categorical(Train_ufc_y, 6)\n",
        "# Test_ufc_y = np.array(Test_ufc_y)\n",
        "# Test_ufc_y = np_utils.to_categorical(Test_ufc_y, 6)\n",
        "print(\"Final channels for UFC train dataset\\n\",M1_ufc.shape,M2_ufc.shape,M3_ufc.shape,M4_ufc.shape,M5_ufc.shape)\n",
        "# print(\"Final channels for UFC test dataset\\n\",M1_ufct.shape,M2_ufct.shape,M3_ufct.shape,M4_ufct.shape,M5_ufct.shape)\n",
        "print(Train_ufc_y.shape)\n",
        "# print(Test_ufc_y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final channels for UFC train dataset\n",
            " (843, 1, 9, 80, 60) (843, 1, 9, 80, 60) (843, 1, 9, 80, 60) (843, 1, 8, 80, 60) (843, 1, 8, 80, 60)\n",
            "(843, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYIDbE0hTwl4",
        "outputId": "856a52df-4f3b-46c6-c80d-72c0f611156e"
      },
      "source": [
        "dirname_kth = '/content/drive/MyDrive/ML_CSP774/Theory_project/3D-CNN Activity Recognition/KTH_Data_unzip/'\n",
        "Train_kth,Test_kth,Train_kth_y,Test_kth_y = apply_H1(dirname_kth,0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "boxing loading...\n",
            "boxing loaded\n",
            "handclapping loading...\n",
            "handclapping loaded\n",
            "handwaving loading...\n",
            "handwaving loaded\n",
            "jogging loading...\n",
            "jogging loaded\n",
            "running loading...\n",
            "running loaded\n",
            "walking loading...\n",
            "walking loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-viV_lll6sR",
        "outputId": "239d9afe-5a62-4f9f-94fb-f059376ce9ea"
      },
      "source": [
        "M1_kth,M2_kth,M3_kth,M4_kth,M5_kth = provide_channels(Train_kth)\n",
        "print(\"Final channels for UFC dataset\\n\",M1_kth.shape,M2_kth.shape,M3_kth.shape,M4_kth.shape,M5_kth.shape)\n",
        "# M1_ktht,M2_ktht,M3_ktht,M4_ktht,M5_ktht = provide_channels(Test_kth)\n",
        "# print(\"Final channels for UFC test dataset\\n\",M1_ktht.shape,M2_ktht.shape,M3_ktht.shape,M4_ktht.shape,M5_ktht.shape)\n",
        "Train_kth_y = np.array(Train_kth_y)\n",
        "Train_kth_y = np_utils.to_categorical(Train_kth_y, 6)\n",
        "# Test_kth_y = np.array(Test_kth_y)\n",
        "# Test_kth_y = np_utils.to_categorical(Test_kth_y, 6)\n",
        "print(Train_kth_y.shape)\n",
        "# print(Test_kth_y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final channels for UFC dataset\n",
            " (599, 1, 9, 80, 60) (599, 1, 9, 80, 60) (599, 1, 9, 80, 60) (599, 1, 8, 80, 60) (599, 1, 8, 80, 60)\n",
            "(599, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr9h4HVtmEFV"
      },
      "source": [
        "#3D CNN ARCHITECTURE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ukit4PW9-3fq"
      },
      "source": [
        "## Input channels for all the models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLTZPPen98Ix",
        "outputId": "d4a97c37-030e-47af-a89b-ce56a69faaf0"
      },
      "source": [
        "#H1\n",
        "channel1_input = keras.Input(shape=(1,9,80,60), name=\"channel1\")  #later use variables instead of hearcoding the pixel size and frame number\n",
        "channel2_input = keras.Input(shape=(1,9,80,60), name=\"channel2\") \n",
        "channel3_input = keras.Input(shape=(1,9,80,60), name=\"channel3\") \n",
        "channel4_input = keras.Input(shape=(1,8,80,60), name=\"channel4\") \n",
        "channel5_input = keras.Input(shape=(1,8,80,60), name=\"channel5\")  \n",
        "print(channel1_input.shape,channel2_input.shape,channel3_input.shape,channel4_input.shape,channel5_input.shape)\n",
        "# channel3_input = keras.Input(shape=(num_tags,), name=\"tags\")  # Binary vectors of size `num_tags`"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 1, 9, 80, 60) (None, 1, 9, 80, 60) (None, 1, 9, 80, 60) (None, 1, 8, 80, 60) (None, 1, 8, 80, 60)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KzovUk9ZGMv"
      },
      "source": [
        "## Regularisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8TjWGhaZSqM"
      },
      "source": [
        "### SIFT feature extraction\n",
        "1. from raw images gray \n",
        "2. Motion edge history images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pbc2kDwZRz0"
      },
      "source": [
        "def SIFT_desc(dirname,MEHI_raw=True,KTH=True,num_frames=9):\n",
        "  if (KTH):\n",
        "    actions = ['boxing','handclapping','handwaving','jogging','running','walking']\n",
        "  else:\n",
        "    actions = [\"ApplyEyeMakeup\",\"Basketball\",\"Diving\",\"HorseRiding\",\"PizzaTossing\",\"Rowing\"]\n",
        "  sift_dataset = []\n",
        "  for action in actions:\n",
        "    raw_input_dir = os.listdir(dirname+action)\n",
        "    print(action,'loading...')\n",
        "    for file_name in raw_input_dir:\n",
        "      file_id = dirname + action + '/' + file_name\n",
        "      capture = cv2.VideoCapture(file_id)\n",
        "      fps = capture.get(cv2.CAP_PROP_FPS)\n",
        "      video_features = None\n",
        "      if (not MEHI_raw):\n",
        "        success, frame = capture.read()\n",
        "        frame = cv2.resize(frame,(80,60),interpolation=cv2.INTER_AREA)\n",
        "        gray1 =  cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "      for i in range(num_frames):\n",
        "        # print(i)\n",
        "        if (MEHI_raw): #Raw images\n",
        "          success, frame = capture.read()\n",
        "          frame = cv2.resize(frame,(80,60),interpolation=cv2.INTER_AREA)\n",
        "          gray =  cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "          DSIFT_STEP_SIZE = 6\n",
        "          sift = cv2.xfeatures2d.SIFT_create()\n",
        "          disft_step_size = DSIFT_STEP_SIZE\n",
        "          keypoints = [cv2.KeyPoint(x, y, disft_step_size)\n",
        "                  for y in range(0, gray.shape[0], disft_step_size)\n",
        "                      for x in range(0, gray.shape[1], disft_step_size)]\n",
        "          descriptors = sift.compute(gray, keypoints)[1]\n",
        "          try:\n",
        "            video_features = np.concatenate((video_features,np.array(descriptors)),axis=0)\n",
        "          except:\n",
        "            video_features = np.array(descriptors)\n",
        "        else:\n",
        "          success2, frame2 = capture.read()\n",
        "          frame2 = cv2.resize(frame2,(80,60),interpolation=cv2.INTER_AREA)\n",
        "          gray2 =  cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
        "          D_t_xy = gray1 - gray2\n",
        "          MEHI = cv2.Canny(D_t_xy,100,200)\n",
        "          DSIFT_STEP_SIZE = 6\n",
        "          sift = cv2.xfeatures2d.SIFT_create()\n",
        "          disft_step_size = DSIFT_STEP_SIZE\n",
        "          keypoints = [cv2.KeyPoint(x, y, disft_step_size)\n",
        "                  for y in range(0, MEHI.shape[0], disft_step_size)\n",
        "                      for x in range(0, MEHI.shape[1], disft_step_size)]\n",
        "          descriptors = sift.compute(MEHI, keypoints)[1]\n",
        "          try:\n",
        "            video_features = np.concatenate((video_features,np.array(descriptors)),axis=0)\n",
        "          except:\n",
        "            video_features = np.array(descriptors)\n",
        "          gray1 = gray2\n",
        "\n",
        "      sift_dataset.append(video_features)\n",
        "    print(action,'loaded')\n",
        "  # Training_set = np.array(Training_set)\n",
        "  return sift_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2k2tCKjmcGX6",
        "outputId": "7fecf0f3-9fcc-46d7-db4c-cf85b2ad8f3a"
      },
      "source": [
        "sift_whole = SIFT_desc(dirname_ufc,True,False,9)\n",
        "sift_whole_np = np.array(sift_whole)\n",
        "print(sift_whole_np.shape)\n",
        "sift_whole_MEHI = SIFT_desc(dirname_ufc,False,False,9)\n",
        "sift_whole_MEHI_np = np.array(sift_whole_MEHI)\n",
        "print(sift_whole_MEHI_np.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ApplyEyeMakeup loading...\n",
            "ApplyEyeMakeup loaded\n",
            "Basketball loading...\n",
            "Basketball loaded\n",
            "Diving loading...\n",
            "Diving loaded\n",
            "HorseRiding loading...\n",
            "HorseRiding loaded\n",
            "PizzaTossing loading...\n",
            "PizzaTossing loaded\n",
            "Rowing loading...\n",
            "Rowing loaded\n",
            "(843, 1260, 128)\n",
            "ApplyEyeMakeup loading...\n",
            "ApplyEyeMakeup loaded\n",
            "Basketball loading...\n",
            "Basketball loaded\n",
            "Diving loading...\n",
            "Diving loaded\n",
            "HorseRiding loading...\n",
            "HorseRiding loaded\n",
            "PizzaTossing loading...\n",
            "PizzaTossing loaded\n",
            "Rowing loading...\n",
            "Rowing loaded\n",
            "(843, 1260, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1c4l6tnc-pu"
      },
      "source": [
        "### Soft-feature Quantisation, GMM\n",
        "\n",
        "Softly quantized (each local feature can be assigned to multiple codebook words) using a 512-word codebook. The method is basically Multiple clustering where each data point can be assigned to multiple clusters with each point having the probability of belonging to each cluster. Such a model is GMM.\n",
        "\n",
        "Not using the whole dataset for GMM model because of RAM constraints. Instead sampling random features with the assumption that the randomly chosen arguments would also give a fair representation of the complete distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Efe8NP1wdHp5"
      },
      "source": [
        "def cluster_features(img_descs,cluster_model,n_clusters=512):\n",
        "    # n_clusters = cluster_model.n_clusters\n",
        "    des_stack_train=[desc for img in img_descs for desc in img]\n",
        "    all_train_descriptors = np.array(des_stack_train)\n",
        "\n",
        "    if all_train_descriptors.shape[1] != 128:\n",
        "        raise ValueError('Expected SIFT descriptors to have 128 features, got', all_train_descriptors.shape[1])\n",
        "\n",
        "    print ('%i Descriptors before clustering' % all_train_descriptors.shape[0])\n",
        "\n",
        "    randomly_sampled = all_train_descriptors[np.random.choice(all_train_descriptors.shape[0], size=30000, replace=False), :]\n",
        "    # randomly_sampled = np.random.choice(sift_whole_np, size=10000, replace=False)\n",
        "    #If data does not fit in memory you can find a way to randomly sample when you read it\n",
        "    print(randomly_sampled.shape)\n",
        "\n",
        "    print ('Using clustering model %s...' % repr(cluster_model))\n",
        "    print ('Clustering on training set to get codebook of %i words' % n_clusters)\n",
        "\n",
        "    # train kmeans or other cluster model on those descriptors selected above\n",
        "    cluster_model.fit(randomly_sampled)\n",
        "    print ('done clustering.')\n",
        "\n",
        "    return cluster_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmktpH_1dPdw",
        "outputId": "96e3a695-72d4-4fd4-db74-dbcad7401739"
      },
      "source": [
        "GMM_model = GaussianMixture(n_components=512)\n",
        "cluster_model_raw = cluster_features(sift_whole_np,GMM_model)\n",
        "GMM_model_MEHI = GaussianMixture(n_components=512)\n",
        "cluster_model_MEHI = cluster_features(sift_whole_MEHI_np,GMM_model_MEHI)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1062180 Descriptors before clustering\n",
            "(30000, 128)\n",
            "Using clustering model GaussianMixture(covariance_type='full', init_params='kmeans', max_iter=100,\n",
            "                means_init=None, n_components=512, n_init=1,\n",
            "                precisions_init=None, random_state=None, reg_covar=1e-06,\n",
            "                tol=0.001, verbose=0, verbose_interval=10, warm_start=False,\n",
            "                weights_init=None)...\n",
            "Clustering on training set to get codebook of 512 words\n",
            "done clustering.\n",
            "1062180 Descriptors before clustering\n",
            "(30000, 128)\n",
            "Using clustering model GaussianMixture(covariance_type='full', init_params='kmeans', max_iter=100,\n",
            "                means_init=None, n_components=512, n_init=1,\n",
            "                precisions_init=None, random_state=None, reg_covar=1e-06,\n",
            "                tol=0.001, verbose=0, verbose_interval=10, warm_start=False,\n",
            "                weights_init=None)...\n",
            "Clustering on training set to get codebook of 512 words\n",
            "done clustering.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rI9AkcYseSa2"
      },
      "source": [
        "### Encoding the features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVHTXNkseX6m"
      },
      "source": [
        "def extract_denseSIFT(gray):\n",
        "    DSIFT_STEP_SIZE = 6\n",
        "    sift = cv2.xfeatures2d.SIFT_create()\n",
        "    disft_step_size = DSIFT_STEP_SIZE\n",
        "    keypoints = [cv2.KeyPoint(x, y, disft_step_size)\n",
        "            for y in range(0, gray.shape[0], disft_step_size)\n",
        "                for x in range(0, gray.shape[1], disft_step_size)]\n",
        "\n",
        "    descriptors = sift.compute(gray, keypoints)[1]\n",
        "    \n",
        "    #keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
        "    return descriptors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9wuGWpWgOK7"
      },
      "source": [
        "### Spatial Pyramid Matching"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tw5gCt4dgRxF"
      },
      "source": [
        "def getImageFeaturesSPM(w_step,h_step, file_id, cluster_model, K,raw_MEHI=True,W=80, H=60,num_frames=9):  \n",
        "    h = []\n",
        "    x = 0\n",
        "    y = 0\n",
        "    for i in range(w_step):\n",
        "      for j in range(h_step):\n",
        "        capture = cv2.VideoCapture(file_id)\n",
        "        fps = capture.get(cv2.CAP_PROP_FPS)\n",
        "        desc_ = None\n",
        "        if (not raw_MEHI):\n",
        "          success, frame = capture.read()\n",
        "          frame = cv2.resize(frame,(80,60),interpolation=cv2.INTER_AREA)\n",
        "          img1 =  cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        for k in range(num_frames):\n",
        "            # print(k)\n",
        "            if (raw_MEHI):\n",
        "              success, frame = capture.read()\n",
        "              frame = cv2.resize(frame,(80,60),interpolation=cv2.INTER_AREA)\n",
        "              img =  cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "              desc = extract_denseSIFT(img[y:y+w_step, x:x+h_step])\n",
        "              try: \n",
        "                desc_ = np.concatenate((desc_,desc),axis=0)\n",
        "              except:\n",
        "                desc_ = desc\n",
        "            else:\n",
        "              success2, frame2 = capture.read()\n",
        "              frame2 = cv2.resize(frame2,(80,60),interpolation=cv2.INTER_AREA)\n",
        "              img2 =  cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
        "              D = img1 - img2\n",
        "              H = cv2.Canny(D,100,200)\n",
        "              desc = extract_denseSIFT(H[y:y+w_step, x:x+h_step])\n",
        "              try: \n",
        "                desc_ = np.concatenate((desc_,desc),axis=0)\n",
        "              except:\n",
        "                desc_ = desc\n",
        "        capture.release()\n",
        "        predict = cluster_model.predict(desc_)\n",
        "        histo = np.bincount(predict, minlength=K).reshape(1,-1).ravel()\n",
        "        h.append(histo)\n",
        "        x = x + w_step\n",
        "      y = y + h_step\n",
        "    \n",
        "    hist = np.array(h).ravel()\n",
        "    # normalize hist\n",
        "    dev = np.std(hist)\n",
        "    hist = hist - np.mean(hist)\n",
        "    hist /= dev\n",
        "    return hist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rimkh7F_hTDF"
      },
      "source": [
        "def aux_units_gray_MEHI(dirname,raw_MEHI=True,KTH=True,num_frames=9):\n",
        "  if (KTH):\n",
        "    actions = ['boxing','handclapping','handwaving','jogging','running','walking']\n",
        "  else:\n",
        "    actions = [\"ApplyEyeMakeup\",\"Basketball\",\"Diving\",\"HorseRiding\",\"PizzaTossing\",\"Rowing\"]\n",
        "  sift_dataset = []\n",
        "  for action in actions:\n",
        "    raw_input_dir = os.listdir(dirname+action)\n",
        "    # print(action,'loading...')\n",
        "    for file_name in raw_input_dir:\n",
        "      file_id = dirname + action + '/' + file_name\n",
        "      if (raw_MEHI):\n",
        "        res1_gray = getImageFeaturesSPM(2,2,file_id,cluster_model_raw,512,True)\n",
        "        res2_gray = getImageFeaturesSPM(3,4,file_id,cluster_model_raw,512,True)\n",
        "        SPM_Gray = np.concatenate((res1_gray,res2_gray))\n",
        "        sift_dataset.append(SPM_Gray)\n",
        "      else:\n",
        "        res1_MEHI = getImageFeaturesSPM(2,2,file_id,cluster_model_MEHI,512,False)\n",
        "        res2_MEHI = getImageFeaturesSPM(3,4,file_id,cluster_model_MEHI,512,False)\n",
        "        SPM_MEHI = np.concatenate((res1_MEHI,res2_MEHI)) \n",
        "        sift_dataset.append(SPM_MEHI)\n",
        "    # print(action,'loaded')\n",
        "  # Training_set = np.array(Training_set)\n",
        "  return sift_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUk6bJpciDO0",
        "outputId": "dc6cc59d-3db7-452b-d03a-79e1ce7b14c9"
      },
      "source": [
        "aux_output_units_g = aux_units_gray_MEHI(dirname_ufc,True,False)\n",
        "aux_output_units_g_np = np.array(aux_output_units_g)\n",
        "print(aux_output_units_g_np.shape)\n",
        "aux_output_units_m = aux_units_gray_MEHI(dirname_ufc,False,False)\n",
        "aux_output_units_m_np = np.array(aux_output_units_m)\n",
        "print(aux_output_units_m_np.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(843, 8192)\n",
            "(843, 8192)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrUeE9g-qRMx"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler \n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GASReLhTk5Cy",
        "outputId": "3a2ec0ec-e43a-44a6-d061-a327550f544e"
      },
      "source": [
        "print(aux_output_units_m_np.shape)\n",
        "sc = StandardScaler() \n",
        "pca_SPM_MEHI = sc.fit_transform(aux_output_units_m_np)\n",
        "# print(pca_SPM_MEHI.shape)\n",
        "pca = PCA(n_components = 150) \n",
        "pca_SPM_MEHI = pca.fit_transform(pca_SPM_MEHI)\n",
        "print(pca_SPM_MEHI.shape) \n",
        "#for raw gray images\n",
        "print(aux_output_units_g_np.shape)\n",
        "sc = StandardScaler() \n",
        "pca_SPM_GRAY = sc.fit_transform(aux_output_units_g_np)\n",
        "# print(pca_SPM_GRAY.shape)\n",
        "pca = PCA(n_components = 150) \n",
        "pca_SPM_GRAY = pca.fit_transform(pca_SPM_GRAY)\n",
        "print(pca_SPM_GRAY.shape) \n",
        "pca_SPM_cube_ufc = np.concatenate((pca_SPM_GRAY,pca_SPM_MEHI),axis=1)\n",
        "print(pca_SPM_cube_ufc.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(843, 8192)\n",
            "(843, 150)\n",
            "(843, 8192)\n",
            "(843, 150)\n",
            "(843, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muW4oT7cricC"
      },
      "source": [
        "filename = '/content/drive/MyDrive/ML_CSP774/Theory_project/3D-CNN Activity Recognition/Pickle/pca_spm_cube.pickle'\n",
        "with open(filename, 'wb') as f:\n",
        "    pickle.dump(pca_SPM_cube_ufc, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNKp5Wbr4AsR"
      },
      "source": [
        "filename = '/content/drive/MyDrive/ML_CSP774/Theory_project/3D-CNN Activity Recognition/Pickle/pca_spm_cube.pickle'\n",
        "with open(filename, 'rb') as f:\n",
        "    pca_SPM_cube_ufc_reloaded = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdGokmoy4NoQ",
        "outputId": "37ae3f30-e2d6-4788-d379-784016288ad2"
      },
      "source": [
        "pca_SPM_cube_ufc_reloaded == pca_SPM_cube_ufc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True,  True,  True, ...,  True,  True,  True],\n",
              "       [ True,  True,  True, ...,  True,  True,  True],\n",
              "       [ True,  True,  True, ...,  True,  True,  True],\n",
              "       ...,\n",
              "       [ True,  True,  True, ...,  True,  True,  True],\n",
              "       [ True,  True,  True, ...,  True,  True,  True],\n",
              "       [ True,  True,  True, ...,  True,  True,  True]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7i82d0ZJ-82R"
      },
      "source": [
        "## Generic architectures\n",
        "* for writing and compiling the function\n",
        "* Defining a function that can create all architectures, using keras inbuilt libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhcOZ46k_VS9"
      },
      "source": [
        "def CNN_3D(channel1_inputs,channel2_inputs,channel3_inputs,channel4_inputs,channel5_inputs,architecture='s332',activation_function='relu',combination=5,optimizer_c='RMSProp'):\n",
        "\n",
        "  if (architecture == 's332') or (architecture == 'rs332'):\n",
        "    print(architecture)\n",
        "    kernel_size1 = (3,9,7)\n",
        "    kernel_size2 = (3,7,7)\n",
        "    final_ = 138\n",
        "    if (architecture == 's332'):\n",
        "      name_128 = \"shape128_s332\"\n",
        "      name_output = \"output_s332\"\n",
        "    else:\n",
        "      name_128 = \"shape128_rs332\"\n",
        "      name_output = \"output_rs332\"\n",
        "\n",
        "  if (architecture == 'm332'):\n",
        "    print(architecture)\n",
        "    kernel_size1 = (3,9,7)\n",
        "    kernel_size2 = (3,7,7)\n",
        "    final_ = 162\n",
        "    name_128 = \"shape128_m332\"\n",
        "    name_output = \"output_m332\"\n",
        "  \n",
        "  if (architecture == 'm322'):\n",
        "    print(architecture)\n",
        "    kernel_size1 = (3,9,7)\n",
        "    kernel_size2 = (1,7,7)\n",
        "    final_ = 198\n",
        "    name_128 = \"shape128_m322\"\n",
        "    name_output = \"output_m322\"\n",
        "\n",
        "  if (architecture == 'm222'):\n",
        "    print(architecture)\n",
        "    kernel_size1 = (1,9,7)\n",
        "    kernel_size2 = (1,7,7)\n",
        "    final_ = 258\n",
        "    name_128 = \"shape128_m222\"\n",
        "    name_output = \"output_m222\"\n",
        "\n",
        "\n",
        "  if (architecture == \"ensemble\"):\n",
        "    if (combination==1):\n",
        "      #rs332\n",
        "      modelr332 = CNN_3D(channel1_input,channel2_input,channel3_input,channel4_input,channel5_input,\"rs332\")\n",
        "      return modelr332\n",
        "    elif (combination==2):\n",
        "      #rs332 + s332\n",
        "      model_s332 = CNN_3D(channel1_input,channel2_input,channel3_input,channel4_input,channel5_input)\n",
        "      model_r332 = CNN_3D(channel1_input,channel2_input,channel3_input,channel4_input,channel5_input,\"rs332\")\n",
        "      ensemble_layer = keras.layers.Average(name=\"ens_res\")([model_s332.outputs[0],model_r332.outputs[0]])\n",
        "    elif (combination==3):\n",
        "      #rs332 + s332 + m222\n",
        "      model_s332 = CNN_3D(channel1_input,channel2_input,channel3_input,channel4_input,channel5_input)\n",
        "      model_r332 = CNN_3D(channel1_input,channel2_input,channel3_input,channel4_input,channel5_input,\"rs332\")\n",
        "      model_m222 = CNN_3D(channel1_input,channel2_input,channel3_input,channel4_input,channel5_input,\"m222\")\n",
        "      ensemble_layer = keras.layers.Average(name=\"ens_res\")([model_s332.outputs[0],model_r332.outputs[0],model_m222.outputs[0]])\n",
        "    elif (combination==4):\n",
        "      #rs332 + s332 + m222 + m322\n",
        "      model_s332 = CNN_3D(channel1_input,channel2_input,channel3_input,channel4_input,channel5_input)\n",
        "      model_r332 = CNN_3D(channel1_input,channel2_input,channel3_input,channel4_input,channel5_input,\"rs332\")\n",
        "      model_m322 = CNN_3D(channel1_input,channel2_input,channel3_input,channel4_input,channel5_input,\"m322\")\n",
        "      model_m222 = CNN_3D(channel1_input,channel2_input,channel3_input,channel4_input,channel5_input,\"m222\")\n",
        "      ensemble_layer = keras.layers.Average(name=\"ens_res\")([model_s332.outputs[0],model_r332.outputs[0],model_m322.outputs[0],model_m222.outputs[0]])\n",
        "    elif (combination==5):\n",
        "      #rs332 + s332 + m222 + m322 + m332\n",
        "      model_s332 = CNN_3D(channel1_input,channel2_input,channel3_input,channel4_input,channel5_input)\n",
        "      model_r332 = CNN_3D(channel1_input,channel2_input,channel3_input,channel4_input,channel5_input,\"rs332\")\n",
        "      model_m332 = CNN_3D(channel1_input,channel2_input,channel3_input,channel4_input,channel5_input,\"m332\")\n",
        "      model_m322 = CNN_3D(channel1_input,channel2_input,channel3_input,channel4_input,channel5_input,\"m322\")\n",
        "      model_m222 = CNN_3D(channel1_input,channel2_input,channel3_input,channel4_input,channel5_input,\"m222\")\n",
        "      ensemble_layer = keras.layers.Average(name=\"ens_res\")([model_s332.outputs[0],model_r332.outputs[0],model_m332.outputs[0],model_m322.outputs[0],model_m222.outputs[0]])\n",
        "    ensemble_model = keras.Model(\n",
        "        inputs=[channel1_input,channel2_input,channel3_input,channel4_input,channel5_input],\n",
        "        outputs = [ensemble_layer]\n",
        "    )\n",
        "    ensemble_model.compile(loss='categorical_crossentropy', metrics=['mse', 'accuracy',keras.metrics.Precision()])\n",
        "    return ensemble_model\n",
        "\n",
        "  #C2\n",
        "  channel1_features = keras.layers.Conv3D(2,kernel_size=kernel_size1,data_format='channels_first',activation=activation_function)(channel1_input)\n",
        "  channel2_features = keras.layers.Conv3D(2,kernel_size=kernel_size1,data_format='channels_first',activation=activation_function)(channel2_input)\n",
        "  channel3_features = keras.layers.Conv3D(2,kernel_size=kernel_size1,data_format='channels_first',activation=activation_function)(channel3_input)\n",
        "  channel4_features = keras.layers.Conv3D(2,kernel_size=kernel_size1,data_format='channels_first',activation=activation_function)(channel4_input)\n",
        "  channel5_features = keras.layers.Conv3D(2,kernel_size=kernel_size1,data_format='channels_first',activation=activation_function)(channel5_input)\n",
        "  print(channel1_features.shape,channel2_features.shape,channel3_features.shape,channel4_features.shape,channel5_features.shape)\n",
        "\n",
        "  #S3\n",
        "  channel1_features = keras.layers.AveragePooling3D(pool_size=(1,3,3),data_format=\"channels_first\")(channel1_features)\n",
        "\n",
        "  if (architecture == 's332') or (architecture == 'rs332'):\n",
        "    #normal\n",
        "    channel2_features = keras.layers.AveragePooling3D(pool_size=(1,3,3),data_format=\"channels_first\")(channel2_features)\n",
        "    channel3_features = keras.layers.AveragePooling3D(pool_size=(1,3,3),data_format=\"channels_first\")(channel3_features)\n",
        "    channel4_features = keras.layers.AveragePooling3D(pool_size=(1,3,3),data_format=\"channels_first\")(channel4_features)\n",
        "    channel5_features = keras.layers.AveragePooling3D(pool_size=(1,3,3),data_format=\"channels_first\")(channel5_features)\n",
        "    print(channel1_features.shape,channel2_features.shape,channel3_features.shape,channel4_features.shape,channel5_features.shape)\n",
        "  elif ((architecture == \"m332\") or (architecture == \"m322\") or (architecture == \"m222\")):\n",
        "    #S3 (First mixing the channels of same type and subsampling) \n",
        "    channel2_features = keras.layers.concatenate(inputs=[channel2_features, channel3_features],axis=2)\n",
        "    channel3_features = keras.layers.concatenate(inputs=[channel4_features,channel5_features],axis=2)\n",
        "\n",
        "    channel2_features = keras.layers.AveragePooling3D(pool_size=(1,3,3),data_format=\"channels_first\")(channel2_features)\n",
        "    channel3_features = keras.layers.AveragePooling3D(pool_size=(1,3,3),data_format=\"channels_first\")(channel3_features)\n",
        "    print(channel1_features.shape,channel2_features.shape,channel3_features.shape)\n",
        "  \n",
        "\n",
        "  #C4\n",
        "  channel1_features = tf.keras.layers.Conv3D(6,kernel_size=kernel_size2,data_format='channels_first',activation=activation_function,groups=2)(channel1_features)\n",
        "  channel2_features = tf.keras.layers.Conv3D(6,kernel_size=kernel_size2,data_format='channels_first',activation=activation_function,groups=2)(channel2_features)\n",
        "  channel3_features = tf.keras.layers.Conv3D(6,kernel_size=kernel_size2,data_format='channels_first',activation=activation_function,groups=2)(channel3_features)\n",
        "\n",
        "  if (architecture == 's332') or (architecture == 'rs332'):\n",
        "    channel4_features = tf.keras.layers.Conv3D(6,kernel_size=kernel_size2,data_format='channels_first',activation=activation_function,groups=2)(channel4_features)\n",
        "    channel5_features = tf.keras.layers.Conv3D(6,kernel_size=kernel_size2,data_format='channels_first',activation=activation_function,groups=2)(channel5_features)\n",
        "    print(channel1_features.shape,channel2_features.shape,channel3_features.shape,channel4_features.shape,channel5_features.shape)\n",
        "  elif ((architecture == \"m332\") or (architecture == \"m322\") or (architecture == \"m222\")):\n",
        "    print(channel1_features.shape,channel2_features.shape,channel3_features.shape)\n",
        "\n",
        "  #S5\n",
        "  if (architecture == 's332') or (architecture == 'rs332'):\n",
        "    channel1_features = keras.layers.AveragePooling3D(pool_size=(1,3,3),data_format=\"channels_first\")(channel1_features)\n",
        "    channel2_features = keras.layers.AveragePooling3D(pool_size=(1,3,3),data_format=\"channels_first\")(channel2_features)\n",
        "    channel3_features = keras.layers.AveragePooling3D(pool_size=(1,3,3),data_format=\"channels_first\")(channel3_features)\n",
        "    channel4_features = keras.layers.AveragePooling3D(pool_size=(1,3,3),data_format=\"channels_first\")(channel4_features)\n",
        "    channel5_features = keras.layers.AveragePooling3D(pool_size=(1,3,3),data_format=\"channels_first\")(channel5_features)\n",
        "    print(channel1_features.shape,channel2_features.shape,channel3_features.shape,channel4_features.shape,channel5_features.shape)\n",
        "  elif ((architecture == \"m332\") or (architecture == \"m322\") or (architecture == \"m222\")):\n",
        "    channel1_features = keras.layers.concatenate(inputs=[channel1_features,channel2_features, channel3_features],axis=2)\n",
        "    channel1_features = keras.layers.AveragePooling3D(pool_size=(1,3,3),data_format=\"channels_first\")(channel1_features)\n",
        "    print(channel1_features.shape)\n",
        "\n",
        "  #C6\n",
        "  channel1_features = keras.layers.Conv3D(filters=6,kernel_size=(1,6,4),data_format='channels_first',activation='relu')(channel1_features)\n",
        "  if (architecture == 's332') or (architecture == 'rs332'):\n",
        "    channel2_features = keras.layers.Conv3D(filters=6,kernel_size=(1,6,4),data_format='channels_first',activation=activation_function)(channel2_features)\n",
        "    channel3_features = keras.layers.Conv3D(filters=6,kernel_size=(1,6,4),data_format='channels_first',activation=activation_function)(channel3_features)\n",
        "    channel4_features = keras.layers.Conv3D(filters=6,kernel_size=(1,6,4),data_format='channels_first',activation=activation_function)(channel4_features)\n",
        "    channel5_features = keras.layers.Conv3D(filters=6,kernel_size=(1,6,4),data_format='channels_first',activation=activation_function)(channel5_features)\n",
        "    print(channel1_features.shape,channel2_features.shape,channel3_features.shape,channel4_features.shape,channel5_features.shape)\n",
        "  elif ((architecture == \"m332\") or (architecture == \"m322\") or (architecture == \"m222\")):\n",
        "    print(channel1_features.shape)\n",
        "\n",
        "  if (architecture == 's332') or (architecture == 'rs332'):\n",
        "    features = keras.layers.concatenate(inputs=[channel1_features, channel2_features, channel3_features,channel4_features,channel5_features],axis=2)\n",
        "    print(features.shape)\n",
        "  elif ((architecture == \"m332\") or (architecture == \"m322\") or (architecture == \"m222\")):\n",
        "    features = channel1_features\n",
        "\n",
        "  features = tf.keras.layers.Reshape(target_shape=(final_,),)(features)\n",
        "  print(features.shape)\n",
        "\n",
        "  features = tf.keras.layers.Dense(128,name=name_128)(features)\n",
        "  print(features.shape)\n",
        "\n",
        "  # if (architecture == \"rs322\"):\n",
        "  #   pca_features = tf.keras.layers.Dense(300,activation='relu', name='output_spm_rs332')(features)\n",
        "  #   print(pca_features.shape)\n",
        "\n",
        "  final_features = tf.keras.layers.Dense(6,activation='softmax',name=name_output)(features)\n",
        "  print(final_features.shape)\n",
        "\n",
        "  # softmax_layer = Dense(1,activation='softmax')(final_features)\n",
        "  # print(softmax_layer.shape)\n",
        "\n",
        "  if (architecture == 'rs332'):\n",
        "    print(\"correct\")\n",
        "    pca_features = tf.keras.layers.Dense(300,activation='relu', name='output_spm_rs332')(features)\n",
        "    print(pca_features.shape)\n",
        "    model = keras.Model(\n",
        "        inputs=[channel1_input,channel2_input,channel3_input,channel4_input,channel5_input],\n",
        "        outputs = [final_features,pca_features])\n",
        "    model.compile(\n",
        "        optimizer='RMSprop',\n",
        "        loss={\"output_rs332\": keras.losses.categorical_crossentropy,\"output_spm_rs332\": keras.losses.mean_squared_error},\n",
        "        loss_weights=[1.0, 0.005],\n",
        "        metrics={\"output_rs332\":[\"mse\",\"accuracy\",keras.metrics.Precision()],\"output_spm_rs332\":['mse', 'accuracy']},)\n",
        "    return model\n",
        "\n",
        "  model = keras.Model(\n",
        "      inputs=[channel1_input,channel2_input,channel3_input,channel4_input,channel5_input],\n",
        "      outputs = [final_features]\n",
        "  )\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['mse', 'accuracy',keras.metrics.Precision()])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBc9bcnD-fEj"
      },
      "source": [
        "## Averaging all five models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHYPJ8MRP6g8",
        "outputId": "b04bd159-45bd-41fe-f0a1-eff03a7cda6e"
      },
      "source": [
        "# model = CNN_3D(channel1_input,channel2_input,channel3_input,channel4_input,channel5_input)\n",
        "# model = CNN_3D(channel1_input,channel2_input,channel3_input,channel4_input,channel5_input,\"m332\")\n",
        "# model = CNN_3D(channel1_input,channel2_input,channel3_input,channel4_input,channel5_input,\"m322\")\n",
        "# model = CNN_3D(channel1_input,channel2_input,channel3_input,channel4_input,channel5_input,\"m222\")\n",
        "model = CNN_3D(channel1_input,channel2_input,channel3_input,channel4_input,channel5_input,\"s332\",\"tanh\",None,\"RMSProp\")\n",
        "model.summary()\n",
        "del model\n",
        "keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "s332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "channel1 (InputLayer)           [(None, 1, 9, 80, 60 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "channel2 (InputLayer)           [(None, 1, 9, 80, 60 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "channel3 (InputLayer)           [(None, 1, 9, 80, 60 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "channel4 (InputLayer)           [(None, 1, 8, 80, 60 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "channel5 (InputLayer)           [(None, 1, 8, 80, 60 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv3d (Conv3D)                 (None, 2, 7, 72, 54) 380         channel1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1 (Conv3D)               (None, 2, 7, 72, 54) 380         channel2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2 (Conv3D)               (None, 2, 7, 72, 54) 380         channel3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_3 (Conv3D)               (None, 2, 6, 72, 54) 380         channel4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_4 (Conv3D)               (None, 2, 6, 72, 54) 380         channel5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling3d (AveragePooli (None, 2, 7, 24, 18) 0           conv3d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling3d_1 (AveragePoo (None, 2, 7, 24, 18) 0           conv3d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling3d_2 (AveragePoo (None, 2, 7, 24, 18) 0           conv3d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling3d_3 (AveragePoo (None, 2, 6, 24, 18) 0           conv3d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling3d_4 (AveragePoo (None, 2, 6, 24, 18) 0           conv3d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_5 (Conv3D)               (None, 6, 5, 18, 12) 888         average_pooling3d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_6 (Conv3D)               (None, 6, 5, 18, 12) 888         average_pooling3d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_7 (Conv3D)               (None, 6, 5, 18, 12) 888         average_pooling3d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_8 (Conv3D)               (None, 6, 4, 18, 12) 888         average_pooling3d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_9 (Conv3D)               (None, 6, 4, 18, 12) 888         average_pooling3d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling3d_5 (AveragePoo (None, 6, 5, 6, 4)   0           conv3d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling3d_6 (AveragePoo (None, 6, 5, 6, 4)   0           conv3d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling3d_7 (AveragePoo (None, 6, 5, 6, 4)   0           conv3d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling3d_8 (AveragePoo (None, 6, 4, 6, 4)   0           conv3d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling3d_9 (AveragePoo (None, 6, 4, 6, 4)   0           conv3d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_10 (Conv3D)              (None, 6, 5, 1, 1)   870         average_pooling3d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_11 (Conv3D)              (None, 6, 5, 1, 1)   870         average_pooling3d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_12 (Conv3D)              (None, 6, 5, 1, 1)   870         average_pooling3d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_13 (Conv3D)              (None, 6, 4, 1, 1)   870         average_pooling3d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_14 (Conv3D)              (None, 6, 4, 1, 1)   870         average_pooling3d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 6, 23, 1, 1)  0           conv3d_10[0][0]                  \n",
            "                                                                 conv3d_11[0][0]                  \n",
            "                                                                 conv3d_12[0][0]                  \n",
            "                                                                 conv3d_13[0][0]                  \n",
            "                                                                 conv3d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 138)          0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "shape128_s332 (Dense)           (None, 128)          17792       reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "output_s332 (Dense)             (None, 6)            774         shape128_s332[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 29,256\n",
            "Trainable params: 29,256\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqSf358J-Bkj"
      },
      "source": [
        "# EXPERIMENTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SfWNe8HD-7h"
      },
      "source": [
        "def kfold_validation(model_type,M1,M2,M3,M4,M5,Y,spm,batch_size=32,no_epochs=30,verbosity=1,combination=5,activation='relu',optimizer='RMSProp'): \n",
        "  num_folds = 5\n",
        "  loss_per_fold = []\n",
        "  acc_per_fold = []\n",
        "  prec_per_fold = []\n",
        "  mse_per_fold = []\n",
        "  # Merge inputs and targets\n",
        "  fold_no = 1\n",
        "  kfold = KFold(n_splits=5, shuffle=True)\n",
        "  for train, test in kfold.split(M1, Y):\n",
        "\n",
        "    output_name = \"output_\" + model_type\n",
        "\n",
        "    if (model_type==\"s332\"):\n",
        "      model = CNN_3D(channel1_input,channel2_input,channel3_input,channel4_input,channel5_input,\"s332\",activation,None,optimizer)\n",
        "      print(\"New s332 model initialised\")\n",
        "    elif (model_type==\"m332\"):\n",
        "      model = CNN_3D(channel1_input,channel2_input,channel3_input,channel4_input,channel5_input,\"m332\",activation,None,optimizer)\n",
        "      print(\"New m332 model initialised\")\n",
        "    elif (model_type==\"m322\"):\n",
        "      model = CNN_3D(channel1_input,channel2_input,channel3_input,channel4_input,channel5_input,\"m322\",activation,None,optimizer)\n",
        "      print(\"New m322 model initialised\")\n",
        "    elif (model_type==\"m222\"):\n",
        "      model = CNN_3D(channel1_input,channel2_input,channel3_input,channel4_input,channel5_input,\"m222\",activation,None,optimizer)\n",
        "      print(\"New m222 model initialised\")\n",
        "    elif (model_type==\"rs332\"):\n",
        "      model = CNN_3D(channel1_input,channel2_input,channel3_input,channel4_input,channel5_input,\"rs332\",activation,None,optimizer)\n",
        "      print(\"New rs332 model initialised\")\n",
        "    elif (model_type==\"ensemble\"):\n",
        "      model = CNN_3D(channel1_input,channel2_input,channel3_input,channel4_input,channel5_input,\"ensemble\",activation,5,optimizer)\n",
        "      print(\"New ensemble model initialised\")\n",
        "\n",
        "    # Generate a print\n",
        "    print('------------------------------------------------------------------------')\n",
        "    print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "    # Fit data to model\n",
        "    if (model_type == \"rs332\"):\n",
        "      history = model.fit(\n",
        "                  {\"channel1\": M1[train], \"channel2\": M2[train], \"channel3\": M3[train],\"channel4\":M4[train],\"channel5\":M5[train]},\n",
        "                  {output_name:Y[train],\"output_spm_rs332\":spm[train]},\n",
        "                  batch_size=batch_size,\n",
        "                  epochs=no_epochs,\n",
        "                  verbose=verbosity)\n",
        "      # Generate generalization metrics\n",
        "      scores = model.evaluate({\"channel1\":M1[test],\"channel2\":M2[test],\"channel3\":M3[test],\"channel4\":M4[test],\"channel5\":M5[test]}, \n",
        "                              {output_name:Y[test],\"output_spm_rs332\":spm[test]}, \n",
        "                              verbose=0)\n",
        "      print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]};{model.metrics_names[2]} of {scores[2]};{model.metrics_names[3]} of {scores[3]}')\n",
        "      acc_per_fold.append(scores[4])\n",
        "      loss_per_fold.append(scores[1])\n",
        "      prec_per_fold.append(scores[5])\n",
        "      mse_per_fold.append(scores[3])\n",
        "    else:\n",
        "      if (model_type==\"ensemble\"):\n",
        "        output_name = \"ens_res\"\n",
        "      history = model.fit(\n",
        "                  {\"channel1\": M1[train], \"channel2\": M2[train], \"channel3\": M3[train],\"channel4\":M4[train],\"channel5\":M5[train]},\n",
        "                  {output_name:Y[train]},\n",
        "                  batch_size=batch_size,\n",
        "                  epochs=no_epochs,\n",
        "                  verbose=verbosity)\n",
        "    \n",
        "      # Generate generalization metrics\n",
        "      scores = model.evaluate({\"channel1\":M1[test],\"channel2\":M2[test],\"channel3\":M3[test],\"channel4\":M4[test],\"channel5\":M5[test]}, \n",
        "                              {output_name:Y[test]}, \n",
        "                              verbose=0)\n",
        "      print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]};{model.metrics_names[2]} of {scores[2]};{model.metrics_names[3]} of {scores[3]}')\n",
        "      acc_per_fold.append(scores[2])\n",
        "      loss_per_fold.append(scores[0])\n",
        "      prec_per_fold.append(scores[3])\n",
        "      mse_per_fold.append(scores[1])\n",
        "\n",
        "    del model\n",
        "    keras.backend.clear_session()\n",
        "\n",
        "\n",
        "    # Increase fold number\n",
        "    fold_no = fold_no + 1\n",
        "\n",
        "  # == Provide average scores ==\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print('Score per fold')\n",
        "  for i in range(0, len(acc_per_fold)):\n",
        "    print('------------------------------------------------------------------------')\n",
        "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]} - Precision: {prec_per_fold[i]}%')\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print('Average scores for all folds:')\n",
        "  print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "  print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "  print(f'> Precision: {np.mean(prec_per_fold)}')\n",
        "  print('------------------------------------------------------------------------')\n",
        "  return np.array(loss_per_fold),np.array(mse_per_fold),np.array(acc_per_fold),np.array(prec_per_fold)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Nk3sAFoxLLf"
      },
      "source": [
        "## ReLu and RMSProp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibtPRnxlxaPk"
      },
      "source": [
        "### Epochs - 30"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGMkt0KpxhBe"
      },
      "source": [
        "#### Model s332"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "S937ErMeEq1q",
        "outputId": "85e4cba6-f171-4c80-f9ee-073a4a6834d5"
      },
      "source": [
        "results_diff = {}\n",
        "loss,mse,acc,prec = kfold_validation(\"s332\",M1_ufc,M2_ufc,M3_ufc,M4_ufc,M5_ufc,Train_ufc_y,pca_SPM_cube_ufc_reloaded,32,30)\n",
        "results_diff[\"s332\"] = np.array((loss,mse,acc,prec))\n",
        "#the error has been resolved\n",
        "filename = '/content/drive/MyDrive/ML_CSP774/Theory_project/3D-CNN Activity Recognition/Pickle/s332_30epochs.pickle'\n",
        "with open(filename, 'wb') as f:\n",
        "    pickle.dump(results_diff[\"s332\"], f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "s332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New s332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 1.5721 - mse: 0.1245 - accuracy: 0.3501 - precision: 0.7538\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 1.1720 - mse: 0.0966 - accuracy: 0.5593 - precision: 0.7610\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.9811 - mse: 0.0819 - accuracy: 0.6350 - precision: 0.7663\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.8180 - mse: 0.0692 - accuracy: 0.7062 - precision: 0.8013\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.7351 - mse: 0.0616 - accuracy: 0.7226 - precision: 0.8275\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.6725 - mse: 0.0549 - accuracy: 0.7611 - precision: 0.8521\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.5774 - mse: 0.0483 - accuracy: 0.8056 - precision: 0.8604\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.5542 - mse: 0.0462 - accuracy: 0.8012 - precision: 0.8653\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.5193 - mse: 0.0429 - accuracy: 0.8398 - precision: 0.8876\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.4171 - mse: 0.0341 - accuracy: 0.8561 - precision: 0.9008\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.4107 - mse: 0.0352 - accuracy: 0.8531 - precision: 0.8987\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.3603 - mse: 0.0297 - accuracy: 0.8843 - precision: 0.9105\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.3635 - mse: 0.0310 - accuracy: 0.8680 - precision: 0.9006\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.2833 - mse: 0.0234 - accuracy: 0.9036 - precision: 0.9222\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.2809 - mse: 0.0228 - accuracy: 0.9095 - precision: 0.9260\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.2373 - mse: 0.0204 - accuracy: 0.9228 - precision: 0.9346\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.2199 - mse: 0.0197 - accuracy: 0.9199 - precision: 0.9369\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.2256 - mse: 0.0175 - accuracy: 0.9392 - precision: 0.9497\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.1948 - mse: 0.0164 - accuracy: 0.9377 - precision: 0.9399\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.1371 - mse: 0.0110 - accuracy: 0.9570 - precision: 0.9655\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.1624 - mse: 0.0139 - accuracy: 0.9466 - precision: 0.9578\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.1850 - mse: 0.0141 - accuracy: 0.9510 - precision: 0.9565\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.0827 - mse: 0.0068 - accuracy: 0.9718 - precision: 0.9761\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.1375 - mse: 0.0094 - accuracy: 0.9718 - precision: 0.9776\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.0659 - mse: 0.0053 - accuracy: 0.9837 - precision: 0.9880\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.1139 - mse: 0.0100 - accuracy: 0.9570 - precision: 0.9598\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.0452 - mse: 0.0032 - accuracy: 0.9941 - precision: 0.9941\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.0765 - mse: 0.0064 - accuracy: 0.9733 - precision: 0.9747\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.0764 - mse: 0.0069 - accuracy: 0.9718 - precision: 0.9732\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.0238 - mse: 0.0014 - accuracy: 0.9955 - precision: 0.9955\n",
            "Score for fold 1: loss of 1.7384331226348877; mse of 0.06662584096193314;accuracy of 0.7751479148864746;precision of 0.7797619104385376\n",
            "s332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New s332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 1.7138 - mse: 0.1341 - accuracy: 0.2641 - precision: 0.7500\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 1.3532 - mse: 0.1114 - accuracy: 0.4688 - precision: 0.6629\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 1.0964 - mse: 0.0902 - accuracy: 0.5950 - precision: 0.7479\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.8864 - mse: 0.0744 - accuracy: 0.6662 - precision: 0.7761\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.7768 - mse: 0.0651 - accuracy: 0.7315 - precision: 0.7970\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.6957 - mse: 0.0582 - accuracy: 0.7567 - precision: 0.8309\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.6268 - mse: 0.0535 - accuracy: 0.7804 - precision: 0.8281\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.5646 - mse: 0.0481 - accuracy: 0.7938 - precision: 0.8350\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.4939 - mse: 0.0415 - accuracy: 0.8383 - precision: 0.8735\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.4799 - mse: 0.0394 - accuracy: 0.8442 - precision: 0.8862\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.4041 - mse: 0.0343 - accuracy: 0.8591 - precision: 0.8995\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.3804 - mse: 0.0310 - accuracy: 0.8724 - precision: 0.9038\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.3050 - mse: 0.0261 - accuracy: 0.8813 - precision: 0.9060\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.3254 - mse: 0.0269 - accuracy: 0.8843 - precision: 0.9156\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.2399 - mse: 0.0201 - accuracy: 0.9214 - precision: 0.9369\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 5s 250ms/step - loss: 0.2437 - mse: 0.0197 - accuracy: 0.9243 - precision: 0.9442\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.2041 - mse: 0.0158 - accuracy: 0.9436 - precision: 0.9497\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.1865 - mse: 0.0150 - accuracy: 0.9466 - precision: 0.9605\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.1663 - mse: 0.0135 - accuracy: 0.9525 - precision: 0.9620\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.1695 - mse: 0.0139 - accuracy: 0.9525 - precision: 0.9578\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.1410 - mse: 0.0117 - accuracy: 0.9599 - precision: 0.9697\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.1292 - mse: 0.0111 - accuracy: 0.9525 - precision: 0.9594\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.0932 - mse: 0.0077 - accuracy: 0.9718 - precision: 0.9761\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.0879 - mse: 0.0072 - accuracy: 0.9733 - precision: 0.9805\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 5s 250ms/step - loss: 0.0751 - mse: 0.0066 - accuracy: 0.9733 - precision: 0.9775\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.1007 - mse: 0.0086 - accuracy: 0.9688 - precision: 0.9746\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.0531 - mse: 0.0045 - accuracy: 0.9837 - precision: 0.9866\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.0931 - mse: 0.0084 - accuracy: 0.9629 - precision: 0.9671\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.0490 - mse: 0.0042 - accuracy: 0.9881 - precision: 0.9896\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.0136 - mse: 9.5177e-04 - accuracy: 0.9941 - precision: 0.9955\n",
            "Score for fold 2: loss of 2.9706966876983643; mse of 0.10851360112428665;accuracy of 0.6331360936164856;precision of 0.6331360936164856\n",
            "s332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New s332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 1.6452 - mse: 0.1287 - accuracy: 0.3398 - precision: 0.7895\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 1.2606 - mse: 0.1025 - accuracy: 0.5104 - precision: 0.7652\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 1.0334 - mse: 0.0860 - accuracy: 0.6068 - precision: 0.7711\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.8722 - mse: 0.0733 - accuracy: 0.6766 - precision: 0.8009\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.8030 - mse: 0.0684 - accuracy: 0.7062 - precision: 0.7798\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.7121 - mse: 0.0602 - accuracy: 0.7463 - precision: 0.8366\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.6521 - mse: 0.0552 - accuracy: 0.7685 - precision: 0.8319\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.5813 - mse: 0.0494 - accuracy: 0.7967 - precision: 0.8540\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.5574 - mse: 0.0458 - accuracy: 0.8175 - precision: 0.8656\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.4848 - mse: 0.0410 - accuracy: 0.8323 - precision: 0.8744\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.4566 - mse: 0.0388 - accuracy: 0.8338 - precision: 0.8787\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.4271 - mse: 0.0369 - accuracy: 0.8516 - precision: 0.8822\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.4226 - mse: 0.0340 - accuracy: 0.8680 - precision: 0.9088\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.3398 - mse: 0.0281 - accuracy: 0.8828 - precision: 0.9152\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.3529 - mse: 0.0292 - accuracy: 0.8769 - precision: 0.9100\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.2698 - mse: 0.0229 - accuracy: 0.9050 - precision: 0.9282\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.2476 - mse: 0.0210 - accuracy: 0.9184 - precision: 0.9285\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.2718 - mse: 0.0206 - accuracy: 0.9199 - precision: 0.9462\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.2096 - mse: 0.0174 - accuracy: 0.9362 - precision: 0.9481\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.1846 - mse: 0.0153 - accuracy: 0.9377 - precision: 0.9541\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.1543 - mse: 0.0131 - accuracy: 0.9540 - precision: 0.9652\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.2046 - mse: 0.0183 - accuracy: 0.9318 - precision: 0.9391\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.1120 - mse: 0.0086 - accuracy: 0.9718 - precision: 0.9775\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.1185 - mse: 0.0101 - accuracy: 0.9659 - precision: 0.9685\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.1344 - mse: 0.0126 - accuracy: 0.9496 - precision: 0.9522\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.0807 - mse: 0.0069 - accuracy: 0.9718 - precision: 0.9761\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.1029 - mse: 0.0078 - accuracy: 0.9688 - precision: 0.9716\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.1020 - mse: 0.0087 - accuracy: 0.9703 - precision: 0.9716\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.0535 - mse: 0.0046 - accuracy: 0.9807 - precision: 0.9835\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.1091 - mse: 0.0079 - accuracy: 0.9748 - precision: 0.9748\n",
            "Score for fold 3: loss of 1.9106369018554688; mse of 0.08502800762653351;accuracy of 0.6863905191421509;precision of 0.7030302882194519\n",
            "s332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New s332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/30\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 1.7180 - mse: 0.1344 - accuracy: 0.2622 - precision: 0.5455\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 1.2853 - mse: 0.1044 - accuracy: 0.5185 - precision: 0.6940\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 1.0730 - mse: 0.0888 - accuracy: 0.5867 - precision: 0.7582\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.8962 - mse: 0.0751 - accuracy: 0.6622 - precision: 0.7667\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.8781 - mse: 0.0738 - accuracy: 0.6889 - precision: 0.7760\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.7134 - mse: 0.0606 - accuracy: 0.7407 - precision: 0.8212\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 5s 250ms/step - loss: 0.6617 - mse: 0.0569 - accuracy: 0.7570 - precision: 0.8160\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.6175 - mse: 0.0512 - accuracy: 0.7867 - precision: 0.8571\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.5499 - mse: 0.0477 - accuracy: 0.8074 - precision: 0.8476\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.4753 - mse: 0.0415 - accuracy: 0.8193 - precision: 0.8668\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.4518 - mse: 0.0373 - accuracy: 0.8444 - precision: 0.8867\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.3928 - mse: 0.0338 - accuracy: 0.8622 - precision: 0.8970\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.3843 - mse: 0.0337 - accuracy: 0.8548 - precision: 0.8768\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.3330 - mse: 0.0279 - accuracy: 0.8889 - precision: 0.9067\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.3244 - mse: 0.0273 - accuracy: 0.8874 - precision: 0.9128\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.2716 - mse: 0.0232 - accuracy: 0.8993 - precision: 0.9270\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.2385 - mse: 0.0204 - accuracy: 0.9185 - precision: 0.9384\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.1964 - mse: 0.0167 - accuracy: 0.9289 - precision: 0.9451\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.2102 - mse: 0.0181 - accuracy: 0.9274 - precision: 0.9394\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.1355 - mse: 0.0115 - accuracy: 0.9541 - precision: 0.9653\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.1417 - mse: 0.0120 - accuracy: 0.9556 - precision: 0.9610\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.1426 - mse: 0.0126 - accuracy: 0.9452 - precision: 0.9518\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.1012 - mse: 0.0084 - accuracy: 0.9674 - precision: 0.9746\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.0807 - mse: 0.0068 - accuracy: 0.9778 - precision: 0.9806\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.1020 - mse: 0.0091 - accuracy: 0.9659 - precision: 0.9729\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.0463 - mse: 0.0036 - accuracy: 0.9867 - precision: 0.9866\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.1048 - mse: 0.0082 - accuracy: 0.9704 - precision: 0.9703\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.0605 - mse: 0.0055 - accuracy: 0.9778 - precision: 0.9792\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.0555 - mse: 0.0033 - accuracy: 0.9881 - precision: 0.9881\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.1100 - mse: 0.0083 - accuracy: 0.9689 - precision: 0.9717\n",
            "Score for fold 4: loss of 2.2758970260620117; mse of 0.1011858880519867;accuracy of 0.6547619104385376;precision of 0.6566265225410461\n",
            "s332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New s332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 1.6571 - mse: 0.1306 - accuracy: 0.3289 - precision: 0.5938\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 1.1992 - mse: 0.0986 - accuracy: 0.5496 - precision: 0.7083\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.9991 - mse: 0.0837 - accuracy: 0.6193 - precision: 0.7281\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.9158 - mse: 0.0764 - accuracy: 0.6741 - precision: 0.7537\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.7803 - mse: 0.0667 - accuracy: 0.7126 - precision: 0.7741\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.7454 - mse: 0.0637 - accuracy: 0.7289 - precision: 0.8066\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.6619 - mse: 0.0573 - accuracy: 0.7600 - precision: 0.8219\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.6490 - mse: 0.0553 - accuracy: 0.7674 - precision: 0.8152\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.5780 - mse: 0.0500 - accuracy: 0.7807 - precision: 0.8408\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.5271 - mse: 0.0466 - accuracy: 0.8044 - precision: 0.8419\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.4829 - mse: 0.0424 - accuracy: 0.8281 - precision: 0.8672\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.4476 - mse: 0.0398 - accuracy: 0.8252 - precision: 0.8659\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.3959 - mse: 0.0355 - accuracy: 0.8533 - precision: 0.8790\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.3516 - mse: 0.0288 - accuracy: 0.8844 - precision: 0.9097\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.3757 - mse: 0.0329 - accuracy: 0.8593 - precision: 0.8877\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.2923 - mse: 0.0257 - accuracy: 0.8963 - precision: 0.9095\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.2373 - mse: 0.0201 - accuracy: 0.9230 - precision: 0.9357\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.2759 - mse: 0.0252 - accuracy: 0.8948 - precision: 0.9128\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.2089 - mse: 0.0180 - accuracy: 0.9289 - precision: 0.9381\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.1926 - mse: 0.0165 - accuracy: 0.9333 - precision: 0.9426\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.1947 - mse: 0.0164 - accuracy: 0.9363 - precision: 0.9486\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.1491 - mse: 0.0131 - accuracy: 0.9452 - precision: 0.9520\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.1381 - mse: 0.0104 - accuracy: 0.9644 - precision: 0.9671\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.0939 - mse: 0.0073 - accuracy: 0.9748 - precision: 0.9791\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.1583 - mse: 0.0105 - accuracy: 0.9659 - precision: 0.9687\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.0868 - mse: 0.0072 - accuracy: 0.9778 - precision: 0.9821\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.0748 - mse: 0.0060 - accuracy: 0.9793 - precision: 0.9807\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.0640 - mse: 0.0057 - accuracy: 0.9748 - precision: 0.9791\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.1339 - mse: 0.0110 - accuracy: 0.9585 - precision: 0.9585\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.0505 - mse: 0.0043 - accuracy: 0.9852 - precision: 0.9852\n",
            "Score for fold 5: loss of 1.625670075416565; mse of 0.07481256872415543;accuracy of 0.726190447807312;precision of 0.7305389046669006\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 1.7384331226348877 - Accuracy: 0.7751479148864746 - Precision: 0.7797619104385376%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 2.9706966876983643 - Accuracy: 0.6331360936164856 - Precision: 0.6331360936164856%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 1.9106369018554688 - Accuracy: 0.6863905191421509 - Precision: 0.7030302882194519%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 2.2758970260620117 - Accuracy: 0.6547619104385376 - Precision: 0.6566265225410461%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 1.625670075416565 - Accuracy: 0.726190447807312 - Precision: 0.7305389046669006%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 0.6951253771781921 (+- 0.05082681108059476)\n",
            "> Loss: 2.1042667627334595\n",
            "> Precision: 0.7006187438964844\n",
            "------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-25853dc267b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresults_diff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkfold_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"s332\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mM1_ufc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mM2_ufc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mM3_ufc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mM4_ufc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mM5_ufc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTrain_ufc_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpca_SPM_cube_ufc_reloaded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresults_diff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"s332\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: only 2 non-keyword arguments accepted"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UrCAxl2xm0s"
      },
      "source": [
        "#### Model m332"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZdRmCuUKEw4",
        "outputId": "6ff8cf91-5dc5-400a-cb4c-240b78a1cf0e"
      },
      "source": [
        "loss,mse,acc,prec = kfold_validation(\"m332\",M1_ufc,M2_ufc,M3_ufc,M4_ufc,M5_ufc,Train_ufc_y,pca_SPM_cube_ufc_reloaded,32,30)\n",
        "results_diff[\"m332\"] = np.array((loss,mse,acc,prec))\n",
        "filename = '/content/drive/MyDrive/ML_CSP774/Theory_project/3D-CNN Activity Recognition/Pickle/m332_30epochs.pickle'\n",
        "with open(filename, 'wb') as f:\n",
        "    pickle.dump(results_diff[\"m332\"], f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "m332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 12, 18, 12) (None, 6, 10, 18, 12)\n",
            "(None, 6, 27, 6, 4)\n",
            "(None, 6, 27, 1, 1)\n",
            "(None, 162)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 1.5291 - mse: 0.1214 - accuracy: 0.4065 - precision: 0.6875\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 1.0734 - mse: 0.0879 - accuracy: 0.6128 - precision: 0.7647\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.8945 - mse: 0.0756 - accuracy: 0.6691 - precision: 0.7630\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.7990 - mse: 0.0688 - accuracy: 0.6840 - precision: 0.7881\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.7132 - mse: 0.0620 - accuracy: 0.7196 - precision: 0.7941\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.6364 - mse: 0.0546 - accuracy: 0.7626 - precision: 0.8407\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.6126 - mse: 0.0536 - accuracy: 0.7671 - precision: 0.8187\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.5515 - mse: 0.0471 - accuracy: 0.8056 - precision: 0.8440\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.5309 - mse: 0.0467 - accuracy: 0.7997 - precision: 0.8428\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.4812 - mse: 0.0406 - accuracy: 0.8457 - precision: 0.8764\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.4464 - mse: 0.0395 - accuracy: 0.8323 - precision: 0.8681\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.4316 - mse: 0.0380 - accuracy: 0.8501 - precision: 0.8810\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.3879 - mse: 0.0346 - accuracy: 0.8620 - precision: 0.8901\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.3753 - mse: 0.0329 - accuracy: 0.8650 - precision: 0.9010\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.3306 - mse: 0.0289 - accuracy: 0.8783 - precision: 0.8991\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.3182 - mse: 0.0281 - accuracy: 0.8813 - precision: 0.8983\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.2941 - mse: 0.0271 - accuracy: 0.8813 - precision: 0.9092\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.2932 - mse: 0.0264 - accuracy: 0.8872 - precision: 0.9062\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.2265 - mse: 0.0198 - accuracy: 0.9273 - precision: 0.9429\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.2410 - mse: 0.0220 - accuracy: 0.9080 - precision: 0.9207\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.2450 - mse: 0.0220 - accuracy: 0.9036 - precision: 0.9193\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.1975 - mse: 0.0176 - accuracy: 0.9303 - precision: 0.9452\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.1840 - mse: 0.0164 - accuracy: 0.9318 - precision: 0.9438\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.1781 - mse: 0.0150 - accuracy: 0.9421 - precision: 0.9501\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.1560 - mse: 0.0140 - accuracy: 0.9451 - precision: 0.9534\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.1604 - mse: 0.0153 - accuracy: 0.9318 - precision: 0.9398\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.1143 - mse: 0.0106 - accuracy: 0.9555 - precision: 0.9565\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 5s 243ms/step - loss: 0.1099 - mse: 0.0098 - accuracy: 0.9599 - precision: 0.9699\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.1371 - mse: 0.0120 - accuracy: 0.9481 - precision: 0.9562\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.0861 - mse: 0.0069 - accuracy: 0.9718 - precision: 0.9776\n",
            "Score for fold 1: loss of 1.7556864023208618; mse of 0.09262871742248535;accuracy of 0.6745561957359314;precision of 0.6871165633201599\n",
            "m332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 12, 18, 12) (None, 6, 10, 18, 12)\n",
            "(None, 6, 27, 6, 4)\n",
            "(None, 6, 27, 1, 1)\n",
            "(None, 162)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/30\n",
            "22/22 [==============================] - 5s 243ms/step - loss: 1.7651 - mse: 0.1373 - accuracy: 0.2389 - precision: 0.0000e+00\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 1.5387 - mse: 0.1219 - accuracy: 0.3650 - precision: 0.7532\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 1.2586 - mse: 0.1022 - accuracy: 0.5252 - precision: 0.7406\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 1.0522 - mse: 0.0889 - accuracy: 0.5964 - precision: 0.7207\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.8948 - mse: 0.0753 - accuracy: 0.6751 - precision: 0.7599\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.8162 - mse: 0.0700 - accuracy: 0.7107 - precision: 0.7868\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.7033 - mse: 0.0594 - accuracy: 0.7478 - precision: 0.8395\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.6323 - mse: 0.0544 - accuracy: 0.7745 - precision: 0.8423\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.5948 - mse: 0.0509 - accuracy: 0.8056 - precision: 0.8564\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.5388 - mse: 0.0463 - accuracy: 0.8101 - precision: 0.8702\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.4924 - mse: 0.0419 - accuracy: 0.8338 - precision: 0.8832\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.4462 - mse: 0.0380 - accuracy: 0.8576 - precision: 0.8929\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.4315 - mse: 0.0376 - accuracy: 0.8323 - precision: 0.8710\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.3735 - mse: 0.0316 - accuracy: 0.8798 - precision: 0.9156\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.3501 - mse: 0.0291 - accuracy: 0.8872 - precision: 0.9111\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.3581 - mse: 0.0307 - accuracy: 0.8843 - precision: 0.9062\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.3335 - mse: 0.0283 - accuracy: 0.9006 - precision: 0.9172\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.2581 - mse: 0.0219 - accuracy: 0.9184 - precision: 0.9346\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.2729 - mse: 0.0241 - accuracy: 0.8991 - precision: 0.9141\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.2504 - mse: 0.0210 - accuracy: 0.9214 - precision: 0.9311\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.2217 - mse: 0.0190 - accuracy: 0.9273 - precision: 0.9431\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.2026 - mse: 0.0172 - accuracy: 0.9303 - precision: 0.9407\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.1844 - mse: 0.0159 - accuracy: 0.9407 - precision: 0.9457\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.1769 - mse: 0.0144 - accuracy: 0.9451 - precision: 0.9544\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 5s 243ms/step - loss: 0.1868 - mse: 0.0148 - accuracy: 0.9525 - precision: 0.9549\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.1252 - mse: 0.0104 - accuracy: 0.9629 - precision: 0.9656\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.1395 - mse: 0.0119 - accuracy: 0.9570 - precision: 0.9609\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 5s 243ms/step - loss: 0.1084 - mse: 0.0093 - accuracy: 0.9614 - precision: 0.9713\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 5s 243ms/step - loss: 0.1041 - mse: 0.0089 - accuracy: 0.9659 - precision: 0.9687\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.1310 - mse: 0.0118 - accuracy: 0.9510 - precision: 0.9537\n",
            "Score for fold 2: loss of 1.6139495372772217; mse of 0.07562210410833359;accuracy of 0.715976357460022;precision of 0.7345678806304932\n",
            "m332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 12, 18, 12) (None, 6, 10, 18, 12)\n",
            "(None, 6, 27, 6, 4)\n",
            "(None, 6, 27, 1, 1)\n",
            "(None, 162)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 1.6338 - mse: 0.1293 - accuracy: 0.3116 - precision: 0.6512\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 1.3435 - mse: 0.1099 - accuracy: 0.4866 - precision: 0.6157\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 1.1017 - mse: 0.0913 - accuracy: 0.5905 - precision: 0.7211\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.9868 - mse: 0.0820 - accuracy: 0.6469 - precision: 0.7749\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.9063 - mse: 0.0756 - accuracy: 0.6899 - precision: 0.7773\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.7989 - mse: 0.0676 - accuracy: 0.7047 - precision: 0.7917\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.7357 - mse: 0.0627 - accuracy: 0.7315 - precision: 0.8152\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.7194 - mse: 0.0607 - accuracy: 0.7404 - precision: 0.7870\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.6498 - mse: 0.0552 - accuracy: 0.7656 - precision: 0.8290\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.6400 - mse: 0.0549 - accuracy: 0.7671 - precision: 0.8240\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.5915 - mse: 0.0508 - accuracy: 0.7804 - precision: 0.8294\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.5467 - mse: 0.0471 - accuracy: 0.8131 - precision: 0.8601\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.5194 - mse: 0.0441 - accuracy: 0.8131 - precision: 0.8536\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.5075 - mse: 0.0426 - accuracy: 0.8323 - precision: 0.8663\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.4622 - mse: 0.0401 - accuracy: 0.8398 - precision: 0.8669\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.4266 - mse: 0.0367 - accuracy: 0.8398 - precision: 0.8730\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.4405 - mse: 0.0381 - accuracy: 0.8472 - precision: 0.8714\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.3744 - mse: 0.0328 - accuracy: 0.8546 - precision: 0.8926\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.3893 - mse: 0.0330 - accuracy: 0.8680 - precision: 0.8926\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.3278 - mse: 0.0269 - accuracy: 0.9021 - precision: 0.9154\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.3342 - mse: 0.0295 - accuracy: 0.8813 - precision: 0.8949\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.2925 - mse: 0.0241 - accuracy: 0.9065 - precision: 0.9270\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.2659 - mse: 0.0235 - accuracy: 0.9080 - precision: 0.9213\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.2673 - mse: 0.0227 - accuracy: 0.9065 - precision: 0.9307\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.2238 - mse: 0.0199 - accuracy: 0.9214 - precision: 0.9398\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.2464 - mse: 0.0205 - accuracy: 0.9273 - precision: 0.9362\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.2083 - mse: 0.0178 - accuracy: 0.9288 - precision: 0.9379\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.1956 - mse: 0.0170 - accuracy: 0.9362 - precision: 0.9455\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.1224 - mse: 0.0096 - accuracy: 0.9644 - precision: 0.9714\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.1678 - mse: 0.0140 - accuracy: 0.9466 - precision: 0.9619\n",
            "Score for fold 3: loss of 1.3932883739471436; mse of 0.08638124912977219;accuracy of 0.692307710647583;precision of 0.688622772693634\n",
            "m332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 12, 18, 12) (None, 6, 10, 18, 12)\n",
            "(None, 6, 27, 6, 4)\n",
            "(None, 6, 27, 1, 1)\n",
            "(None, 162)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 1.6184 - mse: 0.1276 - accuracy: 0.3511 - precision: 0.7353\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 1.1684 - mse: 0.0964 - accuracy: 0.5600 - precision: 0.7207\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 1.0029 - mse: 0.0848 - accuracy: 0.6281 - precision: 0.7340\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.9078 - mse: 0.0759 - accuracy: 0.6844 - precision: 0.7739\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.8690 - mse: 0.0730 - accuracy: 0.6770 - precision: 0.7582\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.7776 - mse: 0.0659 - accuracy: 0.7141 - precision: 0.8007\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.7083 - mse: 0.0604 - accuracy: 0.7319 - precision: 0.8183\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.6878 - mse: 0.0588 - accuracy: 0.7467 - precision: 0.8166\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.6122 - mse: 0.0521 - accuracy: 0.7926 - precision: 0.8404\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.5708 - mse: 0.0468 - accuracy: 0.8119 - precision: 0.8583\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.5354 - mse: 0.0461 - accuracy: 0.8000 - precision: 0.8539\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.5087 - mse: 0.0423 - accuracy: 0.8341 - precision: 0.8690\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.4652 - mse: 0.0408 - accuracy: 0.8207 - precision: 0.8645\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.4364 - mse: 0.0374 - accuracy: 0.8444 - precision: 0.8728\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.4232 - mse: 0.0365 - accuracy: 0.8459 - precision: 0.8804\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.3795 - mse: 0.0320 - accuracy: 0.8607 - precision: 0.9013\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.3346 - mse: 0.0291 - accuracy: 0.8711 - precision: 0.9003\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.3590 - mse: 0.0294 - accuracy: 0.8874 - precision: 0.9102\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.2969 - mse: 0.0257 - accuracy: 0.8948 - precision: 0.9140\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.2734 - mse: 0.0237 - accuracy: 0.8919 - precision: 0.9178\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.2921 - mse: 0.0262 - accuracy: 0.8889 - precision: 0.9106\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.2066 - mse: 0.0170 - accuracy: 0.9289 - precision: 0.9452\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.2761 - mse: 0.0245 - accuracy: 0.8978 - precision: 0.9194\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.2084 - mse: 0.0172 - accuracy: 0.9319 - precision: 0.9439\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.2007 - mse: 0.0173 - accuracy: 0.9274 - precision: 0.9423\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.1957 - mse: 0.0166 - accuracy: 0.9348 - precision: 0.9455\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.1819 - mse: 0.0154 - accuracy: 0.9467 - precision: 0.9530\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.1432 - mse: 0.0123 - accuracy: 0.9452 - precision: 0.9548\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.1930 - mse: 0.0163 - accuracy: 0.9407 - precision: 0.9459\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.1133 - mse: 0.0098 - accuracy: 0.9615 - precision: 0.9669\n",
            "Score for fold 4: loss of 1.5320684909820557; mse of 0.08375922590494156;accuracy of 0.6904761791229248;precision of 0.7030302882194519\n",
            "m332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 12, 18, 12) (None, 6, 10, 18, 12)\n",
            "(None, 6, 27, 6, 4)\n",
            "(None, 6, 27, 1, 1)\n",
            "(None, 162)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 1.7106 - mse: 0.1342 - accuracy: 0.2711 - precision: 0.5000\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 1.2704 - mse: 0.1050 - accuracy: 0.5096 - precision: 0.6833\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.9624 - mse: 0.0799 - accuracy: 0.6622 - precision: 0.7767\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.8800 - mse: 0.0746 - accuracy: 0.6681 - precision: 0.7515\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.7637 - mse: 0.0660 - accuracy: 0.7126 - precision: 0.7833\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.7314 - mse: 0.0629 - accuracy: 0.7393 - precision: 0.7946\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.6180 - mse: 0.0533 - accuracy: 0.7733 - precision: 0.8316\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.6302 - mse: 0.0533 - accuracy: 0.7867 - precision: 0.8394\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.5789 - mse: 0.0509 - accuracy: 0.7719 - precision: 0.8361\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.5142 - mse: 0.0446 - accuracy: 0.8059 - precision: 0.8494\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.5297 - mse: 0.0467 - accuracy: 0.8044 - precision: 0.8336\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.4794 - mse: 0.0414 - accuracy: 0.8311 - precision: 0.8655\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.4459 - mse: 0.0383 - accuracy: 0.8444 - precision: 0.8740\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.4093 - mse: 0.0343 - accuracy: 0.8548 - precision: 0.8882\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.3854 - mse: 0.0333 - accuracy: 0.8726 - precision: 0.8906\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.3839 - mse: 0.0338 - accuracy: 0.8504 - precision: 0.8919\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.3537 - mse: 0.0317 - accuracy: 0.8637 - precision: 0.8891\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.3292 - mse: 0.0297 - accuracy: 0.8785 - precision: 0.9017\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.2792 - mse: 0.0244 - accuracy: 0.8919 - precision: 0.9134\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.2687 - mse: 0.0243 - accuracy: 0.8948 - precision: 0.9141\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.2760 - mse: 0.0247 - accuracy: 0.9022 - precision: 0.9152\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.2451 - mse: 0.0217 - accuracy: 0.9200 - precision: 0.9294\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.2497 - mse: 0.0211 - accuracy: 0.9185 - precision: 0.9314\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.2111 - mse: 0.0192 - accuracy: 0.9215 - precision: 0.9318\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.2076 - mse: 0.0188 - accuracy: 0.9200 - precision: 0.9319\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.2057 - mse: 0.0186 - accuracy: 0.9230 - precision: 0.9392\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.1581 - mse: 0.0136 - accuracy: 0.9422 - precision: 0.9548\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.1574 - mse: 0.0144 - accuracy: 0.9393 - precision: 0.9459\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.1721 - mse: 0.0145 - accuracy: 0.9348 - precision: 0.9531\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.1320 - mse: 0.0114 - accuracy: 0.9556 - precision: 0.9639\n",
            "Score for fold 5: loss of 1.4543721675872803; mse of 0.07239294052124023;accuracy of 0.738095223903656;precision of 0.75\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 1.7556864023208618 - Accuracy: 0.6745561957359314 - Precision: 0.6871165633201599%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 1.6139495372772217 - Accuracy: 0.715976357460022 - Precision: 0.7345678806304932%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 1.3932883739471436 - Accuracy: 0.692307710647583 - Precision: 0.688622772693634%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 1.5320684909820557 - Accuracy: 0.6904761791229248 - Precision: 0.7030302882194519%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 1.4543721675872803 - Accuracy: 0.738095223903656 - Precision: 0.75%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 0.7022823333740235 (+- 0.02226075698990191)\n",
            "> Loss: 1.5498729944229126\n",
            "> Precision: 0.7126675009727478\n",
            "------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMus734HRih-"
      },
      "source": [
        "keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMaxCh06x8ak"
      },
      "source": [
        "#### Model m322"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqPJoJyQRfdq",
        "outputId": "19ee4611-69ee-4fe0-c53d-0a55e6f286e5"
      },
      "source": [
        "loss,mse,acc,prec = kfold_validation(\"m322\",M1_ufc,M2_ufc,M3_ufc,M4_ufc,M5_ufc,Train_ufc_y,pca_SPM_cube_ufc_reloaded,32,30)\n",
        "results_diff[\"m322\"] = np.array((loss,mse,acc,prec))\n",
        "filename = '/content/drive/MyDrive/ML_CSP774/Theory_project/3D-CNN Activity Recognition/Pickle/m322_30epochs.pickle'\n",
        "with open(filename, 'wb') as f:\n",
        "    pickle.dump(results_diff[\"m322\"], f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "m322\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 7, 18, 12) (None, 6, 14, 18, 12) (None, 6, 12, 18, 12)\n",
            "(None, 6, 33, 6, 4)\n",
            "(None, 6, 33, 1, 1)\n",
            "(None, 198)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m322 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 1.6948 - mse: 0.1332 - accuracy: 0.2493 - precision: 0.6000\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 5s 242ms/step - loss: 1.3275 - mse: 0.1105 - accuracy: 0.4540 - precision: 0.6726\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 1.1646 - mse: 0.0980 - accuracy: 0.5564 - precision: 0.6677\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 5s 239ms/step - loss: 0.9849 - mse: 0.0855 - accuracy: 0.6157 - precision: 0.7188\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.8990 - mse: 0.0780 - accuracy: 0.6766 - precision: 0.7406\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.7710 - mse: 0.0673 - accuracy: 0.7181 - precision: 0.7769\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.7679 - mse: 0.0668 - accuracy: 0.7122 - precision: 0.7729\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 5s 239ms/step - loss: 0.6801 - mse: 0.0583 - accuracy: 0.7656 - precision: 0.8147\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 5s 239ms/step - loss: 0.5980 - mse: 0.0519 - accuracy: 0.7789 - precision: 0.8299\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.5512 - mse: 0.0481 - accuracy: 0.8042 - precision: 0.8393\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 5s 239ms/step - loss: 0.5120 - mse: 0.0444 - accuracy: 0.8190 - precision: 0.8502\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 5s 238ms/step - loss: 0.5001 - mse: 0.0425 - accuracy: 0.8353 - precision: 0.8627\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 5s 239ms/step - loss: 0.4777 - mse: 0.0423 - accuracy: 0.8205 - precision: 0.8512\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.4298 - mse: 0.0375 - accuracy: 0.8368 - precision: 0.8639\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 5s 238ms/step - loss: 0.4225 - mse: 0.0355 - accuracy: 0.8472 - precision: 0.8841\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 5s 238ms/step - loss: 0.3949 - mse: 0.0346 - accuracy: 0.8650 - precision: 0.8809\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.3352 - mse: 0.0289 - accuracy: 0.8902 - precision: 0.9142\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.3461 - mse: 0.0307 - accuracy: 0.8739 - precision: 0.8870\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.3062 - mse: 0.0274 - accuracy: 0.8843 - precision: 0.9043\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 5s 239ms/step - loss: 0.2744 - mse: 0.0230 - accuracy: 0.9021 - precision: 0.9268\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 5s 239ms/step - loss: 0.2997 - mse: 0.0257 - accuracy: 0.8991 - precision: 0.9148\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.2744 - mse: 0.0223 - accuracy: 0.9169 - precision: 0.9297\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 5s 239ms/step - loss: 0.2204 - mse: 0.0195 - accuracy: 0.9199 - precision: 0.9288\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 5s 238ms/step - loss: 0.2443 - mse: 0.0213 - accuracy: 0.9154 - precision: 0.9298\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.1933 - mse: 0.0180 - accuracy: 0.9214 - precision: 0.9361\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.1755 - mse: 0.0155 - accuracy: 0.9362 - precision: 0.9442\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 5s 238ms/step - loss: 0.1693 - mse: 0.0153 - accuracy: 0.9436 - precision: 0.9503\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 5s 239ms/step - loss: 0.1639 - mse: 0.0152 - accuracy: 0.9407 - precision: 0.9489\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.1489 - mse: 0.0125 - accuracy: 0.9525 - precision: 0.9549\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 5s 239ms/step - loss: 0.1418 - mse: 0.0123 - accuracy: 0.9481 - precision: 0.9591\n",
            "Score for fold 1: loss of 1.5167407989501953; mse of 0.08541694283485413;accuracy of 0.7041420340538025;precision of 0.7037037014961243\n",
            "m322\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 7, 18, 12) (None, 6, 14, 18, 12) (None, 6, 12, 18, 12)\n",
            "(None, 6, 33, 6, 4)\n",
            "(None, 6, 33, 1, 1)\n",
            "(None, 198)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m322 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/30\n",
            "22/22 [==============================] - 5s 237ms/step - loss: 1.5962 - mse: 0.1258 - accuracy: 0.3338 - precision: 0.6190\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 1.1290 - mse: 0.0936 - accuracy: 0.5727 - precision: 0.7638\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 5s 239ms/step - loss: 0.9292 - mse: 0.0774 - accuracy: 0.6810 - precision: 0.7966\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.8605 - mse: 0.0741 - accuracy: 0.6617 - precision: 0.7526\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.7428 - mse: 0.0629 - accuracy: 0.7433 - precision: 0.8173\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 5s 243ms/step - loss: 0.7053 - mse: 0.0610 - accuracy: 0.7478 - precision: 0.7961\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 5s 239ms/step - loss: 0.6342 - mse: 0.0528 - accuracy: 0.7834 - precision: 0.8556\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.6162 - mse: 0.0530 - accuracy: 0.7730 - precision: 0.8302\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 5s 239ms/step - loss: 0.5620 - mse: 0.0472 - accuracy: 0.8042 - precision: 0.8601\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.5734 - mse: 0.0480 - accuracy: 0.8042 - precision: 0.8436\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 5s 239ms/step - loss: 0.4884 - mse: 0.0425 - accuracy: 0.8205 - precision: 0.8532\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 5s 239ms/step - loss: 0.4534 - mse: 0.0378 - accuracy: 0.8546 - precision: 0.8969\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.4665 - mse: 0.0401 - accuracy: 0.8368 - precision: 0.8832\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.4110 - mse: 0.0339 - accuracy: 0.8605 - precision: 0.9066\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.3970 - mse: 0.0323 - accuracy: 0.8769 - precision: 0.9054\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.3936 - mse: 0.0336 - accuracy: 0.8680 - precision: 0.8882\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.3515 - mse: 0.0311 - accuracy: 0.8739 - precision: 0.9009\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 5s 238ms/step - loss: 0.3257 - mse: 0.0264 - accuracy: 0.9006 - precision: 0.9190\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 5s 239ms/step - loss: 0.3062 - mse: 0.0254 - accuracy: 0.9065 - precision: 0.9206\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.3064 - mse: 0.0263 - accuracy: 0.8917 - precision: 0.9112\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.2768 - mse: 0.0225 - accuracy: 0.9154 - precision: 0.9281\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.2528 - mse: 0.0224 - accuracy: 0.9036 - precision: 0.9215\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.2472 - mse: 0.0211 - accuracy: 0.9095 - precision: 0.9235\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 5s 239ms/step - loss: 0.2007 - mse: 0.0168 - accuracy: 0.9347 - precision: 0.9494\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 5s 238ms/step - loss: 0.2168 - mse: 0.0182 - accuracy: 0.9273 - precision: 0.9451\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 5s 239ms/step - loss: 0.1776 - mse: 0.0153 - accuracy: 0.9347 - precision: 0.9495\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 5s 238ms/step - loss: 0.1770 - mse: 0.0152 - accuracy: 0.9421 - precision: 0.9528\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 5s 238ms/step - loss: 0.1679 - mse: 0.0130 - accuracy: 0.9555 - precision: 0.9680\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 5s 238ms/step - loss: 0.1787 - mse: 0.0152 - accuracy: 0.9407 - precision: 0.9501\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 5s 239ms/step - loss: 0.1419 - mse: 0.0123 - accuracy: 0.9510 - precision: 0.9577\n",
            "Score for fold 2: loss of 1.5587483644485474; mse of 0.07974398136138916;accuracy of 0.7218934893608093;precision of 0.7289156913757324\n",
            "m322\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 7, 18, 12) (None, 6, 14, 18, 12) (None, 6, 12, 18, 12)\n",
            "(None, 6, 33, 6, 4)\n",
            "(None, 6, 33, 1, 1)\n",
            "(None, 198)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m322 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/30\n",
            "22/22 [==============================] - 5s 238ms/step - loss: 1.6944 - mse: 0.1325 - accuracy: 0.3027 - precision: 0.7500\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 5s 238ms/step - loss: 1.3888 - mse: 0.1123 - accuracy: 0.4525 - precision: 0.7355\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 5s 239ms/step - loss: 1.1407 - mse: 0.0943 - accuracy: 0.5682 - precision: 0.7327\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 5s 239ms/step - loss: 1.0189 - mse: 0.0850 - accuracy: 0.6306 - precision: 0.7696\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.9234 - mse: 0.0786 - accuracy: 0.6424 - precision: 0.7505\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.8700 - mse: 0.0743 - accuracy: 0.6721 - precision: 0.7874\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 5s 239ms/step - loss: 0.8022 - mse: 0.0693 - accuracy: 0.7092 - precision: 0.7760\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.7422 - mse: 0.0643 - accuracy: 0.7151 - precision: 0.8129\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.7101 - mse: 0.0616 - accuracy: 0.7315 - precision: 0.8226\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.6663 - mse: 0.0582 - accuracy: 0.7478 - precision: 0.8101\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.6673 - mse: 0.0562 - accuracy: 0.7611 - precision: 0.8156\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 5s 242ms/step - loss: 0.5932 - mse: 0.0515 - accuracy: 0.7849 - precision: 0.8333\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.5510 - mse: 0.0460 - accuracy: 0.8160 - precision: 0.8583\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.5410 - mse: 0.0467 - accuracy: 0.8027 - precision: 0.8497\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.4727 - mse: 0.0410 - accuracy: 0.8264 - precision: 0.8663\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 5s 239ms/step - loss: 0.4648 - mse: 0.0390 - accuracy: 0.8398 - precision: 0.8801\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.4489 - mse: 0.0390 - accuracy: 0.8190 - precision: 0.8592\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.3945 - mse: 0.0328 - accuracy: 0.8620 - precision: 0.8928\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.3859 - mse: 0.0324 - accuracy: 0.8769 - precision: 0.9000\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.3379 - mse: 0.0289 - accuracy: 0.8887 - precision: 0.9104\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.3039 - mse: 0.0265 - accuracy: 0.8887 - precision: 0.9107\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 5s 239ms/step - loss: 0.3014 - mse: 0.0253 - accuracy: 0.9006 - precision: 0.9261\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 5s 239ms/step - loss: 0.2782 - mse: 0.0241 - accuracy: 0.9125 - precision: 0.9256\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 5s 239ms/step - loss: 0.2586 - mse: 0.0215 - accuracy: 0.9139 - precision: 0.9254\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 5s 239ms/step - loss: 0.2224 - mse: 0.0197 - accuracy: 0.9154 - precision: 0.9293\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 5s 238ms/step - loss: 0.2396 - mse: 0.0193 - accuracy: 0.9318 - precision: 0.9432\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 5s 239ms/step - loss: 0.2116 - mse: 0.0180 - accuracy: 0.9273 - precision: 0.9365\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.2256 - mse: 0.0165 - accuracy: 0.9451 - precision: 0.9530\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.1555 - mse: 0.0124 - accuracy: 0.9540 - precision: 0.9610\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.1858 - mse: 0.0157 - accuracy: 0.9481 - precision: 0.9546\n",
            "Score for fold 3: loss of 1.006239891052246; mse of 0.06982029974460602;accuracy of 0.7278106212615967;precision of 0.7423312664031982\n",
            "m322\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 7, 18, 12) (None, 6, 14, 18, 12) (None, 6, 12, 18, 12)\n",
            "(None, 6, 33, 6, 4)\n",
            "(None, 6, 33, 1, 1)\n",
            "(None, 198)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m322 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/30\n",
            "22/22 [==============================] - 5s 243ms/step - loss: 1.6208 - mse: 0.1284 - accuracy: 0.3348 - precision: 0.6389\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 5s 239ms/step - loss: 1.2176 - mse: 0.1003 - accuracy: 0.5437 - precision: 0.6656\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 5s 239ms/step - loss: 1.0318 - mse: 0.0875 - accuracy: 0.6148 - precision: 0.7176\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.9185 - mse: 0.0772 - accuracy: 0.6785 - precision: 0.7570\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 5s 239ms/step - loss: 0.8594 - mse: 0.0720 - accuracy: 0.7067 - precision: 0.7798\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 5s 242ms/step - loss: 0.7621 - mse: 0.0633 - accuracy: 0.7467 - precision: 0.8137\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.7244 - mse: 0.0610 - accuracy: 0.7467 - precision: 0.8240\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.6807 - mse: 0.0575 - accuracy: 0.7541 - precision: 0.8255\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 5s 238ms/step - loss: 0.6257 - mse: 0.0527 - accuracy: 0.7852 - precision: 0.8310\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.5699 - mse: 0.0477 - accuracy: 0.8089 - precision: 0.8555\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 5s 243ms/step - loss: 0.5313 - mse: 0.0457 - accuracy: 0.8030 - precision: 0.8496\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.5068 - mse: 0.0426 - accuracy: 0.8400 - precision: 0.8587\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.4807 - mse: 0.0405 - accuracy: 0.8311 - precision: 0.8667\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 5s 239ms/step - loss: 0.4448 - mse: 0.0388 - accuracy: 0.8474 - precision: 0.8724\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.4287 - mse: 0.0371 - accuracy: 0.8489 - precision: 0.8758\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 5s 238ms/step - loss: 0.3751 - mse: 0.0320 - accuracy: 0.8681 - precision: 0.8880\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 5s 239ms/step - loss: 0.3678 - mse: 0.0316 - accuracy: 0.8667 - precision: 0.8939\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.3332 - mse: 0.0293 - accuracy: 0.8726 - precision: 0.9017\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.3155 - mse: 0.0280 - accuracy: 0.8785 - precision: 0.9039\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.2880 - mse: 0.0251 - accuracy: 0.9067 - precision: 0.9244\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.2574 - mse: 0.0226 - accuracy: 0.9081 - precision: 0.9230\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 5s 239ms/step - loss: 0.2303 - mse: 0.0194 - accuracy: 0.9200 - precision: 0.9413\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 5s 239ms/step - loss: 0.2368 - mse: 0.0210 - accuracy: 0.9052 - precision: 0.9152\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.2246 - mse: 0.0194 - accuracy: 0.9244 - precision: 0.9346\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.1640 - mse: 0.0139 - accuracy: 0.9452 - precision: 0.9590\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.1936 - mse: 0.0160 - accuracy: 0.9467 - precision: 0.9545\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.1552 - mse: 0.0131 - accuracy: 0.9452 - precision: 0.9563\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.1223 - mse: 0.0095 - accuracy: 0.9659 - precision: 0.9760\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.1437 - mse: 0.0119 - accuracy: 0.9585 - precision: 0.9712\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 5s 238ms/step - loss: 0.1094 - mse: 0.0092 - accuracy: 0.9659 - precision: 0.9686\n",
            "Score for fold 4: loss of 1.4128167629241943; mse of 0.08627058565616608;accuracy of 0.6607142686843872;precision of 0.6666666865348816\n",
            "m322\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 7, 18, 12) (None, 6, 14, 18, 12) (None, 6, 12, 18, 12)\n",
            "(None, 6, 33, 6, 4)\n",
            "(None, 6, 33, 1, 1)\n",
            "(None, 198)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m322 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/30\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 1.6634 - mse: 0.1308 - accuracy: 0.3244 - precision: 0.5667\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 5s 239ms/step - loss: 1.2560 - mse: 0.1013 - accuracy: 0.5526 - precision: 0.7688\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 1.0323 - mse: 0.0854 - accuracy: 0.6326 - precision: 0.7582\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.9218 - mse: 0.0779 - accuracy: 0.6459 - precision: 0.7658\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.8646 - mse: 0.0717 - accuracy: 0.6785 - precision: 0.8000\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.7742 - mse: 0.0641 - accuracy: 0.7259 - precision: 0.8160\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.7042 - mse: 0.0586 - accuracy: 0.7541 - precision: 0.8305\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.6618 - mse: 0.0553 - accuracy: 0.7570 - precision: 0.8354\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.6224 - mse: 0.0517 - accuracy: 0.7852 - precision: 0.8464\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.5732 - mse: 0.0472 - accuracy: 0.7941 - precision: 0.8501\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.5169 - mse: 0.0445 - accuracy: 0.8074 - precision: 0.8424\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.5024 - mse: 0.0434 - accuracy: 0.8089 - precision: 0.8664\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.4522 - mse: 0.0380 - accuracy: 0.8504 - precision: 0.9020\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.4365 - mse: 0.0368 - accuracy: 0.8430 - precision: 0.8929\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.4040 - mse: 0.0357 - accuracy: 0.8444 - precision: 0.8746\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.3803 - mse: 0.0329 - accuracy: 0.8548 - precision: 0.8833\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.3669 - mse: 0.0307 - accuracy: 0.8667 - precision: 0.9039\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.3423 - mse: 0.0275 - accuracy: 0.8889 - precision: 0.9122\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.2974 - mse: 0.0252 - accuracy: 0.8963 - precision: 0.9264\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.2709 - mse: 0.0230 - accuracy: 0.9022 - precision: 0.9287\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.2586 - mse: 0.0215 - accuracy: 0.9096 - precision: 0.9278\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.2486 - mse: 0.0204 - accuracy: 0.9170 - precision: 0.9346\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 5s 242ms/step - loss: 0.2229 - mse: 0.0185 - accuracy: 0.9244 - precision: 0.9392\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.2115 - mse: 0.0176 - accuracy: 0.9259 - precision: 0.9452\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.2027 - mse: 0.0175 - accuracy: 0.9259 - precision: 0.9359\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.1756 - mse: 0.0148 - accuracy: 0.9437 - precision: 0.9559\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.1639 - mse: 0.0143 - accuracy: 0.9378 - precision: 0.9560\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.1600 - mse: 0.0138 - accuracy: 0.9511 - precision: 0.9579\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.1327 - mse: 0.0110 - accuracy: 0.9570 - precision: 0.9682\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.1499 - mse: 0.0127 - accuracy: 0.9481 - precision: 0.9535\n",
            "Score for fold 5: loss of 1.1446149349212646; mse of 0.08041978627443314;accuracy of 0.7023809552192688;precision of 0.7195122241973877\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 1.5167407989501953 - Accuracy: 0.7041420340538025 - Precision: 0.7037037014961243%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 1.5587483644485474 - Accuracy: 0.7218934893608093 - Precision: 0.7289156913757324%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 1.006239891052246 - Accuracy: 0.7278106212615967 - Precision: 0.7423312664031982%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 1.4128167629241943 - Accuracy: 0.6607142686843872 - Precision: 0.6666666865348816%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 1.1446149349212646 - Accuracy: 0.7023809552192688 - Precision: 0.7195122241973877%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 0.7033882737159729 (+- 0.023501266418376788)\n",
            "> Loss: 1.3278321504592896\n",
            "> Precision: 0.7122259140014648\n",
            "------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upsqjA5nyAws"
      },
      "source": [
        "#### Model m222 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "061RwK_4VQxy",
        "outputId": "aa7a3326-be06-4fdb-bff4-f56d764f9a9e"
      },
      "source": [
        "loss,mse,acc,prec = kfold_validation(\"m222\",M1_ufc,M2_ufc,M3_ufc,M4_ufc,M5_ufc,Train_ufc_y,pca_SPM_cube_ufc_reloaded,32,30)\n",
        "results_diff[\"m222\"] = np.array((loss,mse,acc,prec))\n",
        "filename = '/content/drive/MyDrive/ML_CSP774/Theory_project/3D-CNN Activity Recognition/Pickle/m222_30epochs.pickle'\n",
        "with open(filename, 'wb') as f:\n",
        "    pickle.dump(results_diff[\"m222\"], f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "m222\n",
            "(None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 8, 72, 54) (None, 2, 8, 72, 54)\n",
            "(None, 2, 9, 24, 18) (None, 2, 18, 24, 18) (None, 2, 16, 24, 18)\n",
            "(None, 6, 9, 18, 12) (None, 6, 18, 18, 12) (None, 6, 16, 18, 12)\n",
            "(None, 6, 43, 6, 4)\n",
            "(None, 6, 43, 1, 1)\n",
            "(None, 258)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m222 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "22/22 [==============================] - 4s 184ms/step - loss: 1.6736 - mse: 0.1316 - accuracy: 0.3012 - precision: 0.8462\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 1.2653 - mse: 0.1052 - accuracy: 0.5059 - precision: 0.6900\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 1.0053 - mse: 0.0854 - accuracy: 0.6246 - precision: 0.7620\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.8385 - mse: 0.0719 - accuracy: 0.6751 - precision: 0.8128\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 4s 171ms/step - loss: 0.7851 - mse: 0.0672 - accuracy: 0.7062 - precision: 0.7922\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.6982 - mse: 0.0595 - accuracy: 0.7433 - precision: 0.8286\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.6655 - mse: 0.0567 - accuracy: 0.7493 - precision: 0.8370\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.6101 - mse: 0.0523 - accuracy: 0.7656 - precision: 0.8384\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.5791 - mse: 0.0483 - accuracy: 0.8012 - precision: 0.8589\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.5313 - mse: 0.0466 - accuracy: 0.7908 - precision: 0.8518\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.4907 - mse: 0.0416 - accuracy: 0.8279 - precision: 0.8717\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.4852 - mse: 0.0409 - accuracy: 0.8294 - precision: 0.8608\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.4465 - mse: 0.0373 - accuracy: 0.8427 - precision: 0.8794\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.4429 - mse: 0.0360 - accuracy: 0.8501 - precision: 0.8788\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.3733 - mse: 0.0318 - accuracy: 0.8650 - precision: 0.9056\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.3881 - mse: 0.0329 - accuracy: 0.8709 - precision: 0.8885\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 4s 171ms/step - loss: 0.3460 - mse: 0.0291 - accuracy: 0.8813 - precision: 0.9033\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.3363 - mse: 0.0276 - accuracy: 0.8932 - precision: 0.9158\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 4s 171ms/step - loss: 0.3043 - mse: 0.0255 - accuracy: 0.8991 - precision: 0.9181\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 4s 171ms/step - loss: 0.2775 - mse: 0.0229 - accuracy: 0.9095 - precision: 0.9247\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 4s 174ms/step - loss: 0.2741 - mse: 0.0229 - accuracy: 0.9065 - precision: 0.9173\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 4s 171ms/step - loss: 0.2439 - mse: 0.0206 - accuracy: 0.9110 - precision: 0.9248\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.2171 - mse: 0.0174 - accuracy: 0.9362 - precision: 0.9539\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 4s 171ms/step - loss: 0.2276 - mse: 0.0184 - accuracy: 0.9258 - precision: 0.9433\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.1885 - mse: 0.0146 - accuracy: 0.9510 - precision: 0.9578\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 4s 171ms/step - loss: 0.1838 - mse: 0.0153 - accuracy: 0.9451 - precision: 0.9497\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.1553 - mse: 0.0127 - accuracy: 0.9555 - precision: 0.9594\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 4s 171ms/step - loss: 0.1497 - mse: 0.0119 - accuracy: 0.9481 - precision: 0.9550\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.1705 - mse: 0.0144 - accuracy: 0.9466 - precision: 0.9520\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 4s 171ms/step - loss: 0.1334 - mse: 0.0105 - accuracy: 0.9644 - precision: 0.9683\n",
            "Score for fold 1: loss of 1.651262640953064; mse of 0.08936648070812225;accuracy of 0.6863905191421509;precision of 0.6904761791229248\n",
            "m222\n",
            "(None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 8, 72, 54) (None, 2, 8, 72, 54)\n",
            "(None, 2, 9, 24, 18) (None, 2, 18, 24, 18) (None, 2, 16, 24, 18)\n",
            "(None, 6, 9, 18, 12) (None, 6, 18, 18, 12) (None, 6, 16, 18, 12)\n",
            "(None, 6, 43, 6, 4)\n",
            "(None, 6, 43, 1, 1)\n",
            "(None, 258)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m222 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 1.7455 - mse: 0.1359 - accuracy: 0.2552 - precision: 1.0000\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 1.4591 - mse: 0.1182 - accuracy: 0.4125 - precision: 0.6129\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 1.2482 - mse: 0.1040 - accuracy: 0.5237 - precision: 0.6892\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 1.0988 - mse: 0.0928 - accuracy: 0.5920 - precision: 0.7351\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 4s 171ms/step - loss: 0.9620 - mse: 0.0813 - accuracy: 0.6350 - precision: 0.7576\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.9035 - mse: 0.0777 - accuracy: 0.6780 - precision: 0.7639\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.8425 - mse: 0.0710 - accuracy: 0.7092 - precision: 0.8070\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.7785 - mse: 0.0662 - accuracy: 0.7240 - precision: 0.7996\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 4s 171ms/step - loss: 0.7203 - mse: 0.0620 - accuracy: 0.7552 - precision: 0.8150\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 4s 170ms/step - loss: 0.6456 - mse: 0.0563 - accuracy: 0.7478 - precision: 0.8112\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 4s 170ms/step - loss: 0.6210 - mse: 0.0533 - accuracy: 0.7774 - precision: 0.8554\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.5845 - mse: 0.0508 - accuracy: 0.7760 - precision: 0.8410\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 4s 171ms/step - loss: 0.5474 - mse: 0.0485 - accuracy: 0.7849 - precision: 0.8515\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.4994 - mse: 0.0431 - accuracy: 0.8071 - precision: 0.8657\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.4756 - mse: 0.0411 - accuracy: 0.8234 - precision: 0.8750\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.4384 - mse: 0.0375 - accuracy: 0.8501 - precision: 0.8947\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 4s 171ms/step - loss: 0.4232 - mse: 0.0364 - accuracy: 0.8501 - precision: 0.8810\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 4s 171ms/step - loss: 0.4422 - mse: 0.0368 - accuracy: 0.8427 - precision: 0.8808\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 4s 171ms/step - loss: 0.3787 - mse: 0.0324 - accuracy: 0.8680 - precision: 0.8963\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.3811 - mse: 0.0340 - accuracy: 0.8694 - precision: 0.8887\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.3568 - mse: 0.0313 - accuracy: 0.8739 - precision: 0.8986\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.3195 - mse: 0.0268 - accuracy: 0.8976 - precision: 0.9146\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.3064 - mse: 0.0273 - accuracy: 0.8828 - precision: 0.9111\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 4s 171ms/step - loss: 0.3049 - mse: 0.0263 - accuracy: 0.8961 - precision: 0.9221\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.2996 - mse: 0.0262 - accuracy: 0.8887 - precision: 0.9070\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.2844 - mse: 0.0255 - accuracy: 0.8961 - precision: 0.9138\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.2677 - mse: 0.0216 - accuracy: 0.9184 - precision: 0.9297\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 4s 175ms/step - loss: 0.2223 - mse: 0.0197 - accuracy: 0.9199 - precision: 0.9352\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 4s 175ms/step - loss: 0.2563 - mse: 0.0210 - accuracy: 0.9199 - precision: 0.9292\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.1991 - mse: 0.0178 - accuracy: 0.9243 - precision: 0.9390\n",
            "Score for fold 2: loss of 1.3179963827133179; mse of 0.08787272870540619;accuracy of 0.6863905191421509;precision of 0.6851851940155029\n",
            "m222\n",
            "(None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 8, 72, 54) (None, 2, 8, 72, 54)\n",
            "(None, 2, 9, 24, 18) (None, 2, 18, 24, 18) (None, 2, 16, 24, 18)\n",
            "(None, 6, 9, 18, 12) (None, 6, 18, 18, 12) (None, 6, 16, 18, 12)\n",
            "(None, 6, 43, 6, 4)\n",
            "(None, 6, 43, 1, 1)\n",
            "(None, 258)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m222 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 1.6269 - mse: 0.1287 - accuracy: 0.3368 - precision: 0.6061\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 1.2280 - mse: 0.1034 - accuracy: 0.5104 - precision: 0.6923\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 1.0658 - mse: 0.0902 - accuracy: 0.5935 - precision: 0.7052\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.9178 - mse: 0.0784 - accuracy: 0.6469 - precision: 0.7778\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.8933 - mse: 0.0770 - accuracy: 0.6751 - precision: 0.7469\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 4s 171ms/step - loss: 0.8039 - mse: 0.0685 - accuracy: 0.7151 - precision: 0.8040\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.7645 - mse: 0.0651 - accuracy: 0.7226 - precision: 0.8141\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.7302 - mse: 0.0616 - accuracy: 0.7404 - precision: 0.8078\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 4s 171ms/step - loss: 0.6674 - mse: 0.0571 - accuracy: 0.7552 - precision: 0.8226\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.6219 - mse: 0.0535 - accuracy: 0.7760 - precision: 0.8330\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.6008 - mse: 0.0506 - accuracy: 0.7864 - precision: 0.8504\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 4s 171ms/step - loss: 0.5862 - mse: 0.0491 - accuracy: 0.8027 - precision: 0.8547\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.5168 - mse: 0.0438 - accuracy: 0.8220 - precision: 0.8621\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 4s 171ms/step - loss: 0.5314 - mse: 0.0459 - accuracy: 0.8012 - precision: 0.8559\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.4727 - mse: 0.0398 - accuracy: 0.8264 - precision: 0.8828\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.4502 - mse: 0.0385 - accuracy: 0.8427 - precision: 0.8849\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 4s 171ms/step - loss: 0.4491 - mse: 0.0386 - accuracy: 0.8368 - precision: 0.8762\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.4007 - mse: 0.0340 - accuracy: 0.8591 - precision: 0.9036\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.3646 - mse: 0.0307 - accuracy: 0.8798 - precision: 0.9160\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.3713 - mse: 0.0322 - accuracy: 0.8650 - precision: 0.8884\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.3319 - mse: 0.0282 - accuracy: 0.8902 - precision: 0.9077\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.3465 - mse: 0.0291 - accuracy: 0.8872 - precision: 0.9148\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.3037 - mse: 0.0263 - accuracy: 0.8947 - precision: 0.9190\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.2619 - mse: 0.0222 - accuracy: 0.9169 - precision: 0.9337\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.2712 - mse: 0.0239 - accuracy: 0.9021 - precision: 0.9169\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.2411 - mse: 0.0213 - accuracy: 0.9110 - precision: 0.9264\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.2419 - mse: 0.0207 - accuracy: 0.9214 - precision: 0.9393\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.2377 - mse: 0.0197 - accuracy: 0.9288 - precision: 0.9489\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 4s 171ms/step - loss: 0.1932 - mse: 0.0170 - accuracy: 0.9332 - precision: 0.9477\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.1795 - mse: 0.0158 - accuracy: 0.9347 - precision: 0.9427\n",
            "Score for fold 3: loss of 1.9158557653427124; mse of 0.11723122000694275;accuracy of 0.5562130212783813;precision of 0.5679012537002563\n",
            "m222\n",
            "(None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 8, 72, 54) (None, 2, 8, 72, 54)\n",
            "(None, 2, 9, 24, 18) (None, 2, 18, 24, 18) (None, 2, 16, 24, 18)\n",
            "(None, 6, 9, 18, 12) (None, 6, 18, 18, 12) (None, 6, 16, 18, 12)\n",
            "(None, 6, 43, 6, 4)\n",
            "(None, 6, 43, 1, 1)\n",
            "(None, 258)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m222 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/30\n",
            "22/22 [==============================] - 4s 186ms/step - loss: 1.6955 - mse: 0.1331 - accuracy: 0.2859 - precision: 0.3333\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 4s 171ms/step - loss: 1.2699 - mse: 0.1047 - accuracy: 0.5096 - precision: 0.7068\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 1.1011 - mse: 0.0924 - accuracy: 0.5881 - precision: 0.7310\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.9310 - mse: 0.0780 - accuracy: 0.6593 - precision: 0.7801\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 4s 171ms/step - loss: 0.8451 - mse: 0.0705 - accuracy: 0.6933 - precision: 0.7869\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.7593 - mse: 0.0632 - accuracy: 0.7289 - precision: 0.8121\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.6931 - mse: 0.0592 - accuracy: 0.7422 - precision: 0.8089\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.6452 - mse: 0.0551 - accuracy: 0.7644 - precision: 0.8304\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.5911 - mse: 0.0506 - accuracy: 0.7852 - precision: 0.8423\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.5070 - mse: 0.0432 - accuracy: 0.8148 - precision: 0.8673\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.4869 - mse: 0.0420 - accuracy: 0.8044 - precision: 0.8677\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.4515 - mse: 0.0375 - accuracy: 0.8548 - precision: 0.8855\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.4385 - mse: 0.0381 - accuracy: 0.8415 - precision: 0.8668\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.3865 - mse: 0.0334 - accuracy: 0.8533 - precision: 0.8806\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.3714 - mse: 0.0308 - accuracy: 0.8667 - precision: 0.9051\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.3555 - mse: 0.0305 - accuracy: 0.8919 - precision: 0.9078\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.3298 - mse: 0.0280 - accuracy: 0.8859 - precision: 0.9194\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.2844 - mse: 0.0250 - accuracy: 0.8919 - precision: 0.9150\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.2722 - mse: 0.0236 - accuracy: 0.9126 - precision: 0.9219\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.2933 - mse: 0.0255 - accuracy: 0.8904 - precision: 0.9088\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.2377 - mse: 0.0201 - accuracy: 0.9304 - precision: 0.9395\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.2309 - mse: 0.0195 - accuracy: 0.9289 - precision: 0.9365\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.2099 - mse: 0.0185 - accuracy: 0.9230 - precision: 0.9320\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 4s 170ms/step - loss: 0.1938 - mse: 0.0166 - accuracy: 0.9289 - precision: 0.9354\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.1775 - mse: 0.0158 - accuracy: 0.9348 - precision: 0.9455\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 4s 171ms/step - loss: 0.1546 - mse: 0.0128 - accuracy: 0.9496 - precision: 0.9606\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.1365 - mse: 0.0110 - accuracy: 0.9600 - precision: 0.9712\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.1300 - mse: 0.0115 - accuracy: 0.9452 - precision: 0.9592\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.1061 - mse: 0.0088 - accuracy: 0.9689 - precision: 0.9701\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.1369 - mse: 0.0121 - accuracy: 0.9511 - precision: 0.9579\n",
            "Score for fold 4: loss of 1.2006933689117432; mse of 0.07197238504886627;accuracy of 0.738095223903656;precision of 0.7469879388809204\n",
            "m222\n",
            "(None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 8, 72, 54) (None, 2, 8, 72, 54)\n",
            "(None, 2, 9, 24, 18) (None, 2, 18, 24, 18) (None, 2, 16, 24, 18)\n",
            "(None, 6, 9, 18, 12) (None, 6, 18, 18, 12) (None, 6, 16, 18, 12)\n",
            "(None, 6, 43, 6, 4)\n",
            "(None, 6, 43, 1, 1)\n",
            "(None, 258)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m222 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/30\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 1.7575 - mse: 0.1369 - accuracy: 0.2311 - precision: 0.0000e+00\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 1.5220 - mse: 0.1220 - accuracy: 0.3911 - precision: 0.7400\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 1.2065 - mse: 0.0990 - accuracy: 0.5467 - precision: 0.7800\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.9862 - mse: 0.0829 - accuracy: 0.6163 - precision: 0.7966\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.8896 - mse: 0.0748 - accuracy: 0.6652 - precision: 0.7977\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.7978 - mse: 0.0661 - accuracy: 0.7274 - precision: 0.8351\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.7398 - mse: 0.0620 - accuracy: 0.7378 - precision: 0.8349\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.6685 - mse: 0.0561 - accuracy: 0.7570 - precision: 0.8389\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 4s 171ms/step - loss: 0.6179 - mse: 0.0519 - accuracy: 0.7852 - precision: 0.8541\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.5929 - mse: 0.0500 - accuracy: 0.7881 - precision: 0.8367\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.5368 - mse: 0.0462 - accuracy: 0.8059 - precision: 0.8627\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.5128 - mse: 0.0435 - accuracy: 0.8193 - precision: 0.8737\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.4823 - mse: 0.0409 - accuracy: 0.8400 - precision: 0.8764\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 4s 171ms/step - loss: 0.4527 - mse: 0.0381 - accuracy: 0.8415 - precision: 0.8842\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.4083 - mse: 0.0339 - accuracy: 0.8726 - precision: 0.9045\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 4s 174ms/step - loss: 0.4119 - mse: 0.0342 - accuracy: 0.8563 - precision: 0.8957\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 4s 174ms/step - loss: 0.3848 - mse: 0.0328 - accuracy: 0.8607 - precision: 0.8970\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 4s 171ms/step - loss: 0.3531 - mse: 0.0291 - accuracy: 0.8859 - precision: 0.9124\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.3330 - mse: 0.0272 - accuracy: 0.8978 - precision: 0.9187\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.3044 - mse: 0.0256 - accuracy: 0.9022 - precision: 0.9185\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.2731 - mse: 0.0229 - accuracy: 0.9111 - precision: 0.9347\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.2535 - mse: 0.0215 - accuracy: 0.9141 - precision: 0.9350\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 4s 171ms/step - loss: 0.2574 - mse: 0.0217 - accuracy: 0.9185 - precision: 0.9371\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 4s 171ms/step - loss: 0.2372 - mse: 0.0203 - accuracy: 0.9215 - precision: 0.9349\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.2027 - mse: 0.0170 - accuracy: 0.9319 - precision: 0.9511\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.1699 - mse: 0.0146 - accuracy: 0.9407 - precision: 0.9470\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.1730 - mse: 0.0147 - accuracy: 0.9452 - precision: 0.9520\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.1475 - mse: 0.0127 - accuracy: 0.9496 - precision: 0.9578\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.1264 - mse: 0.0104 - accuracy: 0.9659 - precision: 0.9700\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.1267 - mse: 0.0108 - accuracy: 0.9615 - precision: 0.9640\n",
            "Score for fold 5: loss of 1.5206725597381592; mse of 0.0824345201253891;accuracy of 0.7023809552192688;precision of 0.7108433842658997\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 1.651262640953064 - Accuracy: 0.6863905191421509 - Precision: 0.6904761791229248%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 1.3179963827133179 - Accuracy: 0.6863905191421509 - Precision: 0.6851851940155029%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 1.9158557653427124 - Accuracy: 0.5562130212783813 - Precision: 0.5679012537002563%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 1.2006933689117432 - Accuracy: 0.738095223903656 - Precision: 0.7469879388809204%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 1.5206725597381592 - Accuracy: 0.7023809552192688 - Precision: 0.7108433842658997%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 0.6738940477371216 (+- 0.06179715608763716)\n",
            "> Loss: 1.5212961435317993\n",
            "> Precision: 0.6802787899971008\n",
            "------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYpxzgmOyFUd"
      },
      "source": [
        "#### Model rs332"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ALsjRLQYChl",
        "outputId": "42dc903d-2558-4671-c943-59d37ddd6260"
      },
      "source": [
        "loss,mse,acc,prec = kfold_validation(\"rs332\",M1_ufc,M2_ufc,M3_ufc,M4_ufc,M5_ufc,Train_ufc_y,pca_SPM_cube_ufc_reloaded,32,30)\n",
        "results_diff[\"rs332\"] = np.array((loss,mse,acc,prec))\n",
        "filename = '/content/drive/MyDrive/ML_CSP774/Theory_project/3D-CNN Activity Recognition/Pickle/rs332_30epochs.pickle'\n",
        "with open(filename, 'wb') as f:\n",
        "    pickle.dump(results_diff[\"rs332\"], f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rs332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "correct\n",
            "(None, 300)\n",
            "New rs332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "22/22 [==============================] - 6s 261ms/step - loss: 1.8873 - output_rs332_loss: 1.6810 - output_spm_rs332_loss: 41.2598 - output_rs332_mse: 0.1311 - output_rs332_accuracy: 0.3012 - output_rs332_precision: 0.7297 - output_spm_rs332_mse: 41.2598 - output_spm_rs332_accuracy: 0.0104\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 1.5812 - output_rs332_loss: 1.3751 - output_spm_rs332_loss: 41.2178 - output_rs332_mse: 0.1108 - output_rs332_accuracy: 0.4733 - output_rs332_precision: 0.7035 - output_spm_rs332_mse: 41.2178 - output_spm_rs332_accuracy: 0.1543\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 1.3449 - output_rs332_loss: 1.1390 - output_spm_rs332_loss: 41.1878 - output_rs332_mse: 0.0942 - output_rs332_accuracy: 0.5579 - output_rs332_precision: 0.7311 - output_spm_rs332_mse: 41.1878 - output_spm_rs332_accuracy: 0.2478\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 1.2250 - output_rs332_loss: 1.0192 - output_spm_rs332_loss: 41.1575 - output_rs332_mse: 0.0846 - output_rs332_accuracy: 0.6365 - output_rs332_precision: 0.7481 - output_spm_rs332_mse: 41.1575 - output_spm_rs332_accuracy: 0.2671\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 1.1189 - output_rs332_loss: 0.9135 - output_spm_rs332_loss: 41.0809 - output_rs332_mse: 0.0771 - output_rs332_accuracy: 0.6543 - output_rs332_precision: 0.7543 - output_spm_rs332_mse: 41.0809 - output_spm_rs332_accuracy: 0.2834\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.9771 - output_rs332_loss: 0.7723 - output_spm_rs332_loss: 40.9641 - output_rs332_mse: 0.0654 - output_rs332_accuracy: 0.7226 - output_rs332_precision: 0.8217 - output_spm_rs332_mse: 40.9641 - output_spm_rs332_accuracy: 0.2967\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 0.9168 - output_rs332_loss: 0.7128 - output_spm_rs332_loss: 40.8041 - output_rs332_mse: 0.0614 - output_rs332_accuracy: 0.7433 - output_rs332_precision: 0.7989 - output_spm_rs332_mse: 40.8041 - output_spm_rs332_accuracy: 0.3205\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.8361 - output_rs332_loss: 0.6330 - output_spm_rs332_loss: 40.6354 - output_rs332_mse: 0.0549 - output_rs332_accuracy: 0.7611 - output_rs332_precision: 0.8191 - output_spm_rs332_mse: 40.6354 - output_spm_rs332_accuracy: 0.3383\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.8581 - output_rs332_loss: 0.6556 - output_spm_rs332_loss: 40.5106 - output_rs332_mse: 0.0539 - output_rs332_accuracy: 0.7700 - output_rs332_precision: 0.8336 - output_spm_rs332_mse: 40.5106 - output_spm_rs332_accuracy: 0.3561\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.7295 - output_rs332_loss: 0.5280 - output_spm_rs332_loss: 40.3043 - output_rs332_mse: 0.0462 - output_rs332_accuracy: 0.7982 - output_rs332_precision: 0.8586 - output_spm_rs332_mse: 40.3043 - output_spm_rs332_accuracy: 0.3635\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 0.6962 - output_rs332_loss: 0.4957 - output_spm_rs332_loss: 40.1073 - output_rs332_mse: 0.0421 - output_rs332_accuracy: 0.8353 - output_rs332_precision: 0.8806 - output_spm_rs332_mse: 40.1073 - output_spm_rs332_accuracy: 0.3650\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.6374 - output_rs332_loss: 0.4380 - output_spm_rs332_loss: 39.8834 - output_rs332_mse: 0.0377 - output_rs332_accuracy: 0.8487 - output_rs332_precision: 0.8805 - output_spm_rs332_mse: 39.8834 - output_spm_rs332_accuracy: 0.3754\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.6003 - output_rs332_loss: 0.4018 - output_spm_rs332_loss: 39.7139 - output_rs332_mse: 0.0342 - output_rs332_accuracy: 0.8650 - output_rs332_precision: 0.9032 - output_spm_rs332_mse: 39.7139 - output_spm_rs332_accuracy: 0.3902\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.5714 - output_rs332_loss: 0.3738 - output_spm_rs332_loss: 39.5261 - output_rs332_mse: 0.0320 - output_rs332_accuracy: 0.8694 - output_rs332_precision: 0.9026 - output_spm_rs332_mse: 39.5261 - output_spm_rs332_accuracy: 0.3887\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.5047 - output_rs332_loss: 0.3082 - output_spm_rs332_loss: 39.2966 - output_rs332_mse: 0.0262 - output_rs332_accuracy: 0.8887 - output_rs332_precision: 0.9277 - output_spm_rs332_mse: 39.2966 - output_spm_rs332_accuracy: 0.3976\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.4942 - output_rs332_loss: 0.2985 - output_spm_rs332_loss: 39.1308 - output_rs332_mse: 0.0256 - output_rs332_accuracy: 0.9065 - output_rs332_precision: 0.9188 - output_spm_rs332_mse: 39.1308 - output_spm_rs332_accuracy: 0.4050\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.4643 - output_rs332_loss: 0.2703 - output_spm_rs332_loss: 38.8105 - output_rs332_mse: 0.0235 - output_rs332_accuracy: 0.9095 - output_rs332_precision: 0.9201 - output_spm_rs332_mse: 38.8105 - output_spm_rs332_accuracy: 0.4006\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.4269 - output_rs332_loss: 0.2345 - output_spm_rs332_loss: 38.4812 - output_rs332_mse: 0.0190 - output_rs332_accuracy: 0.9347 - output_rs332_precision: 0.9433 - output_spm_rs332_mse: 38.4812 - output_spm_rs332_accuracy: 0.4065\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 6s 261ms/step - loss: 0.4532 - output_rs332_loss: 0.2614 - output_spm_rs332_loss: 38.3538 - output_rs332_mse: 0.0227 - output_rs332_accuracy: 0.9139 - output_rs332_precision: 0.9265 - output_spm_rs332_mse: 38.3538 - output_spm_rs332_accuracy: 0.4110\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.3949 - output_rs332_loss: 0.2047 - output_spm_rs332_loss: 38.0523 - output_rs332_mse: 0.0191 - output_rs332_accuracy: 0.9258 - output_rs332_precision: 0.9308 - output_spm_rs332_mse: 38.0523 - output_spm_rs332_accuracy: 0.3917\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.3742 - output_rs332_loss: 0.1851 - output_spm_rs332_loss: 37.8173 - output_rs332_mse: 0.0158 - output_rs332_accuracy: 0.9347 - output_rs332_precision: 0.9467 - output_spm_rs332_mse: 37.8173 - output_spm_rs332_accuracy: 0.4110\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 0.3486 - output_rs332_loss: 0.1607 - output_spm_rs332_loss: 37.5679 - output_rs332_mse: 0.0139 - output_rs332_accuracy: 0.9525 - output_rs332_precision: 0.9604 - output_spm_rs332_mse: 37.5679 - output_spm_rs332_accuracy: 0.3947\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 0.3426 - output_rs332_loss: 0.1553 - output_spm_rs332_loss: 37.4587 - output_rs332_mse: 0.0138 - output_rs332_accuracy: 0.9481 - output_rs332_precision: 0.9518 - output_spm_rs332_mse: 37.4587 - output_spm_rs332_accuracy: 0.3991\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 0.3164 - output_rs332_loss: 0.1310 - output_spm_rs332_loss: 37.0722 - output_rs332_mse: 0.0113 - output_rs332_accuracy: 0.9525 - output_rs332_precision: 0.9567 - output_spm_rs332_mse: 37.0722 - output_spm_rs332_accuracy: 0.4199\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.3266 - output_rs332_loss: 0.1419 - output_spm_rs332_loss: 36.9487 - output_rs332_mse: 0.0116 - output_rs332_accuracy: 0.9570 - output_rs332_precision: 0.9582 - output_spm_rs332_mse: 36.9487 - output_spm_rs332_accuracy: 0.4036\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 0.3229 - output_rs332_loss: 0.1393 - output_spm_rs332_loss: 36.7079 - output_rs332_mse: 0.0118 - output_rs332_accuracy: 0.9525 - output_rs332_precision: 0.9639 - output_spm_rs332_mse: 36.7079 - output_spm_rs332_accuracy: 0.4303\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 0.2389 - output_rs332_loss: 0.0559 - output_spm_rs332_loss: 36.5947 - output_rs332_mse: 0.0047 - output_rs332_accuracy: 0.9807 - output_rs332_precision: 0.9836 - output_spm_rs332_mse: 36.5947 - output_spm_rs332_accuracy: 0.4169\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 0.2948 - output_rs332_loss: 0.1125 - output_spm_rs332_loss: 36.4601 - output_rs332_mse: 0.0098 - output_rs332_accuracy: 0.9614 - output_rs332_precision: 0.9642 - output_spm_rs332_mse: 36.4601 - output_spm_rs332_accuracy: 0.4050\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.2514 - output_rs332_loss: 0.0710 - output_spm_rs332_loss: 36.0788 - output_rs332_mse: 0.0062 - output_rs332_accuracy: 0.9777 - output_rs332_precision: 0.9806 - output_spm_rs332_mse: 36.0788 - output_spm_rs332_accuracy: 0.4243\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 0.2623 - output_rs332_loss: 0.0822 - output_spm_rs332_loss: 36.0161 - output_rs332_mse: 0.0072 - output_rs332_accuracy: 0.9748 - output_rs332_precision: 0.9776 - output_spm_rs332_mse: 36.0161 - output_spm_rs332_accuracy: 0.4080\n",
            "Score for fold 1: loss of 1.7660939693450928; output_rs332_loss of 1.581727147102356;output_spm_rs332_loss of 36.87336349487305;output_rs332_mse of 0.07282824069261551\n",
            "rs332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "correct\n",
            "(None, 300)\n",
            "New rs332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/30\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 1.9916 - output_rs332_loss: 1.7831 - output_spm_rs332_loss: 41.7002 - output_rs332_mse: 0.1384 - output_rs332_accuracy: 0.1929 - output_rs332_precision: 0.0000e+00 - output_spm_rs332_mse: 41.7002 - output_spm_rs332_accuracy: 0.0015\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 1.6791 - output_rs332_loss: 1.4707 - output_spm_rs332_loss: 41.6766 - output_rs332_mse: 0.1185 - output_rs332_accuracy: 0.4273 - output_rs332_precision: 0.6827 - output_spm_rs332_mse: 41.6766 - output_spm_rs332_accuracy: 0.1973\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 1.4714 - output_rs332_loss: 1.2633 - output_spm_rs332_loss: 41.6168 - output_rs332_mse: 0.1054 - output_rs332_accuracy: 0.5045 - output_rs332_precision: 0.6818 - output_spm_rs332_mse: 41.6168 - output_spm_rs332_accuracy: 0.3220\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 1.3021 - output_rs332_loss: 1.0945 - output_spm_rs332_loss: 41.5223 - output_rs332_mse: 0.0901 - output_rs332_accuracy: 0.6142 - output_rs332_precision: 0.7361 - output_spm_rs332_mse: 41.5223 - output_spm_rs332_accuracy: 0.3353\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 1.2376 - output_rs332_loss: 1.0302 - output_spm_rs332_loss: 41.4698 - output_rs332_mse: 0.0863 - output_rs332_accuracy: 0.6157 - output_rs332_precision: 0.7327 - output_spm_rs332_mse: 41.4698 - output_spm_rs332_accuracy: 0.3487\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 1.1277 - output_rs332_loss: 0.9207 - output_spm_rs332_loss: 41.3931 - output_rs332_mse: 0.0777 - output_rs332_accuracy: 0.6706 - output_rs332_precision: 0.7574 - output_spm_rs332_mse: 41.3931 - output_spm_rs332_accuracy: 0.3516\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 1.0395 - output_rs332_loss: 0.8330 - output_spm_rs332_loss: 41.3101 - output_rs332_mse: 0.0717 - output_rs332_accuracy: 0.6884 - output_rs332_precision: 0.7895 - output_spm_rs332_mse: 41.3101 - output_spm_rs332_accuracy: 0.3546\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 1.0073 - output_rs332_loss: 0.8011 - output_spm_rs332_loss: 41.2359 - output_rs332_mse: 0.0673 - output_rs332_accuracy: 0.7181 - output_rs332_precision: 0.7827 - output_spm_rs332_mse: 41.2359 - output_spm_rs332_accuracy: 0.3813\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.8997 - output_rs332_loss: 0.6939 - output_spm_rs332_loss: 41.1622 - output_rs332_mse: 0.0602 - output_rs332_accuracy: 0.7374 - output_rs332_precision: 0.8109 - output_spm_rs332_mse: 41.1622 - output_spm_rs332_accuracy: 0.3858\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.8364 - output_rs332_loss: 0.6310 - output_spm_rs332_loss: 41.0801 - output_rs332_mse: 0.0541 - output_rs332_accuracy: 0.7671 - output_rs332_precision: 0.8319 - output_spm_rs332_mse: 41.0801 - output_spm_rs332_accuracy: 0.3739\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 0.7764 - output_rs332_loss: 0.5717 - output_spm_rs332_loss: 40.9472 - output_rs332_mse: 0.0497 - output_rs332_accuracy: 0.7982 - output_rs332_precision: 0.8356 - output_spm_rs332_mse: 40.9472 - output_spm_rs332_accuracy: 0.3976\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.7402 - output_rs332_loss: 0.5357 - output_spm_rs332_loss: 40.8989 - output_rs332_mse: 0.0453 - output_rs332_accuracy: 0.8042 - output_rs332_precision: 0.8416 - output_spm_rs332_mse: 40.8989 - output_spm_rs332_accuracy: 0.4006\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.7244 - output_rs332_loss: 0.5202 - output_spm_rs332_loss: 40.8310 - output_rs332_mse: 0.0458 - output_rs332_accuracy: 0.8234 - output_rs332_precision: 0.8450 - output_spm_rs332_mse: 40.8310 - output_spm_rs332_accuracy: 0.4065\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.6304 - output_rs332_loss: 0.4266 - output_spm_rs332_loss: 40.7435 - output_rs332_mse: 0.0365 - output_rs332_accuracy: 0.8516 - output_rs332_precision: 0.8951 - output_spm_rs332_mse: 40.7435 - output_spm_rs332_accuracy: 0.4006\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.6511 - output_rs332_loss: 0.4483 - output_spm_rs332_loss: 40.5552 - output_rs332_mse: 0.0387 - output_rs332_accuracy: 0.8383 - output_rs332_precision: 0.8574 - output_spm_rs332_mse: 40.5552 - output_spm_rs332_accuracy: 0.4021\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.5817 - output_rs332_loss: 0.3790 - output_spm_rs332_loss: 40.5424 - output_rs332_mse: 0.0323 - output_rs332_accuracy: 0.8754 - output_rs332_precision: 0.8913 - output_spm_rs332_mse: 40.5424 - output_spm_rs332_accuracy: 0.4095\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.5567 - output_rs332_loss: 0.3545 - output_spm_rs332_loss: 40.4320 - output_rs332_mse: 0.0301 - output_rs332_accuracy: 0.8843 - output_rs332_precision: 0.9072 - output_spm_rs332_mse: 40.4320 - output_spm_rs332_accuracy: 0.4021\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 0.5029 - output_rs332_loss: 0.3014 - output_spm_rs332_loss: 40.2971 - output_rs332_mse: 0.0245 - output_rs332_accuracy: 0.9080 - output_rs332_precision: 0.9281 - output_spm_rs332_mse: 40.2971 - output_spm_rs332_accuracy: 0.3991\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 0.4924 - output_rs332_loss: 0.2916 - output_spm_rs332_loss: 40.1597 - output_rs332_mse: 0.0260 - output_rs332_accuracy: 0.9006 - output_rs332_precision: 0.9090 - output_spm_rs332_mse: 40.1597 - output_spm_rs332_accuracy: 0.3947\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 0.4847 - output_rs332_loss: 0.2850 - output_spm_rs332_loss: 39.9414 - output_rs332_mse: 0.0244 - output_rs332_accuracy: 0.9050 - output_rs332_precision: 0.9220 - output_spm_rs332_mse: 39.9414 - output_spm_rs332_accuracy: 0.4139\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.4290 - output_rs332_loss: 0.2292 - output_spm_rs332_loss: 39.9648 - output_rs332_mse: 0.0206 - output_rs332_accuracy: 0.9154 - output_rs332_precision: 0.9284 - output_spm_rs332_mse: 39.9648 - output_spm_rs332_accuracy: 0.4095\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.4168 - output_rs332_loss: 0.2176 - output_spm_rs332_loss: 39.8520 - output_rs332_mse: 0.0196 - output_rs332_accuracy: 0.9184 - output_rs332_precision: 0.9256 - output_spm_rs332_mse: 39.8520 - output_spm_rs332_accuracy: 0.4036\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.3880 - output_rs332_loss: 0.1899 - output_spm_rs332_loss: 39.6204 - output_rs332_mse: 0.0162 - output_rs332_accuracy: 0.9377 - output_rs332_precision: 0.9412 - output_spm_rs332_mse: 39.6204 - output_spm_rs332_accuracy: 0.4199\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 0.3931 - output_rs332_loss: 0.1960 - output_spm_rs332_loss: 39.4209 - output_rs332_mse: 0.0174 - output_rs332_accuracy: 0.9288 - output_rs332_precision: 0.9337 - output_spm_rs332_mse: 39.4209 - output_spm_rs332_accuracy: 0.4154\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.3573 - output_rs332_loss: 0.1609 - output_spm_rs332_loss: 39.2950 - output_rs332_mse: 0.0130 - output_rs332_accuracy: 0.9540 - output_rs332_precision: 0.9608 - output_spm_rs332_mse: 39.2950 - output_spm_rs332_accuracy: 0.4377\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.3733 - output_rs332_loss: 0.1775 - output_spm_rs332_loss: 39.1619 - output_rs332_mse: 0.0158 - output_rs332_accuracy: 0.9407 - output_rs332_precision: 0.9444 - output_spm_rs332_mse: 39.1619 - output_spm_rs332_accuracy: 0.4199\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 0.3357 - output_rs332_loss: 0.1402 - output_spm_rs332_loss: 39.1005 - output_rs332_mse: 0.0119 - output_rs332_accuracy: 0.9614 - output_rs332_precision: 0.9654 - output_spm_rs332_mse: 39.1005 - output_spm_rs332_accuracy: 0.4169\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 0.3183 - output_rs332_loss: 0.1236 - output_spm_rs332_loss: 38.9448 - output_rs332_mse: 0.0115 - output_rs332_accuracy: 0.9540 - output_rs332_precision: 0.9567 - output_spm_rs332_mse: 38.9448 - output_spm_rs332_accuracy: 0.4392\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.3903 - output_rs332_loss: 0.1961 - output_spm_rs332_loss: 38.8384 - output_rs332_mse: 0.0160 - output_rs332_accuracy: 0.9362 - output_rs332_precision: 0.9459 - output_spm_rs332_mse: 38.8384 - output_spm_rs332_accuracy: 0.4243\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.2722 - output_rs332_loss: 0.0788 - output_spm_rs332_loss: 38.6714 - output_rs332_mse: 0.0062 - output_rs332_accuracy: 0.9807 - output_rs332_precision: 0.9836 - output_spm_rs332_mse: 38.6714 - output_spm_rs332_accuracy: 0.4169\n",
            "Score for fold 2: loss of 1.935384750366211; output_rs332_loss of 1.7525690793991089;output_spm_rs332_loss of 36.56314468383789;output_rs332_mse of 0.09980300068855286\n",
            "rs332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "correct\n",
            "(None, 300)\n",
            "New rs332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/30\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 1.7399 - output_rs332_loss: 1.5356 - output_spm_rs332_loss: 40.8674 - output_rs332_mse: 0.1229 - output_rs332_accuracy: 0.3724 - output_rs332_precision: 0.6667 - output_spm_rs332_mse: 40.8674 - output_spm_rs332_accuracy: 0.0208\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 1.4533 - output_rs332_loss: 1.2491 - output_spm_rs332_loss: 40.8494 - output_rs332_mse: 0.1032 - output_rs332_accuracy: 0.5104 - output_rs332_precision: 0.6599 - output_spm_rs332_mse: 40.8494 - output_spm_rs332_accuracy: 0.1335\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 1.2747 - output_rs332_loss: 1.0707 - output_spm_rs332_loss: 40.7982 - output_rs332_mse: 0.0897 - output_rs332_accuracy: 0.5846 - output_rs332_precision: 0.7282 - output_spm_rs332_mse: 40.7982 - output_spm_rs332_accuracy: 0.2270\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 1.1212 - output_rs332_loss: 0.9177 - output_spm_rs332_loss: 40.6881 - output_rs332_mse: 0.0781 - output_rs332_accuracy: 0.6751 - output_rs332_precision: 0.7644 - output_spm_rs332_mse: 40.6881 - output_spm_rs332_accuracy: 0.2864\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 1.0337 - output_rs332_loss: 0.8311 - output_spm_rs332_loss: 40.5268 - output_rs332_mse: 0.0712 - output_rs332_accuracy: 0.6810 - output_rs332_precision: 0.7778 - output_spm_rs332_mse: 40.5268 - output_spm_rs332_accuracy: 0.3487\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.9592 - output_rs332_loss: 0.7575 - output_spm_rs332_loss: 40.3531 - output_rs332_mse: 0.0656 - output_rs332_accuracy: 0.7092 - output_rs332_precision: 0.7761 - output_spm_rs332_mse: 40.3531 - output_spm_rs332_accuracy: 0.3872\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.8794 - output_rs332_loss: 0.6783 - output_spm_rs332_loss: 40.2078 - output_rs332_mse: 0.0571 - output_rs332_accuracy: 0.7463 - output_rs332_precision: 0.8192 - output_spm_rs332_mse: 40.2078 - output_spm_rs332_accuracy: 0.3976\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.8158 - output_rs332_loss: 0.6154 - output_spm_rs332_loss: 40.0612 - output_rs332_mse: 0.0516 - output_rs332_accuracy: 0.7804 - output_rs332_precision: 0.8453 - output_spm_rs332_mse: 40.0612 - output_spm_rs332_accuracy: 0.4095\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 0.7421 - output_rs332_loss: 0.5430 - output_spm_rs332_loss: 39.8181 - output_rs332_mse: 0.0465 - output_rs332_accuracy: 0.8027 - output_rs332_precision: 0.8372 - output_spm_rs332_mse: 39.8181 - output_spm_rs332_accuracy: 0.4139\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 6s 261ms/step - loss: 0.7168 - output_rs332_loss: 0.5186 - output_spm_rs332_loss: 39.6542 - output_rs332_mse: 0.0432 - output_rs332_accuracy: 0.8205 - output_rs332_precision: 0.8729 - output_spm_rs332_mse: 39.6542 - output_spm_rs332_accuracy: 0.4377\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 6s 262ms/step - loss: 0.6944 - output_rs332_loss: 0.4968 - output_spm_rs332_loss: 39.5182 - output_rs332_mse: 0.0414 - output_rs332_accuracy: 0.8368 - output_rs332_precision: 0.8783 - output_spm_rs332_mse: 39.5182 - output_spm_rs332_accuracy: 0.4125\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.6197 - output_rs332_loss: 0.4231 - output_spm_rs332_loss: 39.3092 - output_rs332_mse: 0.0359 - output_rs332_accuracy: 0.8546 - output_rs332_precision: 0.8846 - output_spm_rs332_mse: 39.3092 - output_spm_rs332_accuracy: 0.4258\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.6168 - output_rs332_loss: 0.4215 - output_spm_rs332_loss: 39.0587 - output_rs332_mse: 0.0370 - output_rs332_accuracy: 0.8427 - output_rs332_precision: 0.8750 - output_spm_rs332_mse: 39.0587 - output_spm_rs332_accuracy: 0.4377\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.5425 - output_rs332_loss: 0.3480 - output_spm_rs332_loss: 38.9122 - output_rs332_mse: 0.0303 - output_rs332_accuracy: 0.8813 - output_rs332_precision: 0.9055 - output_spm_rs332_mse: 38.9122 - output_spm_rs332_accuracy: 0.4243\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.5183 - output_rs332_loss: 0.3251 - output_spm_rs332_loss: 38.6529 - output_rs332_mse: 0.0277 - output_rs332_accuracy: 0.8769 - output_rs332_precision: 0.8997 - output_spm_rs332_mse: 38.6529 - output_spm_rs332_accuracy: 0.4362\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.4899 - output_rs332_loss: 0.2971 - output_spm_rs332_loss: 38.5494 - output_rs332_mse: 0.0257 - output_rs332_accuracy: 0.8947 - output_rs332_precision: 0.9115 - output_spm_rs332_mse: 38.5494 - output_spm_rs332_accuracy: 0.4095\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.5135 - output_rs332_loss: 0.3223 - output_spm_rs332_loss: 38.2315 - output_rs332_mse: 0.0262 - output_rs332_accuracy: 0.8961 - output_rs332_precision: 0.9177 - output_spm_rs332_mse: 38.2315 - output_spm_rs332_accuracy: 0.4184\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.4041 - output_rs332_loss: 0.2142 - output_spm_rs332_loss: 37.9722 - output_rs332_mse: 0.0173 - output_rs332_accuracy: 0.9407 - output_rs332_precision: 0.9484 - output_spm_rs332_mse: 37.9722 - output_spm_rs332_accuracy: 0.4332\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 0.4186 - output_rs332_loss: 0.2295 - output_spm_rs332_loss: 37.8258 - output_rs332_mse: 0.0201 - output_rs332_accuracy: 0.9139 - output_rs332_precision: 0.9271 - output_spm_rs332_mse: 37.8258 - output_spm_rs332_accuracy: 0.4199\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.3619 - output_rs332_loss: 0.1739 - output_spm_rs332_loss: 37.5977 - output_rs332_mse: 0.0156 - output_rs332_accuracy: 0.9362 - output_rs332_precision: 0.9415 - output_spm_rs332_mse: 37.5977 - output_spm_rs332_accuracy: 0.4288\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.3445 - output_rs332_loss: 0.1584 - output_spm_rs332_loss: 37.2232 - output_rs332_mse: 0.0127 - output_rs332_accuracy: 0.9525 - output_rs332_precision: 0.9666 - output_spm_rs332_mse: 37.2232 - output_spm_rs332_accuracy: 0.4273\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.3947 - output_rs332_loss: 0.2092 - output_spm_rs332_loss: 37.0939 - output_rs332_mse: 0.0180 - output_rs332_accuracy: 0.9273 - output_rs332_precision: 0.9325 - output_spm_rs332_mse: 37.0939 - output_spm_rs332_accuracy: 0.4332\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 0.3293 - output_rs332_loss: 0.1443 - output_spm_rs332_loss: 37.0057 - output_rs332_mse: 0.0118 - output_rs332_accuracy: 0.9555 - output_rs332_precision: 0.9595 - output_spm_rs332_mse: 37.0057 - output_spm_rs332_accuracy: 0.4318\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.2957 - output_rs332_loss: 0.1126 - output_spm_rs332_loss: 36.6026 - output_rs332_mse: 0.0093 - output_rs332_accuracy: 0.9659 - output_rs332_precision: 0.9687 - output_spm_rs332_mse: 36.6026 - output_spm_rs332_accuracy: 0.4288\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 0.3409 - output_rs332_loss: 0.1598 - output_spm_rs332_loss: 36.2062 - output_rs332_mse: 0.0126 - output_rs332_accuracy: 0.9481 - output_rs332_precision: 0.9521 - output_spm_rs332_mse: 36.2062 - output_spm_rs332_accuracy: 0.4184\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.2845 - output_rs332_loss: 0.1031 - output_spm_rs332_loss: 36.2878 - output_rs332_mse: 0.0084 - output_rs332_accuracy: 0.9718 - output_rs332_precision: 0.9732 - output_spm_rs332_mse: 36.2878 - output_spm_rs332_accuracy: 0.4228\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.2774 - output_rs332_loss: 0.0967 - output_spm_rs332_loss: 36.1306 - output_rs332_mse: 0.0080 - output_rs332_accuracy: 0.9688 - output_rs332_precision: 0.9717 - output_spm_rs332_mse: 36.1306 - output_spm_rs332_accuracy: 0.4288\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.2438 - output_rs332_loss: 0.0646 - output_spm_rs332_loss: 35.8347 - output_rs332_mse: 0.0049 - output_rs332_accuracy: 0.9822 - output_rs332_precision: 0.9836 - output_spm_rs332_mse: 35.8347 - output_spm_rs332_accuracy: 0.4362\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.2875 - output_rs332_loss: 0.1088 - output_spm_rs332_loss: 35.7392 - output_rs332_mse: 0.0087 - output_rs332_accuracy: 0.9718 - output_rs332_precision: 0.9745 - output_spm_rs332_mse: 35.7392 - output_spm_rs332_accuracy: 0.4332\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.1994 - output_rs332_loss: 0.0211 - output_spm_rs332_loss: 35.6621 - output_rs332_mse: 0.0011 - output_rs332_accuracy: 0.9985 - output_rs332_precision: 0.9985 - output_spm_rs332_mse: 35.6621 - output_spm_rs332_accuracy: 0.4392\n",
            "Score for fold 3: loss of 2.83929181098938; output_rs332_loss of 2.652169704437256;output_spm_rs332_loss of 37.42442321777344;output_rs332_mse of 0.11299107223749161\n",
            "rs332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "correct\n",
            "(None, 300)\n",
            "New rs332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/30\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 1.8015 - output_rs332_loss: 1.5966 - output_spm_rs332_loss: 40.9886 - output_rs332_mse: 0.1258 - output_rs332_accuracy: 0.3496 - output_rs332_precision: 0.8333 - output_spm_rs332_mse: 40.9886 - output_spm_rs332_accuracy: 0.0163\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 1.4310 - output_rs332_loss: 1.2263 - output_spm_rs332_loss: 40.9443 - output_rs332_mse: 0.0992 - output_rs332_accuracy: 0.5600 - output_rs332_precision: 0.7417 - output_spm_rs332_mse: 40.9443 - output_spm_rs332_accuracy: 0.1926\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 1.2177 - output_rs332_loss: 1.0133 - output_spm_rs332_loss: 40.8690 - output_rs332_mse: 0.0825 - output_rs332_accuracy: 0.6430 - output_rs332_precision: 0.7931 - output_spm_rs332_mse: 40.8690 - output_spm_rs332_accuracy: 0.3185\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 1.1166 - output_rs332_loss: 0.9127 - output_spm_rs332_loss: 40.7792 - output_rs332_mse: 0.0744 - output_rs332_accuracy: 0.6830 - output_rs332_precision: 0.7978 - output_spm_rs332_mse: 40.7792 - output_spm_rs332_accuracy: 0.3881\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 1.0327 - output_rs332_loss: 0.8291 - output_spm_rs332_loss: 40.7140 - output_rs332_mse: 0.0683 - output_rs332_accuracy: 0.7111 - output_rs332_precision: 0.8020 - output_spm_rs332_mse: 40.7140 - output_spm_rs332_accuracy: 0.4252\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.9320 - output_rs332_loss: 0.7289 - output_spm_rs332_loss: 40.6108 - output_rs332_mse: 0.0607 - output_rs332_accuracy: 0.7422 - output_rs332_precision: 0.8293 - output_spm_rs332_mse: 40.6108 - output_spm_rs332_accuracy: 0.4133\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 6s 261ms/step - loss: 0.8582 - output_rs332_loss: 0.6557 - output_spm_rs332_loss: 40.5083 - output_rs332_mse: 0.0539 - output_rs332_accuracy: 0.7852 - output_rs332_precision: 0.8380 - output_spm_rs332_mse: 40.5083 - output_spm_rs332_accuracy: 0.4267\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.7851 - output_rs332_loss: 0.5831 - output_spm_rs332_loss: 40.4008 - output_rs332_mse: 0.0478 - output_rs332_accuracy: 0.8104 - output_rs332_precision: 0.8636 - output_spm_rs332_mse: 40.4008 - output_spm_rs332_accuracy: 0.4400\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.7515 - output_rs332_loss: 0.5502 - output_spm_rs332_loss: 40.2631 - output_rs332_mse: 0.0468 - output_rs332_accuracy: 0.8015 - output_rs332_precision: 0.8476 - output_spm_rs332_mse: 40.2631 - output_spm_rs332_accuracy: 0.4341\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.7157 - output_rs332_loss: 0.5149 - output_spm_rs332_loss: 40.1582 - output_rs332_mse: 0.0414 - output_rs332_accuracy: 0.8281 - output_rs332_precision: 0.8756 - output_spm_rs332_mse: 40.1582 - output_spm_rs332_accuracy: 0.4593\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.6550 - output_rs332_loss: 0.4548 - output_spm_rs332_loss: 40.0406 - output_rs332_mse: 0.0378 - output_rs332_accuracy: 0.8430 - output_rs332_precision: 0.8880 - output_spm_rs332_mse: 40.0406 - output_spm_rs332_accuracy: 0.4474\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.6224 - output_rs332_loss: 0.4230 - output_spm_rs332_loss: 39.8671 - output_rs332_mse: 0.0357 - output_rs332_accuracy: 0.8637 - output_rs332_precision: 0.8859 - output_spm_rs332_mse: 39.8671 - output_spm_rs332_accuracy: 0.4548\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.5809 - output_rs332_loss: 0.3829 - output_spm_rs332_loss: 39.6134 - output_rs332_mse: 0.0319 - output_rs332_accuracy: 0.8667 - output_rs332_precision: 0.8950 - output_spm_rs332_mse: 39.6134 - output_spm_rs332_accuracy: 0.4593\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.5654 - output_rs332_loss: 0.3679 - output_spm_rs332_loss: 39.5171 - output_rs332_mse: 0.0322 - output_rs332_accuracy: 0.8696 - output_rs332_precision: 0.8894 - output_spm_rs332_mse: 39.5171 - output_spm_rs332_accuracy: 0.4444\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.4818 - output_rs332_loss: 0.2849 - output_spm_rs332_loss: 39.3803 - output_rs332_mse: 0.0224 - output_rs332_accuracy: 0.9185 - output_rs332_precision: 0.9308 - output_spm_rs332_mse: 39.3803 - output_spm_rs332_accuracy: 0.4489\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.4662 - output_rs332_loss: 0.2701 - output_spm_rs332_loss: 39.2164 - output_rs332_mse: 0.0224 - output_rs332_accuracy: 0.9111 - output_rs332_precision: 0.9320 - output_spm_rs332_mse: 39.2164 - output_spm_rs332_accuracy: 0.4385\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.4268 - output_rs332_loss: 0.2309 - output_spm_rs332_loss: 39.1760 - output_rs332_mse: 0.0188 - output_rs332_accuracy: 0.9333 - output_rs332_precision: 0.9465 - output_spm_rs332_mse: 39.1760 - output_spm_rs332_accuracy: 0.4489\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.4810 - output_rs332_loss: 0.2864 - output_spm_rs332_loss: 38.9279 - output_rs332_mse: 0.0213 - output_rs332_accuracy: 0.9170 - output_rs332_precision: 0.9230 - output_spm_rs332_mse: 38.9279 - output_spm_rs332_accuracy: 0.4563\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.3799 - output_rs332_loss: 0.1863 - output_spm_rs332_loss: 38.7286 - output_rs332_mse: 0.0153 - output_rs332_accuracy: 0.9378 - output_rs332_precision: 0.9455 - output_spm_rs332_mse: 38.7286 - output_spm_rs332_accuracy: 0.4489\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.3708 - output_rs332_loss: 0.1771 - output_spm_rs332_loss: 38.7263 - output_rs332_mse: 0.0145 - output_rs332_accuracy: 0.9393 - output_rs332_precision: 0.9470 - output_spm_rs332_mse: 38.7263 - output_spm_rs332_accuracy: 0.4519\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.3603 - output_rs332_loss: 0.1679 - output_spm_rs332_loss: 38.4861 - output_rs332_mse: 0.0143 - output_rs332_accuracy: 0.9407 - output_rs332_precision: 0.9503 - output_spm_rs332_mse: 38.4861 - output_spm_rs332_accuracy: 0.4593\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.3724 - output_rs332_loss: 0.1809 - output_spm_rs332_loss: 38.3031 - output_rs332_mse: 0.0144 - output_rs332_accuracy: 0.9393 - output_rs332_precision: 0.9489 - output_spm_rs332_mse: 38.3031 - output_spm_rs332_accuracy: 0.4430\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.3396 - output_rs332_loss: 0.1492 - output_spm_rs332_loss: 38.0786 - output_rs332_mse: 0.0128 - output_rs332_accuracy: 0.9452 - output_rs332_precision: 0.9550 - output_spm_rs332_mse: 38.0786 - output_spm_rs332_accuracy: 0.4474\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.3074 - output_rs332_loss: 0.1171 - output_spm_rs332_loss: 38.0461 - output_rs332_mse: 0.0093 - output_rs332_accuracy: 0.9630 - output_rs332_precision: 0.9641 - output_spm_rs332_mse: 38.0461 - output_spm_rs332_accuracy: 0.4533\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.3055 - output_rs332_loss: 0.1164 - output_spm_rs332_loss: 37.8155 - output_rs332_mse: 0.0096 - output_rs332_accuracy: 0.9630 - output_rs332_precision: 0.9671 - output_spm_rs332_mse: 37.8155 - output_spm_rs332_accuracy: 0.4444\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.3094 - output_rs332_loss: 0.1204 - output_spm_rs332_loss: 37.7941 - output_rs332_mse: 0.0106 - output_rs332_accuracy: 0.9585 - output_rs332_precision: 0.9613 - output_spm_rs332_mse: 37.7941 - output_spm_rs332_accuracy: 0.4474\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.2566 - output_rs332_loss: 0.0693 - output_spm_rs332_loss: 37.4643 - output_rs332_mse: 0.0057 - output_rs332_accuracy: 0.9778 - output_rs332_precision: 0.9791 - output_spm_rs332_mse: 37.4643 - output_spm_rs332_accuracy: 0.4533\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.3012 - output_rs332_loss: 0.1132 - output_spm_rs332_loss: 37.6038 - output_rs332_mse: 0.0098 - output_rs332_accuracy: 0.9630 - output_rs332_precision: 0.9643 - output_spm_rs332_mse: 37.6038 - output_spm_rs332_accuracy: 0.4444\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.2742 - output_rs332_loss: 0.0882 - output_spm_rs332_loss: 37.2085 - output_rs332_mse: 0.0056 - output_rs332_accuracy: 0.9822 - output_rs332_precision: 0.9836 - output_spm_rs332_mse: 37.2085 - output_spm_rs332_accuracy: 0.4430\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.2796 - output_rs332_loss: 0.0932 - output_spm_rs332_loss: 37.2839 - output_rs332_mse: 0.0082 - output_rs332_accuracy: 0.9674 - output_rs332_precision: 0.9688 - output_spm_rs332_mse: 37.2839 - output_spm_rs332_accuracy: 0.4489\n",
            "Score for fold 4: loss of 1.6322171688079834; output_rs332_loss of 1.4508975744247437;output_spm_rs332_loss of 36.263916015625;output_rs332_mse of 0.07168090343475342\n",
            "rs332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "correct\n",
            "(None, 300)\n",
            "New rs332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/30\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 1.8196 - output_rs332_loss: 1.6196 - output_spm_rs332_loss: 39.9912 - output_rs332_mse: 0.1278 - output_rs332_accuracy: 0.3289 - output_rs332_precision: 0.6735 - output_spm_rs332_mse: 39.9912 - output_spm_rs332_accuracy: 0.0104\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 1.4454 - output_rs332_loss: 1.2455 - output_spm_rs332_loss: 39.9825 - output_rs332_mse: 0.1018 - output_rs332_accuracy: 0.5185 - output_rs332_precision: 0.7181 - output_spm_rs332_mse: 39.9825 - output_spm_rs332_accuracy: 0.0622\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 6s 261ms/step - loss: 1.2026 - output_rs332_loss: 1.0030 - output_spm_rs332_loss: 39.9330 - output_rs332_mse: 0.0831 - output_rs332_accuracy: 0.6444 - output_rs332_precision: 0.7719 - output_spm_rs332_mse: 39.9330 - output_spm_rs332_accuracy: 0.1807\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 6s 261ms/step - loss: 1.0894 - output_rs332_loss: 0.8901 - output_spm_rs332_loss: 39.8596 - output_rs332_mse: 0.0747 - output_rs332_accuracy: 0.6696 - output_rs332_precision: 0.7739 - output_spm_rs332_mse: 39.8596 - output_spm_rs332_accuracy: 0.2756\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 1.0070 - output_rs332_loss: 0.8081 - output_spm_rs332_loss: 39.7818 - output_rs332_mse: 0.0680 - output_rs332_accuracy: 0.7244 - output_rs332_precision: 0.7958 - output_spm_rs332_mse: 39.7818 - output_spm_rs332_accuracy: 0.2963\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.9450 - output_rs332_loss: 0.7465 - output_spm_rs332_loss: 39.7001 - output_rs332_mse: 0.0638 - output_rs332_accuracy: 0.7319 - output_rs332_precision: 0.7927 - output_spm_rs332_mse: 39.7001 - output_spm_rs332_accuracy: 0.3215\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 6s 261ms/step - loss: 0.8319 - output_rs332_loss: 0.6338 - output_spm_rs332_loss: 39.6330 - output_rs332_mse: 0.0531 - output_rs332_accuracy: 0.7837 - output_rs332_precision: 0.8415 - output_spm_rs332_mse: 39.6330 - output_spm_rs332_accuracy: 0.3378\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.8176 - output_rs332_loss: 0.6203 - output_spm_rs332_loss: 39.4690 - output_rs332_mse: 0.0531 - output_rs332_accuracy: 0.7881 - output_rs332_precision: 0.8440 - output_spm_rs332_mse: 39.4690 - output_spm_rs332_accuracy: 0.3659\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.7271 - output_rs332_loss: 0.5302 - output_spm_rs332_loss: 39.3911 - output_rs332_mse: 0.0464 - output_rs332_accuracy: 0.8104 - output_rs332_precision: 0.8411 - output_spm_rs332_mse: 39.3911 - output_spm_rs332_accuracy: 0.3778\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.6907 - output_rs332_loss: 0.4944 - output_spm_rs332_loss: 39.2599 - output_rs332_mse: 0.0416 - output_rs332_accuracy: 0.8267 - output_rs332_precision: 0.8683 - output_spm_rs332_mse: 39.2599 - output_spm_rs332_accuracy: 0.3881\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.6417 - output_rs332_loss: 0.4463 - output_spm_rs332_loss: 39.0751 - output_rs332_mse: 0.0378 - output_rs332_accuracy: 0.8430 - output_rs332_precision: 0.8680 - output_spm_rs332_mse: 39.0751 - output_spm_rs332_accuracy: 0.4000\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.6280 - output_rs332_loss: 0.4335 - output_spm_rs332_loss: 38.8971 - output_rs332_mse: 0.0372 - output_rs332_accuracy: 0.8415 - output_rs332_precision: 0.8740 - output_spm_rs332_mse: 38.8971 - output_spm_rs332_accuracy: 0.4133\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.5868 - output_rs332_loss: 0.3924 - output_spm_rs332_loss: 38.8712 - output_rs332_mse: 0.0333 - output_rs332_accuracy: 0.8667 - output_rs332_precision: 0.8871 - output_spm_rs332_mse: 38.8712 - output_spm_rs332_accuracy: 0.4030\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.5151 - output_rs332_loss: 0.3217 - output_spm_rs332_loss: 38.6805 - output_rs332_mse: 0.0280 - output_rs332_accuracy: 0.8859 - output_rs332_precision: 0.9081 - output_spm_rs332_mse: 38.6805 - output_spm_rs332_accuracy: 0.4267\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.5057 - output_rs332_loss: 0.3135 - output_spm_rs332_loss: 38.4399 - output_rs332_mse: 0.0261 - output_rs332_accuracy: 0.8919 - output_rs332_precision: 0.9180 - output_spm_rs332_mse: 38.4399 - output_spm_rs332_accuracy: 0.4207\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.5042 - output_rs332_loss: 0.3125 - output_spm_rs332_loss: 38.3345 - output_rs332_mse: 0.0265 - output_rs332_accuracy: 0.8933 - output_rs332_precision: 0.9070 - output_spm_rs332_mse: 38.3345 - output_spm_rs332_accuracy: 0.4222\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.4114 - output_rs332_loss: 0.2204 - output_spm_rs332_loss: 38.1993 - output_rs332_mse: 0.0186 - output_rs332_accuracy: 0.9274 - output_rs332_precision: 0.9421 - output_spm_rs332_mse: 38.1993 - output_spm_rs332_accuracy: 0.4119\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 6s 262ms/step - loss: 0.4251 - output_rs332_loss: 0.2355 - output_spm_rs332_loss: 37.9240 - output_rs332_mse: 0.0202 - output_rs332_accuracy: 0.9230 - output_rs332_precision: 0.9378 - output_spm_rs332_mse: 37.9240 - output_spm_rs332_accuracy: 0.4296\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.3457 - output_rs332_loss: 0.1572 - output_spm_rs332_loss: 37.7055 - output_rs332_mse: 0.0127 - output_rs332_accuracy: 0.9526 - output_rs332_precision: 0.9637 - output_spm_rs332_mse: 37.7055 - output_spm_rs332_accuracy: 0.4252\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.3805 - output_rs332_loss: 0.1926 - output_spm_rs332_loss: 37.5867 - output_rs332_mse: 0.0171 - output_rs332_accuracy: 0.9259 - output_rs332_precision: 0.9410 - output_spm_rs332_mse: 37.5867 - output_spm_rs332_accuracy: 0.4237\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 6s 262ms/step - loss: 0.3310 - output_rs332_loss: 0.1438 - output_spm_rs332_loss: 37.4580 - output_rs332_mse: 0.0111 - output_rs332_accuracy: 0.9570 - output_rs332_precision: 0.9625 - output_spm_rs332_mse: 37.4580 - output_spm_rs332_accuracy: 0.4193\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.3287 - output_rs332_loss: 0.1425 - output_spm_rs332_loss: 37.2331 - output_rs332_mse: 0.0122 - output_rs332_accuracy: 0.9585 - output_rs332_precision: 0.9638 - output_spm_rs332_mse: 37.2331 - output_spm_rs332_accuracy: 0.4193\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 6s 261ms/step - loss: 0.3077 - output_rs332_loss: 0.1233 - output_spm_rs332_loss: 36.8769 - output_rs332_mse: 0.0105 - output_rs332_accuracy: 0.9556 - output_rs332_precision: 0.9655 - output_spm_rs332_mse: 36.8769 - output_spm_rs332_accuracy: 0.4370\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.2795 - output_rs332_loss: 0.0955 - output_spm_rs332_loss: 36.7954 - output_rs332_mse: 0.0080 - output_rs332_accuracy: 0.9659 - output_rs332_precision: 0.9730 - output_spm_rs332_mse: 36.7954 - output_spm_rs332_accuracy: 0.4296\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 6s 262ms/step - loss: 0.3122 - output_rs332_loss: 0.1299 - output_spm_rs332_loss: 36.4561 - output_rs332_mse: 0.0110 - output_rs332_accuracy: 0.9585 - output_rs332_precision: 0.9641 - output_spm_rs332_mse: 36.4561 - output_spm_rs332_accuracy: 0.4370\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 6s 262ms/step - loss: 0.2329 - output_rs332_loss: 0.0514 - output_spm_rs332_loss: 36.2875 - output_rs332_mse: 0.0041 - output_rs332_accuracy: 0.9852 - output_rs332_precision: 0.9881 - output_spm_rs332_mse: 36.2875 - output_spm_rs332_accuracy: 0.4341\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.2781 - output_rs332_loss: 0.0984 - output_spm_rs332_loss: 35.9467 - output_rs332_mse: 0.0080 - output_rs332_accuracy: 0.9659 - output_rs332_precision: 0.9716 - output_spm_rs332_mse: 35.9467 - output_spm_rs332_accuracy: 0.4370\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 6s 262ms/step - loss: 0.2733 - output_rs332_loss: 0.0937 - output_spm_rs332_loss: 35.9193 - output_rs332_mse: 0.0067 - output_rs332_accuracy: 0.9793 - output_rs332_precision: 0.9807 - output_spm_rs332_mse: 35.9193 - output_spm_rs332_accuracy: 0.4296\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 6s 261ms/step - loss: 0.2088 - output_rs332_loss: 0.0308 - output_spm_rs332_loss: 35.6170 - output_rs332_mse: 0.0017 - output_rs332_accuracy: 0.9970 - output_rs332_precision: 0.9970 - output_spm_rs332_mse: 35.6170 - output_spm_rs332_accuracy: 0.4326\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 6s 261ms/step - loss: 0.2706 - output_rs332_loss: 0.0942 - output_spm_rs332_loss: 35.2659 - output_rs332_mse: 0.0085 - output_rs332_accuracy: 0.9630 - output_rs332_precision: 0.9658 - output_spm_rs332_mse: 35.2659 - output_spm_rs332_accuracy: 0.4400\n",
            "Score for fold 5: loss of 1.814603328704834; output_rs332_loss of 1.6120712757110596;output_spm_rs332_loss of 40.50645065307617;output_rs332_mse of 0.07066722214221954\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 1.581727147102356 - Accuracy: 0.7337278127670288 - Precision: 0.7454545497894287%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 1.7525690793991089 - Accuracy: 0.6331360936164856 - Precision: 0.6424242258071899%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 2.652169704437256 - Accuracy: 0.6153846383094788 - Precision: 0.6190476417541504%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 1.4508975744247437 - Accuracy: 0.7559523582458496 - Precision: 0.7636363506317139%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 1.6120712757110596 - Accuracy: 0.7559523582458496 - Precision: 0.7650602459907532%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 0.6988306522369385 (+- 0.06168079552100113)\n",
            "> Loss: 1.8098869562149047\n",
            "> Precision: 0.7071246027946472\n",
            "------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1NMd69uyKRF"
      },
      "source": [
        "#### Average of all five"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXVYgbX8b2y6",
        "outputId": "538a2a66-1b9f-4c3f-82a5-ff6c62b39d6f"
      },
      "source": [
        "loss,mse,acc,prec = kfold_validation(\"ensemble\",M1_ufc,M2_ufc,M3_ufc,M4_ufc,M5_ufc,Train_ufc_y,pca_SPM_cube_ufc_reloaded,32,30,1,5)\n",
        "results_diff[\"ensemble5\"] = np.array((loss,mse,acc,prec))\n",
        "filename = '/content/drive/MyDrive/ML_CSP774/Theory_project/3D-CNN Activity Recognition/Pickle/ensemble5_30epochs.pickle'\n",
        "with open(filename, 'wb') as f:\n",
        "    pickle.dump(results_diff[\"ensemble5\"], f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "s332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "rs332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "correct\n",
            "(None, 300)\n",
            "m332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 12, 18, 12) (None, 6, 10, 18, 12)\n",
            "(None, 6, 27, 6, 4)\n",
            "(None, 6, 27, 1, 1)\n",
            "(None, 162)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "m322\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 7, 18, 12) (None, 6, 14, 18, 12) (None, 6, 12, 18, 12)\n",
            "(None, 6, 33, 6, 4)\n",
            "(None, 6, 33, 1, 1)\n",
            "(None, 198)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "m222\n",
            "(None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 8, 72, 54) (None, 2, 8, 72, 54)\n",
            "(None, 2, 9, 24, 18) (None, 2, 18, 24, 18) (None, 2, 16, 24, 18)\n",
            "(None, 6, 9, 18, 12) (None, 6, 18, 18, 12) (None, 6, 16, 18, 12)\n",
            "(None, 6, 43, 6, 4)\n",
            "(None, 6, 43, 1, 1)\n",
            "(None, 258)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New ensemble model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 1.5735 - mse: 0.1252 - accuracy: 0.3680 - precision_5: 0.9167\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 1.1680 - mse: 0.0978 - accuracy: 0.5920 - precision_5: 0.8529\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.9895 - mse: 0.0842 - accuracy: 0.6350 - precision_5: 0.8645\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.8379 - mse: 0.0726 - accuracy: 0.7122 - precision_5: 0.8469\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.7692 - mse: 0.0667 - accuracy: 0.7285 - precision_5: 0.8548\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.6790 - mse: 0.0598 - accuracy: 0.7789 - precision_5: 0.8959\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.6027 - mse: 0.0527 - accuracy: 0.8160 - precision_5: 0.9085\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.5562 - mse: 0.0496 - accuracy: 0.8190 - precision_5: 0.9006\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.5074 - mse: 0.0446 - accuracy: 0.8576 - precision_5: 0.9206\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.4989 - mse: 0.0438 - accuracy: 0.8576 - precision_5: 0.9270\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.4385 - mse: 0.0385 - accuracy: 0.8813 - precision_5: 0.9385\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.4308 - mse: 0.0376 - accuracy: 0.8828 - precision_5: 0.9355\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3815 - mse: 0.0333 - accuracy: 0.9006 - precision_5: 0.9295\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3716 - mse: 0.0322 - accuracy: 0.8947 - precision_5: 0.9370\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3576 - mse: 0.0307 - accuracy: 0.9080 - precision_5: 0.9424\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3315 - mse: 0.0288 - accuracy: 0.9036 - precision_5: 0.9511\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3190 - mse: 0.0272 - accuracy: 0.9214 - precision_5: 0.9574\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3050 - mse: 0.0260 - accuracy: 0.9303 - precision_5: 0.9535\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2958 - mse: 0.0259 - accuracy: 0.9199 - precision_5: 0.9520\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2872 - mse: 0.0246 - accuracy: 0.9392 - precision_5: 0.9479\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2770 - mse: 0.0240 - accuracy: 0.9258 - precision_5: 0.9463\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2627 - mse: 0.0217 - accuracy: 0.9451 - precision_5: 0.9684\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2525 - mse: 0.0211 - accuracy: 0.9510 - precision_5: 0.9686\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2565 - mse: 0.0213 - accuracy: 0.9332 - precision_5: 0.9593\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2375 - mse: 0.0196 - accuracy: 0.9585 - precision_5: 0.9734\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2307 - mse: 0.0189 - accuracy: 0.9570 - precision_5: 0.9721\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2238 - mse: 0.0186 - accuracy: 0.9525 - precision_5: 0.9678\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2196 - mse: 0.0181 - accuracy: 0.9525 - precision_5: 0.9694\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2071 - mse: 0.0168 - accuracy: 0.9614 - precision_5: 0.9784\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2013 - mse: 0.0165 - accuracy: 0.9555 - precision_5: 0.9724\n",
            "Score for fold 1: loss of 0.8224301934242249; mse of 0.057939570397138596;accuracy of 0.7633135914802551;precision_5 of 0.8309859037399292\n",
            "s332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "rs332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "correct\n",
            "(None, 300)\n",
            "m332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 12, 18, 12) (None, 6, 10, 18, 12)\n",
            "(None, 6, 27, 6, 4)\n",
            "(None, 6, 27, 1, 1)\n",
            "(None, 162)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "m322\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 7, 18, 12) (None, 6, 14, 18, 12) (None, 6, 12, 18, 12)\n",
            "(None, 6, 33, 6, 4)\n",
            "(None, 6, 33, 1, 1)\n",
            "(None, 198)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "m222\n",
            "(None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 8, 72, 54) (None, 2, 8, 72, 54)\n",
            "(None, 2, 9, 24, 18) (None, 2, 18, 24, 18) (None, 2, 16, 24, 18)\n",
            "(None, 6, 9, 18, 12) (None, 6, 18, 18, 12) (None, 6, 16, 18, 12)\n",
            "(None, 6, 43, 6, 4)\n",
            "(None, 6, 43, 1, 1)\n",
            "(None, 258)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New ensemble model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 1.5962 - mse: 0.1267 - accuracy: 0.3709 - precision_5: 0.6667\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 1.1219 - mse: 0.0929 - accuracy: 0.6128 - precision_5: 0.9021\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.8936 - mse: 0.0749 - accuracy: 0.7151 - precision_5: 0.8644\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.7736 - mse: 0.0654 - accuracy: 0.7537 - precision_5: 0.8794\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.6912 - mse: 0.0595 - accuracy: 0.7715 - precision_5: 0.8845\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.6038 - mse: 0.0526 - accuracy: 0.8071 - precision_5: 0.8990\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.5541 - mse: 0.0471 - accuracy: 0.8338 - precision_5: 0.9174\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.5050 - mse: 0.0439 - accuracy: 0.8576 - precision_5: 0.9098\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.4723 - mse: 0.0407 - accuracy: 0.8501 - precision_5: 0.9217\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.4165 - mse: 0.0370 - accuracy: 0.8635 - precision_5: 0.9206\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3911 - mse: 0.0343 - accuracy: 0.8813 - precision_5: 0.9363\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3892 - mse: 0.0333 - accuracy: 0.8917 - precision_5: 0.9468\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3694 - mse: 0.0318 - accuracy: 0.8976 - precision_5: 0.9503\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3330 - mse: 0.0292 - accuracy: 0.8932 - precision_5: 0.9397\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3298 - mse: 0.0285 - accuracy: 0.9065 - precision_5: 0.9460\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3198 - mse: 0.0268 - accuracy: 0.9184 - precision_5: 0.9510\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2789 - mse: 0.0238 - accuracy: 0.9303 - precision_5: 0.9546\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2721 - mse: 0.0232 - accuracy: 0.9303 - precision_5: 0.9658\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2676 - mse: 0.0230 - accuracy: 0.9303 - precision_5: 0.9643\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2474 - mse: 0.0211 - accuracy: 0.9347 - precision_5: 0.9601\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2263 - mse: 0.0193 - accuracy: 0.9421 - precision_5: 0.9729\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2462 - mse: 0.0211 - accuracy: 0.9362 - precision_5: 0.9631\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2141 - mse: 0.0178 - accuracy: 0.9570 - precision_5: 0.9778\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2191 - mse: 0.0187 - accuracy: 0.9421 - precision_5: 0.9715\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2022 - mse: 0.0175 - accuracy: 0.9421 - precision_5: 0.9666\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.1969 - mse: 0.0166 - accuracy: 0.9421 - precision_5: 0.9746\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.1830 - mse: 0.0155 - accuracy: 0.9540 - precision_5: 0.9763\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.1836 - mse: 0.0151 - accuracy: 0.9614 - precision_5: 0.9736\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.1834 - mse: 0.0154 - accuracy: 0.9570 - precision_5: 0.9749\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.1751 - mse: 0.0148 - accuracy: 0.9614 - precision_5: 0.9797\n",
            "Score for fold 2: loss of 0.8642160296440125; mse of 0.057828035205602646;accuracy of 0.7633135914802551;precision_5 of 0.8405796885490417\n",
            "s332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "rs332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "correct\n",
            "(None, 300)\n",
            "m332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 12, 18, 12) (None, 6, 10, 18, 12)\n",
            "(None, 6, 27, 6, 4)\n",
            "(None, 6, 27, 1, 1)\n",
            "(None, 162)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "m322\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 7, 18, 12) (None, 6, 14, 18, 12) (None, 6, 12, 18, 12)\n",
            "(None, 6, 33, 6, 4)\n",
            "(None, 6, 33, 1, 1)\n",
            "(None, 198)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "m222\n",
            "(None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 8, 72, 54) (None, 2, 8, 72, 54)\n",
            "(None, 2, 9, 24, 18) (None, 2, 18, 24, 18) (None, 2, 16, 24, 18)\n",
            "(None, 6, 9, 18, 12) (None, 6, 18, 18, 12) (None, 6, 16, 18, 12)\n",
            "(None, 6, 43, 6, 4)\n",
            "(None, 6, 43, 1, 1)\n",
            "(None, 258)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New ensemble model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 1.6100 - mse: 0.1272 - accuracy: 0.3294 - precision_5: 0.6667\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 1.1620 - mse: 0.0962 - accuracy: 0.6217 - precision_5: 0.8466\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.9788 - mse: 0.0831 - accuracy: 0.6780 - precision_5: 0.8608\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.8387 - mse: 0.0724 - accuracy: 0.7107 - precision_5: 0.8672\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.7244 - mse: 0.0622 - accuracy: 0.7745 - precision_5: 0.8889\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.6615 - mse: 0.0573 - accuracy: 0.7774 - precision_5: 0.8933\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.5938 - mse: 0.0517 - accuracy: 0.8175 - precision_5: 0.8837\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.5223 - mse: 0.0457 - accuracy: 0.8383 - precision_5: 0.9154\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.4994 - mse: 0.0438 - accuracy: 0.8234 - precision_5: 0.9215\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.4516 - mse: 0.0396 - accuracy: 0.8620 - precision_5: 0.9218\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.4395 - mse: 0.0387 - accuracy: 0.8665 - precision_5: 0.9356\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.4047 - mse: 0.0356 - accuracy: 0.8798 - precision_5: 0.9237\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3933 - mse: 0.0342 - accuracy: 0.8976 - precision_5: 0.9378\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3526 - mse: 0.0309 - accuracy: 0.9050 - precision_5: 0.9453\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3340 - mse: 0.0286 - accuracy: 0.9199 - precision_5: 0.9443\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3200 - mse: 0.0277 - accuracy: 0.9169 - precision_5: 0.9492\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2981 - mse: 0.0258 - accuracy: 0.9288 - precision_5: 0.9545\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2941 - mse: 0.0254 - accuracy: 0.9421 - precision_5: 0.9673\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2843 - mse: 0.0244 - accuracy: 0.9362 - precision_5: 0.9653\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2562 - mse: 0.0215 - accuracy: 0.9525 - precision_5: 0.9671\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2412 - mse: 0.0202 - accuracy: 0.9510 - precision_5: 0.9748\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2343 - mse: 0.0199 - accuracy: 0.9585 - precision_5: 0.9702\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2409 - mse: 0.0205 - accuracy: 0.9392 - precision_5: 0.9639\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2190 - mse: 0.0184 - accuracy: 0.9629 - precision_5: 0.9781\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2253 - mse: 0.0190 - accuracy: 0.9510 - precision_5: 0.9673\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2093 - mse: 0.0178 - accuracy: 0.9585 - precision_5: 0.9736\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2039 - mse: 0.0169 - accuracy: 0.9674 - precision_5: 0.9800\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2047 - mse: 0.0169 - accuracy: 0.9629 - precision_5: 0.9813\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.1954 - mse: 0.0162 - accuracy: 0.9688 - precision_5: 0.9830\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.1964 - mse: 0.0164 - accuracy: 0.9659 - precision_5: 0.9784\n",
            "Score for fold 3: loss of 0.7409621477127075; mse of 0.051610156893730164;accuracy of 0.7692307829856873;precision_5 of 0.8472222089767456\n",
            "s332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "rs332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "correct\n",
            "(None, 300)\n",
            "m332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 12, 18, 12) (None, 6, 10, 18, 12)\n",
            "(None, 6, 27, 6, 4)\n",
            "(None, 6, 27, 1, 1)\n",
            "(None, 162)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "m322\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 7, 18, 12) (None, 6, 14, 18, 12) (None, 6, 12, 18, 12)\n",
            "(None, 6, 33, 6, 4)\n",
            "(None, 6, 33, 1, 1)\n",
            "(None, 198)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "m222\n",
            "(None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 8, 72, 54) (None, 2, 8, 72, 54)\n",
            "(None, 2, 9, 24, 18) (None, 2, 18, 24, 18) (None, 2, 16, 24, 18)\n",
            "(None, 6, 9, 18, 12) (None, 6, 18, 18, 12) (None, 6, 16, 18, 12)\n",
            "(None, 6, 43, 6, 4)\n",
            "(None, 6, 43, 1, 1)\n",
            "(None, 258)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New ensemble model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 1.5819 - mse: 0.1250 - accuracy: 0.3600 - precision_5: 0.7600\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 1.1238 - mse: 0.0927 - accuracy: 0.6133 - precision_5: 0.8384\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.9285 - mse: 0.0779 - accuracy: 0.6844 - precision_5: 0.8352\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.7806 - mse: 0.0650 - accuracy: 0.7541 - precision_5: 0.8838\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.7006 - mse: 0.0600 - accuracy: 0.7659 - precision_5: 0.8884\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.6365 - mse: 0.0538 - accuracy: 0.7867 - precision_5: 0.8961\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.5723 - mse: 0.0495 - accuracy: 0.8163 - precision_5: 0.8853\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.5224 - mse: 0.0456 - accuracy: 0.8281 - precision_5: 0.9022\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.4665 - mse: 0.0404 - accuracy: 0.8489 - precision_5: 0.9133\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.4376 - mse: 0.0376 - accuracy: 0.8593 - precision_5: 0.9288\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3890 - mse: 0.0336 - accuracy: 0.8919 - precision_5: 0.9426\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3649 - mse: 0.0310 - accuracy: 0.9111 - precision_5: 0.9450\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3566 - mse: 0.0304 - accuracy: 0.9081 - precision_5: 0.9463\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3205 - mse: 0.0278 - accuracy: 0.9126 - precision_5: 0.9477\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3011 - mse: 0.0251 - accuracy: 0.9259 - precision_5: 0.9643\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2835 - mse: 0.0240 - accuracy: 0.9319 - precision_5: 0.9488\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2663 - mse: 0.0222 - accuracy: 0.9363 - precision_5: 0.9618\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2654 - mse: 0.0219 - accuracy: 0.9422 - precision_5: 0.9682\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2363 - mse: 0.0194 - accuracy: 0.9556 - precision_5: 0.9705\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2478 - mse: 0.0204 - accuracy: 0.9556 - precision_5: 0.9698\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2185 - mse: 0.0177 - accuracy: 0.9644 - precision_5: 0.9739\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2153 - mse: 0.0176 - accuracy: 0.9585 - precision_5: 0.9798\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.1955 - mse: 0.0158 - accuracy: 0.9689 - precision_5: 0.9799\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.1975 - mse: 0.0160 - accuracy: 0.9600 - precision_5: 0.9768\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.1871 - mse: 0.0150 - accuracy: 0.9719 - precision_5: 0.9800\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.1795 - mse: 0.0147 - accuracy: 0.9659 - precision_5: 0.9769\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.1677 - mse: 0.0136 - accuracy: 0.9733 - precision_5: 0.9831\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.1745 - mse: 0.0139 - accuracy: 0.9748 - precision_5: 0.9862\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.1670 - mse: 0.0135 - accuracy: 0.9704 - precision_5: 0.9785\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.1609 - mse: 0.0128 - accuracy: 0.9748 - precision_5: 0.9862\n",
            "Score for fold 4: loss of 0.9468031525611877; mse of 0.05775097385048866;accuracy of 0.7797619104385376;precision_5 of 0.8321678042411804\n",
            "s332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "rs332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "correct\n",
            "(None, 300)\n",
            "m332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 12, 18, 12) (None, 6, 10, 18, 12)\n",
            "(None, 6, 27, 6, 4)\n",
            "(None, 6, 27, 1, 1)\n",
            "(None, 162)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "m322\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 7, 18, 12) (None, 6, 14, 18, 12) (None, 6, 12, 18, 12)\n",
            "(None, 6, 33, 6, 4)\n",
            "(None, 6, 33, 1, 1)\n",
            "(None, 198)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "m222\n",
            "(None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 8, 72, 54) (None, 2, 8, 72, 54)\n",
            "(None, 2, 9, 24, 18) (None, 2, 18, 24, 18) (None, 2, 16, 24, 18)\n",
            "(None, 6, 9, 18, 12) (None, 6, 18, 18, 12) (None, 6, 16, 18, 12)\n",
            "(None, 6, 43, 6, 4)\n",
            "(None, 6, 43, 1, 1)\n",
            "(None, 258)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New ensemble model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 1.6363 - mse: 0.1286 - accuracy: 0.3304 - precision_5: 1.0000\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 1.2299 - mse: 0.1005 - accuracy: 0.5852 - precision_5: 0.9712\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 1.0329 - mse: 0.0863 - accuracy: 0.6593 - precision_5: 0.8610\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.8893 - mse: 0.0748 - accuracy: 0.7141 - precision_5: 0.8902\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.8084 - mse: 0.0692 - accuracy: 0.7215 - precision_5: 0.8831\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.6898 - mse: 0.0599 - accuracy: 0.7837 - precision_5: 0.9002\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.6721 - mse: 0.0580 - accuracy: 0.7822 - precision_5: 0.8979\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.6023 - mse: 0.0530 - accuracy: 0.8119 - precision_5: 0.8889\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.5553 - mse: 0.0482 - accuracy: 0.8311 - precision_5: 0.9118\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.5071 - mse: 0.0440 - accuracy: 0.8726 - precision_5: 0.9251\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.4805 - mse: 0.0420 - accuracy: 0.8696 - precision_5: 0.9063\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.4324 - mse: 0.0375 - accuracy: 0.8770 - precision_5: 0.9254\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.4048 - mse: 0.0352 - accuracy: 0.8874 - precision_5: 0.9439\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3835 - mse: 0.0330 - accuracy: 0.9022 - precision_5: 0.9429\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3789 - mse: 0.0326 - accuracy: 0.9081 - precision_5: 0.9386\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3406 - mse: 0.0291 - accuracy: 0.9215 - precision_5: 0.9568\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3268 - mse: 0.0278 - accuracy: 0.9274 - precision_5: 0.9541\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3279 - mse: 0.0280 - accuracy: 0.9170 - precision_5: 0.9538\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3198 - mse: 0.0270 - accuracy: 0.9259 - precision_5: 0.9513\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3002 - mse: 0.0252 - accuracy: 0.9289 - precision_5: 0.9689\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2910 - mse: 0.0246 - accuracy: 0.9333 - precision_5: 0.9597\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2748 - mse: 0.0232 - accuracy: 0.9437 - precision_5: 0.9557\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2890 - mse: 0.0234 - accuracy: 0.9422 - precision_5: 0.9628\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2526 - mse: 0.0211 - accuracy: 0.9437 - precision_5: 0.9679\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2844 - mse: 0.0224 - accuracy: 0.9393 - precision_5: 0.9587\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2370 - mse: 0.0195 - accuracy: 0.9644 - precision_5: 0.9793\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2361 - mse: 0.0200 - accuracy: 0.9496 - precision_5: 0.9655\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2301 - mse: 0.0188 - accuracy: 0.9511 - precision_5: 0.9671\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2275 - mse: 0.0189 - accuracy: 0.9541 - precision_5: 0.9719\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2123 - mse: 0.0172 - accuracy: 0.9644 - precision_5: 0.9843\n",
            "Score for fold 5: loss of 1.016646385192871; mse of 0.06918780505657196;accuracy of 0.726190447807312;precision_5 of 0.7857142686843872\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 0.8224301934242249 - Accuracy: 0.7633135914802551 - Precision: 0.8309859037399292%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 0.8642160296440125 - Accuracy: 0.7633135914802551 - Precision: 0.8405796885490417%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 0.7409621477127075 - Accuracy: 0.7692307829856873 - Precision: 0.8472222089767456%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 0.9468031525611877 - Accuracy: 0.7797619104385376 - Precision: 0.8321678042411804%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 1.016646385192871 - Accuracy: 0.726190447807312 - Precision: 0.7857142686843872%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 0.7603620648384094 (+- 0.018111491382212037)\n",
            "> Loss: 0.8782115817070008\n",
            "> Precision: 0.8273339748382569\n",
            "------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVcZDSj5tv_0",
        "outputId": "2421ec84-9741-4984-c96c-4bae784af09b"
      },
      "source": [
        "print(results_diff)\n",
        "filename = '/content/drive/MyDrive/ML_CSP774/Theory_project/3D-CNN Activity Recognition/Pickle/all_tanh_RMSProp_30epochs.pickle'\n",
        "with open(filename, 'wb') as f:\n",
        "    pickle.dump(results_diff, f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'s332': array([[1.73843312, 2.97069669, 1.9106369 , 2.27589703, 1.62567008],\n",
            "       [0.06662584, 0.1085136 , 0.08502801, 0.10118589, 0.07481257],\n",
            "       [0.77514791, 0.63313609, 0.68639052, 0.65476191, 0.72619045],\n",
            "       [0.77976191, 0.63313609, 0.70303029, 0.65662652, 0.7305389 ]]), 'm332': array([[1.7556864 , 1.61394954, 1.39328837, 1.53206849, 1.45437217],\n",
            "       [0.09262872, 0.0756221 , 0.08638125, 0.08375923, 0.07239294],\n",
            "       [0.6745562 , 0.71597636, 0.69230771, 0.69047618, 0.73809522],\n",
            "       [0.68711656, 0.73456788, 0.68862277, 0.70303029, 0.75      ]]), 'm322': array([[1.5167408 , 1.55874836, 1.00623989, 1.41281676, 1.14461493],\n",
            "       [0.08541694, 0.07974398, 0.0698203 , 0.08627059, 0.08041979],\n",
            "       [0.70414203, 0.72189349, 0.72781062, 0.66071427, 0.70238096],\n",
            "       [0.7037037 , 0.72891569, 0.74233127, 0.66666669, 0.71951222]]), 'm222': array([[1.65126264, 1.31799638, 1.91585577, 1.20069337, 1.52067256],\n",
            "       [0.08936648, 0.08787273, 0.11723122, 0.07197239, 0.08243452],\n",
            "       [0.68639052, 0.68639052, 0.55621302, 0.73809522, 0.70238096],\n",
            "       [0.69047618, 0.68518519, 0.56790125, 0.74698794, 0.71084338]]), 'rs332': array([[1.58172715, 1.75256908, 2.6521697 , 1.45089757, 1.61207128],\n",
            "       [0.07282824, 0.099803  , 0.11299107, 0.0716809 , 0.07066722],\n",
            "       [0.73372781, 0.63313609, 0.61538464, 0.75595236, 0.75595236],\n",
            "       [0.74545455, 0.64242423, 0.61904764, 0.76363635, 0.76506025]]), 'ensemble5': array([[0.82243019, 0.86421603, 0.74096215, 0.94680315, 1.01664639],\n",
            "       [0.05793957, 0.05782804, 0.05161016, 0.05775097, 0.06918781],\n",
            "       [0.76331359, 0.76331359, 0.76923078, 0.77976191, 0.72619045],\n",
            "       [0.8309859 , 0.84057969, 0.84722221, 0.8321678 , 0.78571427]])}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OwjXOTJyPaw"
      },
      "source": [
        "## Tanh and RMSProp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZJz9IfZi68z"
      },
      "source": [
        "### Model s332"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnPVLPCura48",
        "outputId": "4e0869d2-7ecc-4dc4-fc6f-33af33200749"
      },
      "source": [
        "results_tanh = {}\n",
        "loss,mse,acc,prec = kfold_validation(\"s332\",M1_ufc,M2_ufc,M3_ufc,M4_ufc,M5_ufc,Train_ufc_y,pca_SPM_cube_ufc_reloaded,32,25,1,None,\"tanh\")\n",
        "results_tanh[\"s332\"] = np.array((loss,mse,acc,prec))\n",
        "filename = '/content/drive/MyDrive/ML_CSP774/Theory_project/3D-CNN Activity Recognition/Pickle/s332_30epochs_tanh.pickle'\n",
        "with open(filename, 'wb') as f:\n",
        "    pickle.dump(results_tanh[\"s332\"], f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "s332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New s332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 1.4226 - mse: 0.1138 - accuracy: 0.4303 - precision: 0.8060\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 1.0743 - mse: 0.0913 - accuracy: 0.5816 - precision: 0.7249\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.9389 - mse: 0.0799 - accuracy: 0.6454 - precision: 0.7770\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.8602 - mse: 0.0729 - accuracy: 0.6884 - precision: 0.7751\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 6s 250ms/step - loss: 0.8029 - mse: 0.0679 - accuracy: 0.7107 - precision: 0.7914\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.7357 - mse: 0.0616 - accuracy: 0.7537 - precision: 0.8244\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.6851 - mse: 0.0584 - accuracy: 0.7685 - precision: 0.8294\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.6321 - mse: 0.0532 - accuracy: 0.7774 - precision: 0.8342\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.5707 - mse: 0.0490 - accuracy: 0.7953 - precision: 0.8557\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.5334 - mse: 0.0453 - accuracy: 0.8116 - precision: 0.8622\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 5s 250ms/step - loss: 0.4913 - mse: 0.0420 - accuracy: 0.8220 - precision: 0.8666\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.4503 - mse: 0.0384 - accuracy: 0.8338 - precision: 0.8946\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.4128 - mse: 0.0340 - accuracy: 0.8620 - precision: 0.9054\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.3522 - mse: 0.0286 - accuracy: 0.8917 - precision: 0.9185\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.3368 - mse: 0.0272 - accuracy: 0.8947 - precision: 0.9198\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.2997 - mse: 0.0251 - accuracy: 0.9006 - precision: 0.9198\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.2661 - mse: 0.0215 - accuracy: 0.9169 - precision: 0.9357\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.2294 - mse: 0.0187 - accuracy: 0.9303 - precision: 0.9473\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 5s 250ms/step - loss: 0.2198 - mse: 0.0173 - accuracy: 0.9451 - precision: 0.9629\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 6s 252ms/step - loss: 0.1838 - mse: 0.0147 - accuracy: 0.9510 - precision: 0.9664\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.1837 - mse: 0.0142 - accuracy: 0.9510 - precision: 0.9651\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 6s 250ms/step - loss: 0.1451 - mse: 0.0114 - accuracy: 0.9585 - precision: 0.9683\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.1150 - mse: 0.0085 - accuracy: 0.9733 - precision: 0.9848\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.1036 - mse: 0.0074 - accuracy: 0.9822 - precision: 0.9894\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.0893 - mse: 0.0061 - accuracy: 0.9866 - precision: 0.9896\n",
            "Score for fold 1: loss of 1.4975788593292236; mse of 0.08859553933143616;accuracy of 0.6863905191421509;precision of 0.682634711265564\n",
            "s332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New s332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 1.4117 - mse: 0.1145 - accuracy: 0.4303 - precision: 0.7188\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 1.0339 - mse: 0.0873 - accuracy: 0.6246 - precision: 0.7358\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 5s 250ms/step - loss: 0.8888 - mse: 0.0756 - accuracy: 0.6706 - precision: 0.7694\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.8023 - mse: 0.0674 - accuracy: 0.7033 - precision: 0.8086\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.7377 - mse: 0.0622 - accuracy: 0.7255 - precision: 0.8042\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.6684 - mse: 0.0569 - accuracy: 0.7567 - precision: 0.8231\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 6s 250ms/step - loss: 0.6123 - mse: 0.0511 - accuracy: 0.7967 - precision: 0.8610\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.5620 - mse: 0.0483 - accuracy: 0.8056 - precision: 0.8508\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.5008 - mse: 0.0428 - accuracy: 0.8220 - precision: 0.8687\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.4730 - mse: 0.0402 - accuracy: 0.8234 - precision: 0.8672\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.4527 - mse: 0.0392 - accuracy: 0.8323 - precision: 0.8804\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.3812 - mse: 0.0314 - accuracy: 0.8754 - precision: 0.9147\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 6s 250ms/step - loss: 0.3683 - mse: 0.0310 - accuracy: 0.8724 - precision: 0.9220\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 5s 250ms/step - loss: 0.3130 - mse: 0.0257 - accuracy: 0.9065 - precision: 0.9378\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.2944 - mse: 0.0248 - accuracy: 0.9050 - precision: 0.9317\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.2499 - mse: 0.0205 - accuracy: 0.9214 - precision: 0.9453\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.2257 - mse: 0.0182 - accuracy: 0.9392 - precision: 0.9550\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.2000 - mse: 0.0161 - accuracy: 0.9407 - precision: 0.9614\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.1604 - mse: 0.0126 - accuracy: 0.9570 - precision: 0.9738\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 5s 250ms/step - loss: 0.1556 - mse: 0.0127 - accuracy: 0.9599 - precision: 0.9695\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.1171 - mse: 0.0083 - accuracy: 0.9822 - precision: 0.9850\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.1191 - mse: 0.0094 - accuracy: 0.9718 - precision: 0.9790\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.0863 - mse: 0.0059 - accuracy: 0.9866 - precision: 0.9880\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.0688 - mse: 0.0044 - accuracy: 0.9852 - precision: 0.9925\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 6s 250ms/step - loss: 0.0578 - mse: 0.0034 - accuracy: 0.9941 - precision: 0.9955\n",
            "Score for fold 2: loss of 1.4154016971588135; mse of 0.08141732215881348;accuracy of 0.692307710647583;precision of 0.707317054271698\n",
            "s332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New s332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 1.4527 - mse: 0.1175 - accuracy: 0.4154 - precision: 0.6694\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 1.0498 - mse: 0.0887 - accuracy: 0.5964 - precision: 0.7590\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.9207 - mse: 0.0779 - accuracy: 0.6617 - precision: 0.7642\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.8304 - mse: 0.0710 - accuracy: 0.6914 - precision: 0.7769\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.7552 - mse: 0.0645 - accuracy: 0.7092 - precision: 0.8034\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.7003 - mse: 0.0593 - accuracy: 0.7493 - precision: 0.8185\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.6254 - mse: 0.0529 - accuracy: 0.7834 - precision: 0.8561\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.5863 - mse: 0.0496 - accuracy: 0.8042 - precision: 0.8549\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.5320 - mse: 0.0460 - accuracy: 0.8086 - precision: 0.8666\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.4844 - mse: 0.0413 - accuracy: 0.8353 - precision: 0.8735\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 5s 250ms/step - loss: 0.4440 - mse: 0.0368 - accuracy: 0.8561 - precision: 0.8929\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.4055 - mse: 0.0350 - accuracy: 0.8605 - precision: 0.8882\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.3429 - mse: 0.0292 - accuracy: 0.8739 - precision: 0.9155\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.2975 - mse: 0.0238 - accuracy: 0.9080 - precision: 0.9376\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 6s 250ms/step - loss: 0.2723 - mse: 0.0222 - accuracy: 0.9184 - precision: 0.9424\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.2231 - mse: 0.0185 - accuracy: 0.9332 - precision: 0.9406\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.1955 - mse: 0.0155 - accuracy: 0.9377 - precision: 0.9539\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.1754 - mse: 0.0144 - accuracy: 0.9466 - precision: 0.9544\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.1572 - mse: 0.0125 - accuracy: 0.9614 - precision: 0.9666\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.1357 - mse: 0.0102 - accuracy: 0.9718 - precision: 0.9789\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.0944 - mse: 0.0062 - accuracy: 0.9852 - precision: 0.9895\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.0871 - mse: 0.0064 - accuracy: 0.9807 - precision: 0.9821\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.0839 - mse: 0.0057 - accuracy: 0.9852 - precision: 0.9881\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.0520 - mse: 0.0030 - accuracy: 0.9911 - precision: 0.9940\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.0475 - mse: 0.0028 - accuracy: 0.9911 - precision: 0.9926\n",
            "Score for fold 3: loss of 1.4544650316238403; mse of 0.09278590977191925;accuracy of 0.6508875489234924;precision of 0.6604938507080078\n",
            "s332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New s332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 1.3773 - mse: 0.1119 - accuracy: 0.4430 - precision: 0.7661\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.9502 - mse: 0.0805 - accuracy: 0.6459 - precision: 0.7657\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.8555 - mse: 0.0720 - accuracy: 0.6978 - precision: 0.8060\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.7685 - mse: 0.0662 - accuracy: 0.7022 - precision: 0.7964\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 6s 250ms/step - loss: 0.7046 - mse: 0.0595 - accuracy: 0.7585 - precision: 0.8321\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.6421 - mse: 0.0543 - accuracy: 0.7733 - precision: 0.8561\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.5848 - mse: 0.0491 - accuracy: 0.7956 - precision: 0.8586\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.5335 - mse: 0.0449 - accuracy: 0.8133 - precision: 0.8646\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 5s 250ms/step - loss: 0.4973 - mse: 0.0422 - accuracy: 0.8281 - precision: 0.8831\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.4522 - mse: 0.0381 - accuracy: 0.8400 - precision: 0.8869\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.4196 - mse: 0.0356 - accuracy: 0.8489 - precision: 0.9022\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.3779 - mse: 0.0318 - accuracy: 0.8726 - precision: 0.9185\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.3368 - mse: 0.0283 - accuracy: 0.8919 - precision: 0.9266\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.2919 - mse: 0.0244 - accuracy: 0.9022 - precision: 0.9340\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.2662 - mse: 0.0215 - accuracy: 0.9289 - precision: 0.9496\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.2509 - mse: 0.0218 - accuracy: 0.9156 - precision: 0.9274\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.2193 - mse: 0.0181 - accuracy: 0.9333 - precision: 0.9548\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.1760 - mse: 0.0141 - accuracy: 0.9496 - precision: 0.9604\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.1480 - mse: 0.0114 - accuracy: 0.9615 - precision: 0.9700\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.1353 - mse: 0.0106 - accuracy: 0.9659 - precision: 0.9726\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.1053 - mse: 0.0074 - accuracy: 0.9793 - precision: 0.9880\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.0872 - mse: 0.0055 - accuracy: 0.9867 - precision: 0.9911\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.0771 - mse: 0.0053 - accuracy: 0.9852 - precision: 0.9896\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.0570 - mse: 0.0035 - accuracy: 0.9896 - precision: 0.9896\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.0556 - mse: 0.0039 - accuracy: 0.9896 - precision: 0.9911\n",
            "Score for fold 4: loss of 1.7646199464797974; mse of 0.0979594811797142;accuracy of 0.636904776096344;precision of 0.6583850979804993\n",
            "s332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New s332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 1.4324 - mse: 0.1153 - accuracy: 0.4252 - precision: 0.7797\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 1.0476 - mse: 0.0878 - accuracy: 0.6059 - precision: 0.7748\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.9093 - mse: 0.0772 - accuracy: 0.6459 - precision: 0.7770\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.8037 - mse: 0.0682 - accuracy: 0.7067 - precision: 0.8012\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.7211 - mse: 0.0611 - accuracy: 0.7407 - precision: 0.8132\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.6446 - mse: 0.0544 - accuracy: 0.7644 - precision: 0.8445\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.5906 - mse: 0.0500 - accuracy: 0.7970 - precision: 0.8549\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 6s 250ms/step - loss: 0.5427 - mse: 0.0457 - accuracy: 0.8089 - precision: 0.8652\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.4998 - mse: 0.0420 - accuracy: 0.8296 - precision: 0.8966\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 5s 250ms/step - loss: 0.4469 - mse: 0.0374 - accuracy: 0.8430 - precision: 0.8911\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.4222 - mse: 0.0350 - accuracy: 0.8504 - precision: 0.9061\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.3722 - mse: 0.0300 - accuracy: 0.8756 - precision: 0.9267\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.3251 - mse: 0.0275 - accuracy: 0.8904 - precision: 0.9216\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.3102 - mse: 0.0261 - accuracy: 0.8933 - precision: 0.9272\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.2539 - mse: 0.0209 - accuracy: 0.9200 - precision: 0.9482\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.2389 - mse: 0.0202 - accuracy: 0.9170 - precision: 0.9326\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 5s 250ms/step - loss: 0.2126 - mse: 0.0175 - accuracy: 0.9333 - precision: 0.9490\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 6s 250ms/step - loss: 0.1629 - mse: 0.0127 - accuracy: 0.9570 - precision: 0.9710\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.1467 - mse: 0.0112 - accuracy: 0.9630 - precision: 0.9772\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.1256 - mse: 0.0095 - accuracy: 0.9763 - precision: 0.9819\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 5s 250ms/step - loss: 0.1136 - mse: 0.0086 - accuracy: 0.9689 - precision: 0.9730\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 5s 250ms/step - loss: 0.0995 - mse: 0.0068 - accuracy: 0.9748 - precision: 0.9850\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.0632 - mse: 0.0039 - accuracy: 0.9896 - precision: 0.9940\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.0615 - mse: 0.0041 - accuracy: 0.9867 - precision: 0.9910\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.0477 - mse: 0.0029 - accuracy: 0.9926 - precision: 0.9926\n",
            "Score for fold 5: loss of 1.8750003576278687; mse of 0.0981888547539711;accuracy of 0.6547619104385376;precision of 0.6564416885375977\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 1.4975788593292236 - Accuracy: 0.6863905191421509 - Precision: 0.682634711265564%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 1.4154016971588135 - Accuracy: 0.692307710647583 - Precision: 0.707317054271698%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 1.4544650316238403 - Accuracy: 0.6508875489234924 - Precision: 0.6604938507080078%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 1.7646199464797974 - Accuracy: 0.636904776096344 - Precision: 0.6583850979804993%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 1.8750003576278687 - Accuracy: 0.6547619104385376 - Precision: 0.6564416885375977%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 0.6642504930496216 (+- 0.021418580373551478)\n",
            "> Loss: 1.6014131784439087\n",
            "> Precision: 0.6730544805526734\n",
            "------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7z6jYN0i-IX"
      },
      "source": [
        "### Model m332"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sr599twfCKM",
        "outputId": "13ba050d-b0ec-4c0e-e7aa-6051f6f3274d"
      },
      "source": [
        "loss,mse,acc,prec = kfold_validation(\"m332\",M1_ufc,M2_ufc,M3_ufc,M4_ufc,M5_ufc,Train_ufc_y,pca_SPM_cube_ufc_reloaded,32,25,1,None,\"tanh\")\n",
        "results_tanh[\"m332\"] = np.array((loss,mse,acc,prec))\n",
        "filename = '/content/drive/MyDrive/ML_CSP774/Theory_project/3D-CNN Activity Recognition/Pickle/m332_25epochs_tanh.pickle'\n",
        "with open(filename, 'wb') as f:\n",
        "    pickle.dump(results_tanh[\"m332\"], f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "m332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 12, 18, 12) (None, 6, 10, 18, 12)\n",
            "(None, 6, 27, 6, 4)\n",
            "(None, 6, 27, 1, 1)\n",
            "(None, 162)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 1.4787 - mse: 0.1179 - accuracy: 0.4080 - precision: 0.7404\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 1.0736 - mse: 0.0900 - accuracy: 0.5623 - precision: 0.7485\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 5s 243ms/step - loss: 0.9293 - mse: 0.0784 - accuracy: 0.6558 - precision: 0.7672\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.8316 - mse: 0.0708 - accuracy: 0.6825 - precision: 0.7978\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.7542 - mse: 0.0639 - accuracy: 0.7226 - precision: 0.8027\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.6814 - mse: 0.0586 - accuracy: 0.7582 - precision: 0.8177\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.6127 - mse: 0.0530 - accuracy: 0.7685 - precision: 0.8499\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.5586 - mse: 0.0486 - accuracy: 0.7878 - precision: 0.8503\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.5283 - mse: 0.0449 - accuracy: 0.8145 - precision: 0.8602\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.4922 - mse: 0.0431 - accuracy: 0.8116 - precision: 0.8671\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.4288 - mse: 0.0378 - accuracy: 0.8442 - precision: 0.8940\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.3795 - mse: 0.0335 - accuracy: 0.8516 - precision: 0.8980\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.3529 - mse: 0.0305 - accuracy: 0.8769 - precision: 0.9084\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.3172 - mse: 0.0272 - accuracy: 0.8917 - precision: 0.9239\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.2932 - mse: 0.0254 - accuracy: 0.8947 - precision: 0.9219\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.2616 - mse: 0.0221 - accuracy: 0.9095 - precision: 0.9300\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.2502 - mse: 0.0213 - accuracy: 0.9169 - precision: 0.9393\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.2004 - mse: 0.0166 - accuracy: 0.9421 - precision: 0.9497\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.1841 - mse: 0.0148 - accuracy: 0.9421 - precision: 0.9574\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.1828 - mse: 0.0159 - accuracy: 0.9421 - precision: 0.9501\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.1647 - mse: 0.0135 - accuracy: 0.9510 - precision: 0.9607\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.1246 - mse: 0.0097 - accuracy: 0.9688 - precision: 0.9788\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.1305 - mse: 0.0102 - accuracy: 0.9733 - precision: 0.9774\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.0987 - mse: 0.0074 - accuracy: 0.9792 - precision: 0.9820\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.1006 - mse: 0.0081 - accuracy: 0.9733 - precision: 0.9760\n",
            "Score for fold 1: loss of 2.232710361480713; mse of 0.10517896711826324;accuracy of 0.6153846383094788;precision of 0.6397515535354614\n",
            "m332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 12, 18, 12) (None, 6, 10, 18, 12)\n",
            "(None, 6, 27, 6, 4)\n",
            "(None, 6, 27, 1, 1)\n",
            "(None, 162)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 1.4808 - mse: 0.1192 - accuracy: 0.3887 - precision: 0.6737\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 1.0974 - mse: 0.0920 - accuracy: 0.5786 - precision: 0.7143\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.9321 - mse: 0.0785 - accuracy: 0.6558 - precision: 0.7706\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.8441 - mse: 0.0715 - accuracy: 0.6869 - precision: 0.7900\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.7668 - mse: 0.0656 - accuracy: 0.7226 - precision: 0.7973\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.7058 - mse: 0.0597 - accuracy: 0.7374 - precision: 0.8177\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.6555 - mse: 0.0551 - accuracy: 0.7715 - precision: 0.8555\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.5873 - mse: 0.0498 - accuracy: 0.7938 - precision: 0.8618\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.5911 - mse: 0.0514 - accuracy: 0.7834 - precision: 0.8354\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.5333 - mse: 0.0448 - accuracy: 0.8101 - precision: 0.8632\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.5098 - mse: 0.0425 - accuracy: 0.8160 - precision: 0.8723\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.4687 - mse: 0.0394 - accuracy: 0.8412 - precision: 0.8810\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.4365 - mse: 0.0362 - accuracy: 0.8680 - precision: 0.9018\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.4210 - mse: 0.0356 - accuracy: 0.8576 - precision: 0.8982\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.3953 - mse: 0.0330 - accuracy: 0.8605 - precision: 0.8984\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.3660 - mse: 0.0308 - accuracy: 0.8858 - precision: 0.9135\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.3452 - mse: 0.0293 - accuracy: 0.8843 - precision: 0.9049\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.3153 - mse: 0.0261 - accuracy: 0.9021 - precision: 0.9271\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.3037 - mse: 0.0257 - accuracy: 0.9050 - precision: 0.9160\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.2686 - mse: 0.0217 - accuracy: 0.9154 - precision: 0.9464\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.2519 - mse: 0.0207 - accuracy: 0.9184 - precision: 0.9408\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.2637 - mse: 0.0229 - accuracy: 0.9006 - precision: 0.9227\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.1912 - mse: 0.0156 - accuracy: 0.9332 - precision: 0.9492\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.2020 - mse: 0.0164 - accuracy: 0.9421 - precision: 0.9642\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.1796 - mse: 0.0140 - accuracy: 0.9510 - precision: 0.9618\n",
            "Score for fold 2: loss of 1.1048119068145752; mse of 0.0773426741361618;accuracy of 0.7100591659545898;precision of 0.7222222089767456\n",
            "m332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 12, 18, 12) (None, 6, 10, 18, 12)\n",
            "(None, 6, 27, 6, 4)\n",
            "(None, 6, 27, 1, 1)\n",
            "(None, 162)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 1.4812 - mse: 0.1180 - accuracy: 0.4110 - precision: 0.8043\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 1.0495 - mse: 0.0867 - accuracy: 0.6113 - precision: 0.7647\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.8925 - mse: 0.0744 - accuracy: 0.6810 - precision: 0.8040\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.8010 - mse: 0.0672 - accuracy: 0.7003 - precision: 0.8256\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.7080 - mse: 0.0592 - accuracy: 0.7552 - precision: 0.8358\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.6358 - mse: 0.0539 - accuracy: 0.7834 - precision: 0.8679\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.5763 - mse: 0.0477 - accuracy: 0.8220 - precision: 0.8487\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.5267 - mse: 0.0433 - accuracy: 0.8368 - precision: 0.8799\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.4812 - mse: 0.0399 - accuracy: 0.8383 - precision: 0.8841\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.4655 - mse: 0.0396 - accuracy: 0.8383 - precision: 0.8891\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.4289 - mse: 0.0358 - accuracy: 0.8501 - precision: 0.9023\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.3946 - mse: 0.0333 - accuracy: 0.8650 - precision: 0.8986\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.3749 - mse: 0.0311 - accuracy: 0.8680 - precision: 0.9024\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.3564 - mse: 0.0292 - accuracy: 0.8872 - precision: 0.9187\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.3176 - mse: 0.0262 - accuracy: 0.9065 - precision: 0.9345\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.3180 - mse: 0.0264 - accuracy: 0.8902 - precision: 0.9186\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.2861 - mse: 0.0236 - accuracy: 0.9050 - precision: 0.9403\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.2768 - mse: 0.0237 - accuracy: 0.9006 - precision: 0.9266\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.2559 - mse: 0.0202 - accuracy: 0.9214 - precision: 0.9470\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.2448 - mse: 0.0208 - accuracy: 0.9139 - precision: 0.9371\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.2323 - mse: 0.0194 - accuracy: 0.9258 - precision: 0.9445\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.1969 - mse: 0.0156 - accuracy: 0.9407 - precision: 0.9616\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.1847 - mse: 0.0152 - accuracy: 0.9392 - precision: 0.9557\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.1722 - mse: 0.0134 - accuracy: 0.9510 - precision: 0.9664\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.1791 - mse: 0.0144 - accuracy: 0.9421 - precision: 0.9559\n",
            "Score for fold 3: loss of 0.8927978873252869; mse of 0.06445088237524033;accuracy of 0.7692307829856873;precision of 0.7791411280632019\n",
            "m332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 12, 18, 12) (None, 6, 10, 18, 12)\n",
            "(None, 6, 27, 6, 4)\n",
            "(None, 6, 27, 1, 1)\n",
            "(None, 162)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 1.5084 - mse: 0.1206 - accuracy: 0.3807 - precision: 0.7356\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 1.1026 - mse: 0.0931 - accuracy: 0.5556 - precision: 0.7525\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.9610 - mse: 0.0818 - accuracy: 0.6222 - precision: 0.7487\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.8180 - mse: 0.0701 - accuracy: 0.6889 - precision: 0.7924\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.7370 - mse: 0.0630 - accuracy: 0.7215 - precision: 0.8104\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.6796 - mse: 0.0585 - accuracy: 0.7393 - precision: 0.8321\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.6357 - mse: 0.0547 - accuracy: 0.7704 - precision: 0.8414\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.5962 - mse: 0.0502 - accuracy: 0.7956 - precision: 0.8522\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.5398 - mse: 0.0458 - accuracy: 0.8089 - precision: 0.8662\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.4986 - mse: 0.0434 - accuracy: 0.8000 - precision: 0.8550\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.4584 - mse: 0.0394 - accuracy: 0.8296 - precision: 0.8715\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.4411 - mse: 0.0380 - accuracy: 0.8459 - precision: 0.8975\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.3966 - mse: 0.0344 - accuracy: 0.8622 - precision: 0.8972\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.3640 - mse: 0.0310 - accuracy: 0.8622 - precision: 0.9110\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.3336 - mse: 0.0280 - accuracy: 0.8933 - precision: 0.9142\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.3088 - mse: 0.0263 - accuracy: 0.8948 - precision: 0.9206\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.2921 - mse: 0.0243 - accuracy: 0.9052 - precision: 0.9333\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.2638 - mse: 0.0219 - accuracy: 0.9200 - precision: 0.9397\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.2629 - mse: 0.0226 - accuracy: 0.9111 - precision: 0.9404\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.2227 - mse: 0.0194 - accuracy: 0.9200 - precision: 0.9298\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.2078 - mse: 0.0170 - accuracy: 0.9393 - precision: 0.9541\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.1904 - mse: 0.0157 - accuracy: 0.9407 - precision: 0.9544\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.1746 - mse: 0.0146 - accuracy: 0.9496 - precision: 0.9588\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.1488 - mse: 0.0118 - accuracy: 0.9630 - precision: 0.9757\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.1572 - mse: 0.0132 - accuracy: 0.9556 - precision: 0.9681\n",
            "Score for fold 4: loss of 1.139162540435791; mse of 0.07845643162727356;accuracy of 0.7083333134651184;precision of 0.7151514887809753\n",
            "m332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 12, 18, 12) (None, 6, 10, 18, 12)\n",
            "(None, 6, 27, 6, 4)\n",
            "(None, 6, 27, 1, 1)\n",
            "(None, 162)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 1.4403 - mse: 0.1159 - accuracy: 0.4133 - precision: 0.7589\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 1.0293 - mse: 0.0871 - accuracy: 0.5926 - precision: 0.7577\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.8975 - mse: 0.0776 - accuracy: 0.6533 - precision: 0.7383\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.8150 - mse: 0.0703 - accuracy: 0.6963 - precision: 0.7882\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.7186 - mse: 0.0614 - accuracy: 0.7378 - precision: 0.8132\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.6525 - mse: 0.0569 - accuracy: 0.7526 - precision: 0.8183\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.5980 - mse: 0.0507 - accuracy: 0.7881 - precision: 0.8499\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.5418 - mse: 0.0467 - accuracy: 0.8104 - precision: 0.8687\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.5101 - mse: 0.0441 - accuracy: 0.8207 - precision: 0.8729\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.4795 - mse: 0.0410 - accuracy: 0.8296 - precision: 0.8666\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.4389 - mse: 0.0381 - accuracy: 0.8504 - precision: 0.8770\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.3870 - mse: 0.0326 - accuracy: 0.8652 - precision: 0.9112\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.3725 - mse: 0.0316 - accuracy: 0.8696 - precision: 0.9013\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.3596 - mse: 0.0299 - accuracy: 0.8933 - precision: 0.9148\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.3307 - mse: 0.0283 - accuracy: 0.8889 - precision: 0.9100\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.2939 - mse: 0.0251 - accuracy: 0.9081 - precision: 0.9276\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.2836 - mse: 0.0241 - accuracy: 0.9067 - precision: 0.9266\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.2383 - mse: 0.0197 - accuracy: 0.9230 - precision: 0.9475\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.2211 - mse: 0.0186 - accuracy: 0.9259 - precision: 0.9484\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.2077 - mse: 0.0176 - accuracy: 0.9259 - precision: 0.9429\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.1906 - mse: 0.0159 - accuracy: 0.9437 - precision: 0.9514\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.1403 - mse: 0.0105 - accuracy: 0.9733 - precision: 0.9816\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.1633 - mse: 0.0134 - accuracy: 0.9600 - precision: 0.9665\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.1326 - mse: 0.0108 - accuracy: 0.9615 - precision: 0.9669\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.1306 - mse: 0.0106 - accuracy: 0.9630 - precision: 0.9699\n",
            "Score for fold 5: loss of 1.1210459470748901; mse of 0.0667235255241394;accuracy of 0.75;precision of 0.7544910311698914\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 2.232710361480713 - Accuracy: 0.6153846383094788 - Precision: 0.6397515535354614%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 1.1048119068145752 - Accuracy: 0.7100591659545898 - Precision: 0.7222222089767456%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 0.8927978873252869 - Accuracy: 0.7692307829856873 - Precision: 0.7791411280632019%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 1.139162540435791 - Accuracy: 0.7083333134651184 - Precision: 0.7151514887809753%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 1.1210459470748901 - Accuracy: 0.75 - Precision: 0.7544910311698914%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 0.7106015801429748 (+- 0.05303079138047888)\n",
            "> Loss: 1.2981057286262512\n",
            "> Precision: 0.7221514821052551\n",
            "------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TN1X86wojAWK"
      },
      "source": [
        "### Model m322"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmWY1lcl4UmR",
        "outputId": "56ad02a0-7977-4041-de53-9abc07a0c8cc"
      },
      "source": [
        "loss,mse,acc,prec = kfold_validation(\"m322\",M1_ufc,M2_ufc,M3_ufc,M4_ufc,M5_ufc,Train_ufc_y,pca_SPM_cube_ufc_reloaded,32,25,1,None,\"tanh\")\n",
        "results_tanh[\"m322\"] = np.array((loss,mse,acc,prec))\n",
        "filename = '/content/drive/MyDrive/ML_CSP774/Theory_project/3D-CNN Activity Recognition/Pickle/m322_25epochs_tanh.pickle'\n",
        "with open(filename, 'wb') as f:\n",
        "    pickle.dump(results_tanh[\"m322\"], f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "m322\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 7, 18, 12) (None, 6, 14, 18, 12) (None, 6, 12, 18, 12)\n",
            "(None, 6, 33, 6, 4)\n",
            "(None, 6, 33, 1, 1)\n",
            "(None, 198)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m322 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 1.5428 - mse: 0.1222 - accuracy: 0.3858 - precision: 0.8772\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 1.0771 - mse: 0.0889 - accuracy: 0.6142 - precision: 0.7729\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.9029 - mse: 0.0751 - accuracy: 0.6869 - precision: 0.7964\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.7936 - mse: 0.0669 - accuracy: 0.7151 - precision: 0.7930\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 5s 242ms/step - loss: 0.7294 - mse: 0.0623 - accuracy: 0.7404 - precision: 0.8304\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.6420 - mse: 0.0544 - accuracy: 0.7774 - precision: 0.8394\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.5921 - mse: 0.0510 - accuracy: 0.7834 - precision: 0.8551\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.5568 - mse: 0.0474 - accuracy: 0.7997 - precision: 0.8557\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 5s 242ms/step - loss: 0.5048 - mse: 0.0432 - accuracy: 0.8264 - precision: 0.8698\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 5s 242ms/step - loss: 0.4734 - mse: 0.0397 - accuracy: 0.8338 - precision: 0.8800\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 5s 239ms/step - loss: 0.4659 - mse: 0.0394 - accuracy: 0.8383 - precision: 0.8771\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 5s 242ms/step - loss: 0.4294 - mse: 0.0366 - accuracy: 0.8487 - precision: 0.8874\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 5s 242ms/step - loss: 0.3957 - mse: 0.0339 - accuracy: 0.8665 - precision: 0.8992\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 5s 242ms/step - loss: 0.3805 - mse: 0.0319 - accuracy: 0.8739 - precision: 0.9038\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.3463 - mse: 0.0296 - accuracy: 0.8813 - precision: 0.9045\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.3222 - mse: 0.0262 - accuracy: 0.8976 - precision: 0.9363\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.3215 - mse: 0.0274 - accuracy: 0.8783 - precision: 0.9037\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.2896 - mse: 0.0244 - accuracy: 0.9050 - precision: 0.9220\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 5s 242ms/step - loss: 0.2671 - mse: 0.0219 - accuracy: 0.9184 - precision: 0.9368\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.2505 - mse: 0.0205 - accuracy: 0.9214 - precision: 0.9333\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.2635 - mse: 0.0221 - accuracy: 0.9154 - precision: 0.9364\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.2166 - mse: 0.0180 - accuracy: 0.9288 - precision: 0.9450\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.1961 - mse: 0.0159 - accuracy: 0.9421 - precision: 0.9543\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.2218 - mse: 0.0184 - accuracy: 0.9332 - precision: 0.9423\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.1612 - mse: 0.0123 - accuracy: 0.9585 - precision: 0.9681\n",
            "Score for fold 1: loss of 1.501896858215332; mse of 0.09038183093070984;accuracy of 0.6568047404289246;precision of 0.6646341681480408\n",
            "m322\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 7, 18, 12) (None, 6, 14, 18, 12) (None, 6, 12, 18, 12)\n",
            "(None, 6, 33, 6, 4)\n",
            "(None, 6, 33, 1, 1)\n",
            "(None, 198)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m322 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 1.5852 - mse: 0.1261 - accuracy: 0.3487 - precision: 0.7391\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 1.1909 - mse: 0.0997 - accuracy: 0.5445 - precision: 0.7682\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.9682 - mse: 0.0814 - accuracy: 0.6439 - precision: 0.7730\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 5s 242ms/step - loss: 0.8536 - mse: 0.0725 - accuracy: 0.6840 - precision: 0.7678\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.7484 - mse: 0.0637 - accuracy: 0.7344 - precision: 0.8330\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.6713 - mse: 0.0575 - accuracy: 0.7596 - precision: 0.8400\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.6077 - mse: 0.0512 - accuracy: 0.7864 - precision: 0.8523\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.5814 - mse: 0.0493 - accuracy: 0.7967 - precision: 0.8579\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.5329 - mse: 0.0453 - accuracy: 0.8234 - precision: 0.8649\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.4878 - mse: 0.0404 - accuracy: 0.8442 - precision: 0.8865\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.4745 - mse: 0.0394 - accuracy: 0.8442 - precision: 0.8827\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.4213 - mse: 0.0355 - accuracy: 0.8665 - precision: 0.8964\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.4052 - mse: 0.0333 - accuracy: 0.8724 - precision: 0.9031\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.3685 - mse: 0.0299 - accuracy: 0.8828 - precision: 0.9148\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.3517 - mse: 0.0295 - accuracy: 0.8858 - precision: 0.9154\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.3272 - mse: 0.0267 - accuracy: 0.8961 - precision: 0.9102\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.3069 - mse: 0.0252 - accuracy: 0.9036 - precision: 0.9268\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.2829 - mse: 0.0230 - accuracy: 0.9095 - precision: 0.9289\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.2675 - mse: 0.0207 - accuracy: 0.9258 - precision: 0.9403\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.2463 - mse: 0.0200 - accuracy: 0.9228 - precision: 0.9425\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.2268 - mse: 0.0184 - accuracy: 0.9377 - precision: 0.9538\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.1975 - mse: 0.0154 - accuracy: 0.9466 - precision: 0.9662\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.1847 - mse: 0.0145 - accuracy: 0.9466 - precision: 0.9576\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.1775 - mse: 0.0140 - accuracy: 0.9525 - precision: 0.9577\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 5s 242ms/step - loss: 0.1551 - mse: 0.0126 - accuracy: 0.9570 - precision: 0.9622\n",
            "Score for fold 2: loss of 1.0738519430160522; mse of 0.0758395865559578;accuracy of 0.6982248425483704;precision of 0.7134146094322205\n",
            "m322\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 7, 18, 12) (None, 6, 14, 18, 12) (None, 6, 12, 18, 12)\n",
            "(None, 6, 33, 6, 4)\n",
            "(None, 6, 33, 1, 1)\n",
            "(None, 198)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m322 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 1.5432 - mse: 0.1237 - accuracy: 0.3872 - precision: 0.6809\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 1.1634 - mse: 0.0984 - accuracy: 0.5371 - precision: 0.7256\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.9834 - mse: 0.0847 - accuracy: 0.6128 - precision: 0.7513\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 5s 242ms/step - loss: 0.8950 - mse: 0.0784 - accuracy: 0.6409 - precision: 0.7511\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.7984 - mse: 0.0693 - accuracy: 0.7077 - precision: 0.7807\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.7285 - mse: 0.0631 - accuracy: 0.7166 - precision: 0.8054\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.6610 - mse: 0.0578 - accuracy: 0.7478 - precision: 0.8197\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.6145 - mse: 0.0530 - accuracy: 0.7685 - precision: 0.8293\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.5665 - mse: 0.0484 - accuracy: 0.7997 - precision: 0.8586\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.5318 - mse: 0.0460 - accuracy: 0.8056 - precision: 0.8476\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.5060 - mse: 0.0439 - accuracy: 0.8190 - precision: 0.8555\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.4617 - mse: 0.0389 - accuracy: 0.8383 - precision: 0.8777\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 5s 242ms/step - loss: 0.4246 - mse: 0.0368 - accuracy: 0.8576 - precision: 0.8871\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.4043 - mse: 0.0346 - accuracy: 0.8591 - precision: 0.8950\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.3783 - mse: 0.0325 - accuracy: 0.8591 - precision: 0.9010\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 5s 242ms/step - loss: 0.3322 - mse: 0.0276 - accuracy: 0.8961 - precision: 0.9184\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 5s 242ms/step - loss: 0.3386 - mse: 0.0279 - accuracy: 0.8843 - precision: 0.9151\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 5s 243ms/step - loss: 0.3112 - mse: 0.0262 - accuracy: 0.9021 - precision: 0.9213\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.2768 - mse: 0.0229 - accuracy: 0.9243 - precision: 0.9339\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.2896 - mse: 0.0251 - accuracy: 0.9036 - precision: 0.9149\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.2436 - mse: 0.0202 - accuracy: 0.9258 - precision: 0.9459\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.2359 - mse: 0.0197 - accuracy: 0.9303 - precision: 0.9415\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 5s 242ms/step - loss: 0.2181 - mse: 0.0187 - accuracy: 0.9318 - precision: 0.9405\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 5s 242ms/step - loss: 0.2002 - mse: 0.0172 - accuracy: 0.9362 - precision: 0.9479\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.1926 - mse: 0.0166 - accuracy: 0.9510 - precision: 0.9587\n",
            "Score for fold 3: loss of 1.156221866607666; mse of 0.08103920519351959;accuracy of 0.692307710647583;precision of 0.7197452187538147\n",
            "m322\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 7, 18, 12) (None, 6, 14, 18, 12) (None, 6, 12, 18, 12)\n",
            "(None, 6, 33, 6, 4)\n",
            "(None, 6, 33, 1, 1)\n",
            "(None, 198)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m322 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 1.5446 - mse: 0.1234 - accuracy: 0.3719 - precision: 0.7170\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 5s 242ms/step - loss: 1.1313 - mse: 0.0949 - accuracy: 0.5541 - precision: 0.7724\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.9321 - mse: 0.0789 - accuracy: 0.6489 - precision: 0.8166\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.7941 - mse: 0.0676 - accuracy: 0.7007 - precision: 0.8062\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.7008 - mse: 0.0594 - accuracy: 0.7556 - precision: 0.8507\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.6285 - mse: 0.0528 - accuracy: 0.7881 - precision: 0.8553\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.5891 - mse: 0.0497 - accuracy: 0.8030 - precision: 0.8467\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.5335 - mse: 0.0453 - accuracy: 0.8104 - precision: 0.8567\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.4890 - mse: 0.0409 - accuracy: 0.8341 - precision: 0.8752\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.4660 - mse: 0.0384 - accuracy: 0.8385 - precision: 0.8885\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.4313 - mse: 0.0357 - accuracy: 0.8578 - precision: 0.8891\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.4083 - mse: 0.0339 - accuracy: 0.8681 - precision: 0.8847\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.3680 - mse: 0.0298 - accuracy: 0.8844 - precision: 0.9247\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.3673 - mse: 0.0304 - accuracy: 0.8756 - precision: 0.9039\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 5s 242ms/step - loss: 0.3315 - mse: 0.0269 - accuracy: 0.8978 - precision: 0.9259\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.3165 - mse: 0.0258 - accuracy: 0.8963 - precision: 0.9258\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 5s 240ms/step - loss: 0.2944 - mse: 0.0242 - accuracy: 0.9022 - precision: 0.9270\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.2574 - mse: 0.0212 - accuracy: 0.9185 - precision: 0.9405\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.2552 - mse: 0.0212 - accuracy: 0.9230 - precision: 0.9383\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 5s 242ms/step - loss: 0.2204 - mse: 0.0179 - accuracy: 0.9304 - precision: 0.9464\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.2132 - mse: 0.0167 - accuracy: 0.9378 - precision: 0.9541\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.1862 - mse: 0.0146 - accuracy: 0.9452 - precision: 0.9602\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.1848 - mse: 0.0145 - accuracy: 0.9407 - precision: 0.9532\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 5s 242ms/step - loss: 0.1604 - mse: 0.0128 - accuracy: 0.9600 - precision: 0.9682\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 5s 242ms/step - loss: 0.1538 - mse: 0.0123 - accuracy: 0.9600 - precision: 0.9726\n",
            "Score for fold 4: loss of 1.1340059041976929; mse of 0.08138731867074966;accuracy of 0.6845238208770752;precision of 0.6951219439506531\n",
            "m322\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 7, 18, 12) (None, 6, 14, 18, 12) (None, 6, 12, 18, 12)\n",
            "(None, 6, 33, 6, 4)\n",
            "(None, 6, 33, 1, 1)\n",
            "(None, 198)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m322 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 5s 242ms/step - loss: 1.4937 - mse: 0.1191 - accuracy: 0.4104 - precision: 0.7654\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 1.0189 - mse: 0.0850 - accuracy: 0.6252 - precision: 0.7734\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 5s 242ms/step - loss: 0.8308 - mse: 0.0712 - accuracy: 0.6948 - precision: 0.7806\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 5s 242ms/step - loss: 0.7319 - mse: 0.0623 - accuracy: 0.7259 - precision: 0.8161\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.6537 - mse: 0.0556 - accuracy: 0.7644 - precision: 0.8451\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.6095 - mse: 0.0521 - accuracy: 0.7926 - precision: 0.8445\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 5s 242ms/step - loss: 0.5514 - mse: 0.0469 - accuracy: 0.8133 - precision: 0.8601\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.5253 - mse: 0.0453 - accuracy: 0.8074 - precision: 0.8434\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 5s 242ms/step - loss: 0.4720 - mse: 0.0400 - accuracy: 0.8400 - precision: 0.8880\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.4392 - mse: 0.0376 - accuracy: 0.8444 - precision: 0.8708\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 5s 242ms/step - loss: 0.4077 - mse: 0.0354 - accuracy: 0.8593 - precision: 0.8833\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.3858 - mse: 0.0336 - accuracy: 0.8667 - precision: 0.8896\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.3642 - mse: 0.0320 - accuracy: 0.8711 - precision: 0.8957\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 5s 242ms/step - loss: 0.3343 - mse: 0.0284 - accuracy: 0.8874 - precision: 0.9089\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 5s 242ms/step - loss: 0.3205 - mse: 0.0271 - accuracy: 0.8889 - precision: 0.9045\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.2903 - mse: 0.0251 - accuracy: 0.9037 - precision: 0.9221\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 5s 243ms/step - loss: 0.2656 - mse: 0.0220 - accuracy: 0.9185 - precision: 0.9336\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 5s 243ms/step - loss: 0.2505 - mse: 0.0211 - accuracy: 0.9126 - precision: 0.9355\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 5s 242ms/step - loss: 0.2167 - mse: 0.0188 - accuracy: 0.9274 - precision: 0.9434\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 5s 242ms/step - loss: 0.2287 - mse: 0.0191 - accuracy: 0.9304 - precision: 0.9418\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 5s 242ms/step - loss: 0.1922 - mse: 0.0156 - accuracy: 0.9481 - precision: 0.9559\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 5s 242ms/step - loss: 0.1697 - mse: 0.0133 - accuracy: 0.9541 - precision: 0.9680\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.1798 - mse: 0.0146 - accuracy: 0.9481 - precision: 0.9563\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 5s 242ms/step - loss: 0.1447 - mse: 0.0122 - accuracy: 0.9541 - precision: 0.9567\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 5s 241ms/step - loss: 0.1377 - mse: 0.0119 - accuracy: 0.9526 - precision: 0.9654\n",
            "Score for fold 5: loss of 1.2498877048492432; mse of 0.0787915587425232;accuracy of 0.6964285969734192;precision of 0.7142857313156128\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 1.501896858215332 - Accuracy: 0.6568047404289246 - Precision: 0.6646341681480408%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 1.0738519430160522 - Accuracy: 0.6982248425483704 - Precision: 0.7134146094322205%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 1.156221866607666 - Accuracy: 0.692307710647583 - Precision: 0.7197452187538147%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 1.1340059041976929 - Accuracy: 0.6845238208770752 - Precision: 0.6951219439506531%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 1.2498877048492432 - Accuracy: 0.6964285969734192 - Precision: 0.7142857313156128%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 0.6856579422950745 (+- 0.01517858288930836)\n",
            "> Loss: 1.2231728553771972\n",
            "> Precision: 0.7014403343200684\n",
            "------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VppL0lUajGmo"
      },
      "source": [
        "### Model m222"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6quUVv1t7gsZ",
        "outputId": "ede15d74-7449-4a25-8edf-f603a7bb65ad"
      },
      "source": [
        "loss,mse,acc,prec = kfold_validation(\"m222\",M1_ufc,M2_ufc,M3_ufc,M4_ufc,M5_ufc,Train_ufc_y,pca_SPM_cube_ufc_reloaded,32,25,1,None,\"tanh\")\n",
        "results_tanh[\"m222\"] = np.array((loss,mse,acc,prec))\n",
        "filename = '/content/drive/MyDrive/ML_CSP774/Theory_project/3D-CNN Activity Recognition/Pickle/m222_25epochs_tanh.pickle'\n",
        "with open(filename, 'wb') as f:\n",
        "    pickle.dump(results_tanh[\"m222\"], f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "m222\n",
            "(None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 8, 72, 54) (None, 2, 8, 72, 54)\n",
            "(None, 2, 9, 24, 18) (None, 2, 18, 24, 18) (None, 2, 16, 24, 18)\n",
            "(None, 6, 9, 18, 12) (None, 6, 18, 18, 12) (None, 6, 16, 18, 12)\n",
            "(None, 6, 43, 6, 4)\n",
            "(None, 6, 43, 1, 1)\n",
            "(None, 258)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m222 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "22/22 [==============================] - 4s 175ms/step - loss: 1.5612 - mse: 0.1238 - accuracy: 0.3769 - precision: 0.7234\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 1.1240 - mse: 0.0958 - accuracy: 0.5682 - precision: 0.7028\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 4s 174ms/step - loss: 0.9250 - mse: 0.0808 - accuracy: 0.6276 - precision: 0.7618\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 4s 174ms/step - loss: 0.8094 - mse: 0.0706 - accuracy: 0.6810 - precision: 0.7987\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 4s 175ms/step - loss: 0.7234 - mse: 0.0632 - accuracy: 0.7404 - precision: 0.8134\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.6461 - mse: 0.0558 - accuracy: 0.7893 - precision: 0.8421\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 4s 174ms/step - loss: 0.5911 - mse: 0.0515 - accuracy: 0.7864 - precision: 0.8368\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.5396 - mse: 0.0476 - accuracy: 0.8131 - precision: 0.8483\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.4851 - mse: 0.0420 - accuracy: 0.8264 - precision: 0.8721\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.4288 - mse: 0.0360 - accuracy: 0.8591 - precision: 0.8941\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.4079 - mse: 0.0354 - accuracy: 0.8487 - precision: 0.8808\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.3604 - mse: 0.0310 - accuracy: 0.8813 - precision: 0.9110\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.3437 - mse: 0.0297 - accuracy: 0.8680 - precision: 0.9095\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.3048 - mse: 0.0261 - accuracy: 0.8932 - precision: 0.9092\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.2947 - mse: 0.0252 - accuracy: 0.9050 - precision: 0.9305\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 4s 171ms/step - loss: 0.2770 - mse: 0.0244 - accuracy: 0.9065 - precision: 0.9286\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.2319 - mse: 0.0195 - accuracy: 0.9258 - precision: 0.9460\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.2361 - mse: 0.0204 - accuracy: 0.9288 - precision: 0.9406\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.2056 - mse: 0.0169 - accuracy: 0.9377 - precision: 0.9554\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.1796 - mse: 0.0141 - accuracy: 0.9481 - precision: 0.9617\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.1788 - mse: 0.0144 - accuracy: 0.9451 - precision: 0.9530\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.1398 - mse: 0.0111 - accuracy: 0.9614 - precision: 0.9727\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 4s 175ms/step - loss: 0.1342 - mse: 0.0112 - accuracy: 0.9510 - precision: 0.9664\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 4s 175ms/step - loss: 0.1243 - mse: 0.0105 - accuracy: 0.9629 - precision: 0.9655\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 4s 174ms/step - loss: 0.1174 - mse: 0.0085 - accuracy: 0.9733 - precision: 0.9789\n",
            "Score for fold 1: loss of 1.2343324422836304; mse of 0.06920991837978363;accuracy of 0.7633135914802551;precision of 0.7743902206420898\n",
            "m222\n",
            "(None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 8, 72, 54) (None, 2, 8, 72, 54)\n",
            "(None, 2, 9, 24, 18) (None, 2, 18, 24, 18) (None, 2, 16, 24, 18)\n",
            "(None, 6, 9, 18, 12) (None, 6, 18, 18, 12) (None, 6, 16, 18, 12)\n",
            "(None, 6, 43, 6, 4)\n",
            "(None, 6, 43, 1, 1)\n",
            "(None, 258)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m222 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 1.5437 - mse: 0.1234 - accuracy: 0.3858 - precision: 0.6923\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 4s 174ms/step - loss: 1.1238 - mse: 0.0970 - accuracy: 0.5519 - precision: 0.6902\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 4s 174ms/step - loss: 0.9510 - mse: 0.0830 - accuracy: 0.6320 - precision: 0.7341\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.8600 - mse: 0.0752 - accuracy: 0.6766 - precision: 0.7659\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 4s 174ms/step - loss: 0.7708 - mse: 0.0686 - accuracy: 0.7018 - precision: 0.7684\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.6985 - mse: 0.0612 - accuracy: 0.7374 - precision: 0.8119\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 4s 174ms/step - loss: 0.6611 - mse: 0.0579 - accuracy: 0.7626 - precision: 0.8138\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 4s 175ms/step - loss: 0.6017 - mse: 0.0526 - accuracy: 0.7789 - precision: 0.8366\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.5517 - mse: 0.0475 - accuracy: 0.8071 - precision: 0.8484\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.5230 - mse: 0.0451 - accuracy: 0.8190 - precision: 0.8620\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.4866 - mse: 0.0416 - accuracy: 0.8234 - precision: 0.8705\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.4383 - mse: 0.0376 - accuracy: 0.8576 - precision: 0.8874\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.4248 - mse: 0.0373 - accuracy: 0.8531 - precision: 0.8801\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 4s 174ms/step - loss: 0.3864 - mse: 0.0336 - accuracy: 0.8665 - precision: 0.8889\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 4s 174ms/step - loss: 0.3563 - mse: 0.0304 - accuracy: 0.8887 - precision: 0.9072\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.3318 - mse: 0.0280 - accuracy: 0.8961 - precision: 0.9142\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 4s 171ms/step - loss: 0.3023 - mse: 0.0250 - accuracy: 0.9021 - precision: 0.9206\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.2822 - mse: 0.0223 - accuracy: 0.9184 - precision: 0.9396\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.2585 - mse: 0.0216 - accuracy: 0.9199 - precision: 0.9347\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.2422 - mse: 0.0203 - accuracy: 0.9228 - precision: 0.9342\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.2204 - mse: 0.0172 - accuracy: 0.9362 - precision: 0.9494\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.2099 - mse: 0.0169 - accuracy: 0.9436 - precision: 0.9508\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.1790 - mse: 0.0142 - accuracy: 0.9466 - precision: 0.9590\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.1692 - mse: 0.0134 - accuracy: 0.9525 - precision: 0.9695\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 4s 174ms/step - loss: 0.1447 - mse: 0.0118 - accuracy: 0.9614 - precision: 0.9665\n",
            "Score for fold 2: loss of 1.0705338716506958; mse of 0.07525548338890076;accuracy of 0.7100591659545898;precision of 0.7160493731498718\n",
            "m222\n",
            "(None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 8, 72, 54) (None, 2, 8, 72, 54)\n",
            "(None, 2, 9, 24, 18) (None, 2, 18, 24, 18) (None, 2, 16, 24, 18)\n",
            "(None, 6, 9, 18, 12) (None, 6, 18, 18, 12) (None, 6, 16, 18, 12)\n",
            "(None, 6, 43, 6, 4)\n",
            "(None, 6, 43, 1, 1)\n",
            "(None, 258)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m222 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 1.4946 - mse: 0.1205 - accuracy: 0.4095 - precision: 0.7037\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 4s 174ms/step - loss: 1.0944 - mse: 0.0909 - accuracy: 0.5831 - precision: 0.7947\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.9177 - mse: 0.0775 - accuracy: 0.6602 - precision: 0.7783\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.7960 - mse: 0.0673 - accuracy: 0.6944 - precision: 0.8200\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.7030 - mse: 0.0596 - accuracy: 0.7433 - precision: 0.8382\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.6330 - mse: 0.0536 - accuracy: 0.7819 - precision: 0.8532\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 4s 174ms/step - loss: 0.5733 - mse: 0.0496 - accuracy: 0.7789 - precision: 0.8460\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.5116 - mse: 0.0436 - accuracy: 0.8175 - precision: 0.8793\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.4764 - mse: 0.0410 - accuracy: 0.8294 - precision: 0.8691\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.4467 - mse: 0.0385 - accuracy: 0.8457 - precision: 0.8793\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.3866 - mse: 0.0326 - accuracy: 0.8680 - precision: 0.9066\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.3695 - mse: 0.0316 - accuracy: 0.8709 - precision: 0.9113\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.3283 - mse: 0.0284 - accuracy: 0.8754 - precision: 0.9135\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 4s 174ms/step - loss: 0.2914 - mse: 0.0245 - accuracy: 0.9036 - precision: 0.9214\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.2701 - mse: 0.0230 - accuracy: 0.9110 - precision: 0.9433\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.2561 - mse: 0.0218 - accuracy: 0.9139 - precision: 0.9335\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.2226 - mse: 0.0187 - accuracy: 0.9125 - precision: 0.9396\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.2131 - mse: 0.0167 - accuracy: 0.9421 - precision: 0.9601\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 4s 174ms/step - loss: 0.2008 - mse: 0.0163 - accuracy: 0.9362 - precision: 0.9482\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.1609 - mse: 0.0120 - accuracy: 0.9585 - precision: 0.9669\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.1556 - mse: 0.0120 - accuracy: 0.9555 - precision: 0.9652\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.1451 - mse: 0.0116 - accuracy: 0.9585 - precision: 0.9712\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.1409 - mse: 0.0110 - accuracy: 0.9629 - precision: 0.9684\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.1160 - mse: 0.0089 - accuracy: 0.9718 - precision: 0.9760\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.1057 - mse: 0.0076 - accuracy: 0.9807 - precision: 0.9865\n",
            "Score for fold 3: loss of 1.2899410724639893; mse of 0.08288603276014328;accuracy of 0.6982248425483704;precision of 0.7116564512252808\n",
            "m222\n",
            "(None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 8, 72, 54) (None, 2, 8, 72, 54)\n",
            "(None, 2, 9, 24, 18) (None, 2, 18, 24, 18) (None, 2, 16, 24, 18)\n",
            "(None, 6, 9, 18, 12) (None, 6, 18, 18, 12) (None, 6, 16, 18, 12)\n",
            "(None, 6, 43, 6, 4)\n",
            "(None, 6, 43, 1, 1)\n",
            "(None, 258)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m222 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 1.5269 - mse: 0.1216 - accuracy: 0.4030 - precision: 0.7660\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 1.1002 - mse: 0.0911 - accuracy: 0.6000 - precision: 0.7596\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.8968 - mse: 0.0751 - accuracy: 0.6726 - precision: 0.7986\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.7877 - mse: 0.0664 - accuracy: 0.7096 - precision: 0.8228\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.6959 - mse: 0.0595 - accuracy: 0.7407 - precision: 0.8270\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.6277 - mse: 0.0525 - accuracy: 0.7763 - precision: 0.8425\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.5661 - mse: 0.0480 - accuracy: 0.8074 - precision: 0.8522\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 4s 171ms/step - loss: 0.5094 - mse: 0.0424 - accuracy: 0.8341 - precision: 0.8717\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.4895 - mse: 0.0407 - accuracy: 0.8311 - precision: 0.8756\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.4381 - mse: 0.0363 - accuracy: 0.8578 - precision: 0.9097\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.4167 - mse: 0.0345 - accuracy: 0.8667 - precision: 0.8914\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.3570 - mse: 0.0300 - accuracy: 0.8933 - precision: 0.9169\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.3319 - mse: 0.0282 - accuracy: 0.8889 - precision: 0.9239\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.2999 - mse: 0.0252 - accuracy: 0.9052 - precision: 0.9256\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 4s 174ms/step - loss: 0.2764 - mse: 0.0240 - accuracy: 0.9052 - precision: 0.9258\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.2335 - mse: 0.0189 - accuracy: 0.9304 - precision: 0.9532\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.2409 - mse: 0.0210 - accuracy: 0.9156 - precision: 0.9379\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.1933 - mse: 0.0157 - accuracy: 0.9393 - precision: 0.9527\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.1826 - mse: 0.0152 - accuracy: 0.9422 - precision: 0.9571\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.1705 - mse: 0.0141 - accuracy: 0.9496 - precision: 0.9621\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.1420 - mse: 0.0111 - accuracy: 0.9600 - precision: 0.9756\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.1301 - mse: 0.0107 - accuracy: 0.9615 - precision: 0.9671\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.1112 - mse: 0.0086 - accuracy: 0.9719 - precision: 0.9775\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.1054 - mse: 0.0084 - accuracy: 0.9748 - precision: 0.9760\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 4s 176ms/step - loss: 0.0950 - mse: 0.0072 - accuracy: 0.9793 - precision: 0.9821\n",
            "Score for fold 4: loss of 1.2069458961486816; mse of 0.07261007279157639;accuracy of 0.726190447807312;precision of 0.7345678806304932\n",
            "m222\n",
            "(None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 8, 72, 54) (None, 2, 8, 72, 54)\n",
            "(None, 2, 9, 24, 18) (None, 2, 18, 24, 18) (None, 2, 16, 24, 18)\n",
            "(None, 6, 9, 18, 12) (None, 6, 18, 18, 12) (None, 6, 16, 18, 12)\n",
            "(None, 6, 43, 6, 4)\n",
            "(None, 6, 43, 1, 1)\n",
            "(None, 258)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m222 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 1.6192 - mse: 0.1281 - accuracy: 0.3081 - precision: 0.9583\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 1.1460 - mse: 0.0953 - accuracy: 0.5748 - precision: 0.7472\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.9220 - mse: 0.0780 - accuracy: 0.6430 - precision: 0.7995\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.8222 - mse: 0.0708 - accuracy: 0.6919 - precision: 0.7961\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.7314 - mse: 0.0624 - accuracy: 0.7259 - precision: 0.8041\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.6720 - mse: 0.0578 - accuracy: 0.7452 - precision: 0.8324\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.5986 - mse: 0.0504 - accuracy: 0.8089 - precision: 0.8798\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.5544 - mse: 0.0473 - accuracy: 0.8000 - precision: 0.8596\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.5094 - mse: 0.0434 - accuracy: 0.8207 - precision: 0.8816\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 4s 175ms/step - loss: 0.4446 - mse: 0.0380 - accuracy: 0.8519 - precision: 0.8784\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 4s 176ms/step - loss: 0.4179 - mse: 0.0354 - accuracy: 0.8593 - precision: 0.8976\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 4s 174ms/step - loss: 0.3807 - mse: 0.0332 - accuracy: 0.8681 - precision: 0.9021\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.3722 - mse: 0.0322 - accuracy: 0.8741 - precision: 0.9016\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 4s 174ms/step - loss: 0.3414 - mse: 0.0291 - accuracy: 0.8904 - precision: 0.9213\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.3024 - mse: 0.0258 - accuracy: 0.9067 - precision: 0.9276\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.2673 - mse: 0.0225 - accuracy: 0.9156 - precision: 0.9393\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.2729 - mse: 0.0230 - accuracy: 0.9141 - precision: 0.9321\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.2399 - mse: 0.0208 - accuracy: 0.9156 - precision: 0.9396\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.2234 - mse: 0.0191 - accuracy: 0.9289 - precision: 0.9405\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.1894 - mse: 0.0157 - accuracy: 0.9378 - precision: 0.9444\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 4s 173ms/step - loss: 0.1819 - mse: 0.0147 - accuracy: 0.9467 - precision: 0.9605\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.1714 - mse: 0.0146 - accuracy: 0.9407 - precision: 0.9488\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.1506 - mse: 0.0126 - accuracy: 0.9452 - precision: 0.9636\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 4s 174ms/step - loss: 0.1370 - mse: 0.0112 - accuracy: 0.9615 - precision: 0.9684\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.1182 - mse: 0.0093 - accuracy: 0.9689 - precision: 0.9744\n",
            "Score for fold 5: loss of 1.5990266799926758; mse of 0.09609404951334;accuracy of 0.636904776096344;precision of 0.65625\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 1.2343324422836304 - Accuracy: 0.7633135914802551 - Precision: 0.7743902206420898%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 1.0705338716506958 - Accuracy: 0.7100591659545898 - Precision: 0.7160493731498718%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 1.2899410724639893 - Accuracy: 0.6982248425483704 - Precision: 0.7116564512252808%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 1.2069458961486816 - Accuracy: 0.726190447807312 - Precision: 0.7345678806304932%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 1.5990266799926758 - Accuracy: 0.636904776096344 - Precision: 0.65625%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 0.7069385647773743 (+- 0.04132596592884337)\n",
            "> Loss: 1.2801559925079347\n",
            "> Precision: 0.7185827851295471\n",
            "------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uEPA3sujDoK"
      },
      "source": [
        "### Model rs322"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IA0EycPm93Xe",
        "outputId": "88f21100-b2e6-4e28-9077-33c67e04005a"
      },
      "source": [
        "loss,mse,acc,prec = kfold_validation(\"rs332\",M1_ufc,M2_ufc,M3_ufc,M4_ufc,M5_ufc,Train_ufc_y,pca_SPM_cube_ufc_reloaded,32,25,1,None,\"tanh\")\n",
        "results_tanh[\"rs332\"] = np.array((loss,mse,acc,prec))\n",
        "filename = '/content/drive/MyDrive/ML_CSP774/Theory_project/3D-CNN Activity Recognition/Pickle/rs332_25epochs_tanh.pickle'\n",
        "with open(filename, 'wb') as f:\n",
        "    pickle.dump(results_tanh[\"rs332\"], f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rs332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "correct\n",
            "(None, 300)\n",
            "New rs332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 1.6369 - output_rs332_loss: 1.4254 - output_spm_rs332_loss: 42.2825 - output_rs332_mse: 0.1147 - output_rs332_accuracy: 0.4050 - output_rs332_precision: 0.7394 - output_spm_rs332_mse: 42.2825 - output_spm_rs332_accuracy: 0.0119\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 1.2706 - output_rs332_loss: 1.0595 - output_spm_rs332_loss: 42.2317 - output_rs332_mse: 0.0894 - output_rs332_accuracy: 0.5861 - output_rs332_precision: 0.7417 - output_spm_rs332_mse: 42.2317 - output_spm_rs332_accuracy: 0.1039\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 1.1605 - output_rs332_loss: 0.9498 - output_spm_rs332_loss: 42.1547 - output_rs332_mse: 0.0807 - output_rs332_accuracy: 0.6306 - output_rs332_precision: 0.7667 - output_spm_rs332_mse: 42.1547 - output_spm_rs332_accuracy: 0.2611\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 1.0676 - output_rs332_loss: 0.8572 - output_spm_rs332_loss: 42.0924 - output_rs332_mse: 0.0721 - output_rs332_accuracy: 0.6869 - output_rs332_precision: 0.7929 - output_spm_rs332_mse: 42.0924 - output_spm_rs332_accuracy: 0.3012\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 1.0064 - output_rs332_loss: 0.7963 - output_spm_rs332_loss: 42.0203 - output_rs332_mse: 0.0682 - output_rs332_accuracy: 0.7033 - output_rs332_precision: 0.7939 - output_spm_rs332_mse: 42.0203 - output_spm_rs332_accuracy: 0.3338\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.9319 - output_rs332_loss: 0.7222 - output_spm_rs332_loss: 41.9441 - output_rs332_mse: 0.0618 - output_rs332_accuracy: 0.7448 - output_rs332_precision: 0.8093 - output_spm_rs332_mse: 41.9441 - output_spm_rs332_accuracy: 0.3338\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.9031 - output_rs332_loss: 0.6938 - output_spm_rs332_loss: 41.8569 - output_rs332_mse: 0.0596 - output_rs332_accuracy: 0.7463 - output_rs332_precision: 0.7989 - output_spm_rs332_mse: 41.8569 - output_spm_rs332_accuracy: 0.3398\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.8389 - output_rs332_loss: 0.6298 - output_spm_rs332_loss: 41.8184 - output_rs332_mse: 0.0536 - output_rs332_accuracy: 0.7730 - output_rs332_precision: 0.8505 - output_spm_rs332_mse: 41.8184 - output_spm_rs332_accuracy: 0.3457\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.7894 - output_rs332_loss: 0.5807 - output_spm_rs332_loss: 41.7409 - output_rs332_mse: 0.0488 - output_rs332_accuracy: 0.7997 - output_rs332_precision: 0.8690 - output_spm_rs332_mse: 41.7409 - output_spm_rs332_accuracy: 0.3516\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.7597 - output_rs332_loss: 0.5515 - output_spm_rs332_loss: 41.6315 - output_rs332_mse: 0.0478 - output_rs332_accuracy: 0.7953 - output_rs332_precision: 0.8551 - output_spm_rs332_mse: 41.6315 - output_spm_rs332_accuracy: 0.3650\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.7069 - output_rs332_loss: 0.4990 - output_spm_rs332_loss: 41.5736 - output_rs332_mse: 0.0420 - output_rs332_accuracy: 0.8294 - output_rs332_precision: 0.8776 - output_spm_rs332_mse: 41.5736 - output_spm_rs332_accuracy: 0.3650\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.6823 - output_rs332_loss: 0.4749 - output_spm_rs332_loss: 41.4711 - output_rs332_mse: 0.0409 - output_rs332_accuracy: 0.8353 - output_rs332_precision: 0.8790 - output_spm_rs332_mse: 41.4711 - output_spm_rs332_accuracy: 0.3709\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.6325 - output_rs332_loss: 0.4256 - output_spm_rs332_loss: 41.3814 - output_rs332_mse: 0.0359 - output_rs332_accuracy: 0.8442 - output_rs332_precision: 0.8940 - output_spm_rs332_mse: 41.3814 - output_spm_rs332_accuracy: 0.3724\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.6120 - output_rs332_loss: 0.4055 - output_spm_rs332_loss: 41.3058 - output_rs332_mse: 0.0342 - output_rs332_accuracy: 0.8798 - output_rs332_precision: 0.9045 - output_spm_rs332_mse: 41.3058 - output_spm_rs332_accuracy: 0.3665\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.5795 - output_rs332_loss: 0.3735 - output_spm_rs332_loss: 41.2010 - output_rs332_mse: 0.0314 - output_rs332_accuracy: 0.8783 - output_rs332_precision: 0.9078 - output_spm_rs332_mse: 41.2010 - output_spm_rs332_accuracy: 0.3665\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.5358 - output_rs332_loss: 0.3303 - output_spm_rs332_loss: 41.1065 - output_rs332_mse: 0.0272 - output_rs332_accuracy: 0.8976 - output_rs332_precision: 0.9271 - output_spm_rs332_mse: 41.1065 - output_spm_rs332_accuracy: 0.3665\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.5004 - output_rs332_loss: 0.2953 - output_spm_rs332_loss: 41.0273 - output_rs332_mse: 0.0242 - output_rs332_accuracy: 0.9110 - output_rs332_precision: 0.9326 - output_spm_rs332_mse: 41.0273 - output_spm_rs332_accuracy: 0.3620\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.4789 - output_rs332_loss: 0.2742 - output_spm_rs332_loss: 40.9332 - output_rs332_mse: 0.0226 - output_rs332_accuracy: 0.9184 - output_rs332_precision: 0.9347 - output_spm_rs332_mse: 40.9332 - output_spm_rs332_accuracy: 0.3724\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.4570 - output_rs332_loss: 0.2527 - output_spm_rs332_loss: 40.8649 - output_rs332_mse: 0.0212 - output_rs332_accuracy: 0.9169 - output_rs332_precision: 0.9453 - output_spm_rs332_mse: 40.8649 - output_spm_rs332_accuracy: 0.3650\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.4101 - output_rs332_loss: 0.2064 - output_spm_rs332_loss: 40.7452 - output_rs332_mse: 0.0166 - output_rs332_accuracy: 0.9451 - output_rs332_precision: 0.9619 - output_spm_rs332_mse: 40.7452 - output_spm_rs332_accuracy: 0.3650\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.4173 - output_rs332_loss: 0.2143 - output_spm_rs332_loss: 40.6007 - output_rs332_mse: 0.0178 - output_rs332_accuracy: 0.9332 - output_rs332_precision: 0.9490 - output_spm_rs332_mse: 40.6007 - output_spm_rs332_accuracy: 0.3605\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.3696 - output_rs332_loss: 0.1666 - output_spm_rs332_loss: 40.6175 - output_rs332_mse: 0.0131 - output_rs332_accuracy: 0.9510 - output_rs332_precision: 0.9664 - output_spm_rs332_mse: 40.6175 - output_spm_rs332_accuracy: 0.3665\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.3558 - output_rs332_loss: 0.1537 - output_spm_rs332_loss: 40.4220 - output_rs332_mse: 0.0120 - output_rs332_accuracy: 0.9629 - output_rs332_precision: 0.9756 - output_spm_rs332_mse: 40.4220 - output_spm_rs332_accuracy: 0.3665\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.3224 - output_rs332_loss: 0.1203 - output_spm_rs332_loss: 40.4077 - output_rs332_mse: 0.0090 - output_rs332_accuracy: 0.9718 - output_rs332_precision: 0.9759 - output_spm_rs332_mse: 40.4077 - output_spm_rs332_accuracy: 0.3754\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.3099 - output_rs332_loss: 0.1087 - output_spm_rs332_loss: 40.2355 - output_rs332_mse: 0.0084 - output_rs332_accuracy: 0.9733 - output_rs332_precision: 0.9760 - output_spm_rs332_mse: 40.2355 - output_spm_rs332_accuracy: 0.3739\n",
            "Score for fold 1: loss of 1.62655508518219; output_rs332_loss of 1.450907826423645;output_spm_rs332_loss of 35.12947463989258;output_rs332_mse of 0.09002029150724411\n",
            "rs332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "correct\n",
            "(None, 300)\n",
            "New rs332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 1.6415 - output_rs332_loss: 1.4386 - output_spm_rs332_loss: 40.5907 - output_rs332_mse: 0.1163 - output_rs332_accuracy: 0.4199 - output_rs332_precision: 0.7207 - output_spm_rs332_mse: 40.5907 - output_spm_rs332_accuracy: 0.0475\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 1.1993 - output_rs332_loss: 0.9967 - output_spm_rs332_loss: 40.5336 - output_rs332_mse: 0.0849 - output_rs332_accuracy: 0.6098 - output_rs332_precision: 0.7629 - output_spm_rs332_mse: 40.5336 - output_spm_rs332_accuracy: 0.2389\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 6s 262ms/step - loss: 1.0682 - output_rs332_loss: 0.8658 - output_spm_rs332_loss: 40.4856 - output_rs332_mse: 0.0740 - output_rs332_accuracy: 0.6780 - output_rs332_precision: 0.7658 - output_spm_rs332_mse: 40.4856 - output_spm_rs332_accuracy: 0.2849\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.9808 - output_rs332_loss: 0.7787 - output_spm_rs332_loss: 40.4153 - output_rs332_mse: 0.0669 - output_rs332_accuracy: 0.7092 - output_rs332_precision: 0.7890 - output_spm_rs332_mse: 40.4153 - output_spm_rs332_accuracy: 0.3027\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.8819 - output_rs332_loss: 0.6801 - output_spm_rs332_loss: 40.3602 - output_rs332_mse: 0.0580 - output_rs332_accuracy: 0.7611 - output_rs332_precision: 0.8308 - output_spm_rs332_mse: 40.3602 - output_spm_rs332_accuracy: 0.3383\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.8161 - output_rs332_loss: 0.6146 - output_spm_rs332_loss: 40.3108 - output_rs332_mse: 0.0531 - output_rs332_accuracy: 0.7760 - output_rs332_precision: 0.8381 - output_spm_rs332_mse: 40.3108 - output_spm_rs332_accuracy: 0.3531\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.7773 - output_rs332_loss: 0.5762 - output_spm_rs332_loss: 40.2296 - output_rs332_mse: 0.0498 - output_rs332_accuracy: 0.7878 - output_rs332_precision: 0.8405 - output_spm_rs332_mse: 40.2296 - output_spm_rs332_accuracy: 0.3442\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.7031 - output_rs332_loss: 0.5023 - output_spm_rs332_loss: 40.1656 - output_rs332_mse: 0.0433 - output_rs332_accuracy: 0.8086 - output_rs332_precision: 0.8610 - output_spm_rs332_mse: 40.1656 - output_spm_rs332_accuracy: 0.3576\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.6613 - output_rs332_loss: 0.4608 - output_spm_rs332_loss: 40.0937 - output_rs332_mse: 0.0393 - output_rs332_accuracy: 0.8279 - output_rs332_precision: 0.8878 - output_spm_rs332_mse: 40.0937 - output_spm_rs332_accuracy: 0.3650\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.5990 - output_rs332_loss: 0.3989 - output_spm_rs332_loss: 40.0231 - output_rs332_mse: 0.0341 - output_rs332_accuracy: 0.8635 - output_rs332_precision: 0.9065 - output_spm_rs332_mse: 40.0231 - output_spm_rs332_accuracy: 0.3709\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.5473 - output_rs332_loss: 0.3477 - output_spm_rs332_loss: 39.9273 - output_rs332_mse: 0.0293 - output_rs332_accuracy: 0.8976 - output_rs332_precision: 0.9311 - output_spm_rs332_mse: 39.9273 - output_spm_rs332_accuracy: 0.3650\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.4906 - output_rs332_loss: 0.2914 - output_spm_rs332_loss: 39.8293 - output_rs332_mse: 0.0249 - output_rs332_accuracy: 0.9006 - output_rs332_precision: 0.9276 - output_spm_rs332_mse: 39.8293 - output_spm_rs332_accuracy: 0.3591\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.4794 - output_rs332_loss: 0.2804 - output_spm_rs332_loss: 39.7882 - output_rs332_mse: 0.0230 - output_rs332_accuracy: 0.9243 - output_rs332_precision: 0.9404 - output_spm_rs332_mse: 39.7882 - output_spm_rs332_accuracy: 0.3828\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.4184 - output_rs332_loss: 0.2201 - output_spm_rs332_loss: 39.6585 - output_rs332_mse: 0.0175 - output_rs332_accuracy: 0.9347 - output_rs332_precision: 0.9549 - output_spm_rs332_mse: 39.6585 - output_spm_rs332_accuracy: 0.3769\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.4049 - output_rs332_loss: 0.2072 - output_spm_rs332_loss: 39.5322 - output_rs332_mse: 0.0175 - output_rs332_accuracy: 0.9243 - output_rs332_precision: 0.9405 - output_spm_rs332_mse: 39.5322 - output_spm_rs332_accuracy: 0.3754\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.3561 - output_rs332_loss: 0.1589 - output_spm_rs332_loss: 39.4448 - output_rs332_mse: 0.0121 - output_rs332_accuracy: 0.9703 - output_rs332_precision: 0.9788 - output_spm_rs332_mse: 39.4448 - output_spm_rs332_accuracy: 0.3739\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.3432 - output_rs332_loss: 0.1462 - output_spm_rs332_loss: 39.4003 - output_rs332_mse: 0.0114 - output_rs332_accuracy: 0.9614 - output_rs332_precision: 0.9697 - output_spm_rs332_mse: 39.4003 - output_spm_rs332_accuracy: 0.3635\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.3157 - output_rs332_loss: 0.1192 - output_spm_rs332_loss: 39.2979 - output_rs332_mse: 0.0088 - output_rs332_accuracy: 0.9703 - output_rs332_precision: 0.9774 - output_spm_rs332_mse: 39.2979 - output_spm_rs332_accuracy: 0.3531\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.2919 - output_rs332_loss: 0.0959 - output_spm_rs332_loss: 39.1963 - output_rs332_mse: 0.0070 - output_rs332_accuracy: 0.9807 - output_rs332_precision: 0.9835 - output_spm_rs332_mse: 39.1963 - output_spm_rs332_accuracy: 0.3561\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.2729 - output_rs332_loss: 0.0775 - output_spm_rs332_loss: 39.0765 - output_rs332_mse: 0.0056 - output_rs332_accuracy: 0.9792 - output_rs332_precision: 0.9821 - output_spm_rs332_mse: 39.0765 - output_spm_rs332_accuracy: 0.3694\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.2524 - output_rs332_loss: 0.0574 - output_spm_rs332_loss: 38.9907 - output_rs332_mse: 0.0037 - output_rs332_accuracy: 0.9896 - output_rs332_precision: 0.9896 - output_spm_rs332_mse: 38.9907 - output_spm_rs332_accuracy: 0.3694\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.2533 - output_rs332_loss: 0.0590 - output_spm_rs332_loss: 38.8504 - output_rs332_mse: 0.0040 - output_rs332_accuracy: 0.9881 - output_rs332_precision: 0.9910 - output_spm_rs332_mse: 38.8504 - output_spm_rs332_accuracy: 0.3724\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.2288 - output_rs332_loss: 0.0350 - output_spm_rs332_loss: 38.7536 - output_rs332_mse: 0.0016 - output_rs332_accuracy: 0.9985 - output_rs332_precision: 0.9985 - output_spm_rs332_mse: 38.7536 - output_spm_rs332_accuracy: 0.3635\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.2294 - output_rs332_loss: 0.0361 - output_spm_rs332_loss: 38.6692 - output_rs332_mse: 0.0020 - output_rs332_accuracy: 0.9955 - output_rs332_precision: 0.9955 - output_spm_rs332_mse: 38.6692 - output_spm_rs332_accuracy: 0.3635\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.2231 - output_rs332_loss: 0.0307 - output_spm_rs332_loss: 38.4966 - output_rs332_mse: 0.0016 - output_rs332_accuracy: 0.9985 - output_rs332_precision: 0.9985 - output_spm_rs332_mse: 38.4966 - output_spm_rs332_accuracy: 0.3813\n",
            "Score for fold 2: loss of 2.5135087966918945; output_rs332_loss of 2.3135783672332764;output_spm_rs332_loss of 39.986053466796875;output_rs332_mse of 0.10770057141780853\n",
            "rs332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "correct\n",
            "(None, 300)\n",
            "New rs332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 1.6497 - output_rs332_loss: 1.4502 - output_spm_rs332_loss: 39.9045 - output_rs332_mse: 0.1174 - output_rs332_accuracy: 0.4303 - output_rs332_precision: 0.6759 - output_spm_rs332_mse: 39.9045 - output_spm_rs332_accuracy: 0.0015\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 1.2612 - output_rs332_loss: 1.0618 - output_spm_rs332_loss: 39.8851 - output_rs332_mse: 0.0900 - output_rs332_accuracy: 0.5935 - output_rs332_precision: 0.7427 - output_spm_rs332_mse: 39.8851 - output_spm_rs332_accuracy: 0.0697\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 1.1225 - output_rs332_loss: 0.9231 - output_spm_rs332_loss: 39.8672 - output_rs332_mse: 0.0784 - output_rs332_accuracy: 0.6380 - output_rs332_precision: 0.7600 - output_spm_rs332_mse: 39.8672 - output_spm_rs332_accuracy: 0.1157\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 1.0482 - output_rs332_loss: 0.8491 - output_spm_rs332_loss: 39.8349 - output_rs332_mse: 0.0725 - output_rs332_accuracy: 0.6869 - output_rs332_precision: 0.7833 - output_spm_rs332_mse: 39.8349 - output_spm_rs332_accuracy: 0.1914\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.9459 - output_rs332_loss: 0.7469 - output_spm_rs332_loss: 39.7955 - output_rs332_mse: 0.0641 - output_rs332_accuracy: 0.7300 - output_rs332_precision: 0.8089 - output_spm_rs332_mse: 39.7955 - output_spm_rs332_accuracy: 0.2582\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.8587 - output_rs332_loss: 0.6600 - output_spm_rs332_loss: 39.7367 - output_rs332_mse: 0.0559 - output_rs332_accuracy: 0.7745 - output_rs332_precision: 0.8473 - output_spm_rs332_mse: 39.7367 - output_spm_rs332_accuracy: 0.3145\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.7972 - output_rs332_loss: 0.5987 - output_spm_rs332_loss: 39.6809 - output_rs332_mse: 0.0515 - output_rs332_accuracy: 0.7864 - output_rs332_precision: 0.8468 - output_spm_rs332_mse: 39.6809 - output_spm_rs332_accuracy: 0.3279\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.7562 - output_rs332_loss: 0.5580 - output_spm_rs332_loss: 39.6267 - output_rs332_mse: 0.0468 - output_rs332_accuracy: 0.8101 - output_rs332_precision: 0.8744 - output_spm_rs332_mse: 39.6267 - output_spm_rs332_accuracy: 0.3531\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.7260 - output_rs332_loss: 0.5282 - output_spm_rs332_loss: 39.5608 - output_rs332_mse: 0.0443 - output_rs332_accuracy: 0.8338 - output_rs332_precision: 0.8810 - output_spm_rs332_mse: 39.5608 - output_spm_rs332_accuracy: 0.3591\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.6744 - output_rs332_loss: 0.4768 - output_spm_rs332_loss: 39.5188 - output_rs332_mse: 0.0409 - output_rs332_accuracy: 0.8353 - output_rs332_precision: 0.8754 - output_spm_rs332_mse: 39.5188 - output_spm_rs332_accuracy: 0.3501\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.6358 - output_rs332_loss: 0.4387 - output_spm_rs332_loss: 39.4368 - output_rs332_mse: 0.0372 - output_rs332_accuracy: 0.8427 - output_rs332_precision: 0.8818 - output_spm_rs332_mse: 39.4368 - output_spm_rs332_accuracy: 0.3591\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.6022 - output_rs332_loss: 0.4053 - output_spm_rs332_loss: 39.3715 - output_rs332_mse: 0.0343 - output_rs332_accuracy: 0.8591 - output_rs332_precision: 0.8925 - output_spm_rs332_mse: 39.3715 - output_spm_rs332_accuracy: 0.3605\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.5593 - output_rs332_loss: 0.3630 - output_spm_rs332_loss: 39.2627 - output_rs332_mse: 0.0315 - output_rs332_accuracy: 0.8620 - output_rs332_precision: 0.8924 - output_spm_rs332_mse: 39.2627 - output_spm_rs332_accuracy: 0.3605\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.5409 - output_rs332_loss: 0.3449 - output_spm_rs332_loss: 39.2077 - output_rs332_mse: 0.0292 - output_rs332_accuracy: 0.8783 - output_rs332_precision: 0.9130 - output_spm_rs332_mse: 39.2077 - output_spm_rs332_accuracy: 0.3724\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.4933 - output_rs332_loss: 0.2977 - output_spm_rs332_loss: 39.1130 - output_rs332_mse: 0.0254 - output_rs332_accuracy: 0.8991 - output_rs332_precision: 0.9242 - output_spm_rs332_mse: 39.1130 - output_spm_rs332_accuracy: 0.3783\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.4709 - output_rs332_loss: 0.2759 - output_spm_rs332_loss: 39.0059 - output_rs332_mse: 0.0229 - output_rs332_accuracy: 0.9125 - output_rs332_precision: 0.9357 - output_spm_rs332_mse: 39.0059 - output_spm_rs332_accuracy: 0.3724\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.4354 - output_rs332_loss: 0.2408 - output_spm_rs332_loss: 38.9132 - output_rs332_mse: 0.0201 - output_rs332_accuracy: 0.9214 - output_rs332_precision: 0.9409 - output_spm_rs332_mse: 38.9132 - output_spm_rs332_accuracy: 0.3694\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.3912 - output_rs332_loss: 0.1970 - output_spm_rs332_loss: 38.8364 - output_rs332_mse: 0.0156 - output_rs332_accuracy: 0.9407 - output_rs332_precision: 0.9600 - output_spm_rs332_mse: 38.8364 - output_spm_rs332_accuracy: 0.3665\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.3916 - output_rs332_loss: 0.1982 - output_spm_rs332_loss: 38.6894 - output_rs332_mse: 0.0161 - output_rs332_accuracy: 0.9362 - output_rs332_precision: 0.9542 - output_spm_rs332_mse: 38.6894 - output_spm_rs332_accuracy: 0.3694\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.3450 - output_rs332_loss: 0.1521 - output_spm_rs332_loss: 38.5867 - output_rs332_mse: 0.0113 - output_rs332_accuracy: 0.9688 - output_rs332_precision: 0.9743 - output_spm_rs332_mse: 38.5867 - output_spm_rs332_accuracy: 0.3680\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 6s 261ms/step - loss: 0.3375 - output_rs332_loss: 0.1451 - output_spm_rs332_loss: 38.4850 - output_rs332_mse: 0.0119 - output_rs332_accuracy: 0.9555 - output_rs332_precision: 0.9624 - output_spm_rs332_mse: 38.4850 - output_spm_rs332_accuracy: 0.3724\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.3019 - output_rs332_loss: 0.1100 - output_spm_rs332_loss: 38.3890 - output_rs332_mse: 0.0081 - output_rs332_accuracy: 0.9674 - output_rs332_precision: 0.9788 - output_spm_rs332_mse: 38.3890 - output_spm_rs332_accuracy: 0.3843\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 6s 261ms/step - loss: 0.2849 - output_rs332_loss: 0.0936 - output_spm_rs332_loss: 38.2680 - output_rs332_mse: 0.0066 - output_rs332_accuracy: 0.9837 - output_rs332_precision: 0.9880 - output_spm_rs332_mse: 38.2680 - output_spm_rs332_accuracy: 0.3813\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.2622 - output_rs332_loss: 0.0716 - output_spm_rs332_loss: 38.1272 - output_rs332_mse: 0.0046 - output_rs332_accuracy: 0.9852 - output_rs332_precision: 0.9881 - output_spm_rs332_mse: 38.1272 - output_spm_rs332_accuracy: 0.3783\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.2602 - output_rs332_loss: 0.0701 - output_spm_rs332_loss: 38.0139 - output_rs332_mse: 0.0047 - output_rs332_accuracy: 0.9866 - output_rs332_precision: 0.9910 - output_spm_rs332_mse: 38.0139 - output_spm_rs332_accuracy: 0.3769\n",
            "Score for fold 3: loss of 1.8924771547317505; output_rs332_loss of 1.6747496128082275;output_spm_rs332_loss of 43.545509338378906;output_rs332_mse of 0.08622730523347855\n",
            "rs332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "correct\n",
            "(None, 300)\n",
            "New rs332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 1.7014 - output_rs332_loss: 1.4979 - output_spm_rs332_loss: 40.6887 - output_rs332_mse: 0.1203 - output_rs332_accuracy: 0.3852 - output_rs332_precision: 0.7901 - output_spm_rs332_mse: 40.6887 - output_spm_rs332_accuracy: 0.0059\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 1.3509 - output_rs332_loss: 1.1477 - output_spm_rs332_loss: 40.6476 - output_rs332_mse: 0.0954 - output_rs332_accuracy: 0.5481 - output_rs332_precision: 0.7749 - output_spm_rs332_mse: 40.6476 - output_spm_rs332_accuracy: 0.0963\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 1.1831 - output_rs332_loss: 0.9803 - output_spm_rs332_loss: 40.5661 - output_rs332_mse: 0.0817 - output_rs332_accuracy: 0.6519 - output_rs332_precision: 0.7916 - output_spm_rs332_mse: 40.5661 - output_spm_rs332_accuracy: 0.2341\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 6s 263ms/step - loss: 1.0650 - output_rs332_loss: 0.8626 - output_spm_rs332_loss: 40.4889 - output_rs332_mse: 0.0729 - output_rs332_accuracy: 0.6844 - output_rs332_precision: 0.7884 - output_spm_rs332_mse: 40.4889 - output_spm_rs332_accuracy: 0.2459\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.9874 - output_rs332_loss: 0.7853 - output_spm_rs332_loss: 40.4135 - output_rs332_mse: 0.0652 - output_rs332_accuracy: 0.7304 - output_rs332_precision: 0.8386 - output_spm_rs332_mse: 40.4135 - output_spm_rs332_accuracy: 0.2726\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.9268 - output_rs332_loss: 0.7251 - output_spm_rs332_loss: 40.3455 - output_rs332_mse: 0.0609 - output_rs332_accuracy: 0.7511 - output_rs332_precision: 0.8253 - output_spm_rs332_mse: 40.3455 - output_spm_rs332_accuracy: 0.3007\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.8509 - output_rs332_loss: 0.6495 - output_spm_rs332_loss: 40.2940 - output_rs332_mse: 0.0540 - output_rs332_accuracy: 0.7674 - output_rs332_precision: 0.8501 - output_spm_rs332_mse: 40.2940 - output_spm_rs332_accuracy: 0.3185\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.7954 - output_rs332_loss: 0.5944 - output_spm_rs332_loss: 40.2110 - output_rs332_mse: 0.0493 - output_rs332_accuracy: 0.7941 - output_rs332_precision: 0.8680 - output_spm_rs332_mse: 40.2110 - output_spm_rs332_accuracy: 0.3452\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.7516 - output_rs332_loss: 0.5509 - output_spm_rs332_loss: 40.1332 - output_rs332_mse: 0.0451 - output_rs332_accuracy: 0.8104 - output_rs332_precision: 0.8746 - output_spm_rs332_mse: 40.1332 - output_spm_rs332_accuracy: 0.3289\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.7190 - output_rs332_loss: 0.5186 - output_spm_rs332_loss: 40.0767 - output_rs332_mse: 0.0428 - output_rs332_accuracy: 0.8326 - output_rs332_precision: 0.8828 - output_spm_rs332_mse: 40.0767 - output_spm_rs332_accuracy: 0.3511\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.6444 - output_rs332_loss: 0.4445 - output_spm_rs332_loss: 39.9864 - output_rs332_mse: 0.0364 - output_rs332_accuracy: 0.8681 - output_rs332_precision: 0.9073 - output_spm_rs332_mse: 39.9864 - output_spm_rs332_accuracy: 0.3481\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.6147 - output_rs332_loss: 0.4152 - output_spm_rs332_loss: 39.8999 - output_rs332_mse: 0.0338 - output_rs332_accuracy: 0.8696 - output_rs332_precision: 0.9103 - output_spm_rs332_mse: 39.8999 - output_spm_rs332_accuracy: 0.3570\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.5763 - output_rs332_loss: 0.3770 - output_spm_rs332_loss: 39.8443 - output_rs332_mse: 0.0304 - output_rs332_accuracy: 0.8830 - output_rs332_precision: 0.9222 - output_spm_rs332_mse: 39.8443 - output_spm_rs332_accuracy: 0.3659\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.5295 - output_rs332_loss: 0.3307 - output_spm_rs332_loss: 39.7701 - output_rs332_mse: 0.0263 - output_rs332_accuracy: 0.8919 - output_rs332_precision: 0.9285 - output_spm_rs332_mse: 39.7701 - output_spm_rs332_accuracy: 0.3630\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.5020 - output_rs332_loss: 0.3037 - output_spm_rs332_loss: 39.6616 - output_rs332_mse: 0.0243 - output_rs332_accuracy: 0.9141 - output_rs332_precision: 0.9425 - output_spm_rs332_mse: 39.6616 - output_spm_rs332_accuracy: 0.3570\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.4577 - output_rs332_loss: 0.2596 - output_spm_rs332_loss: 39.6186 - output_rs332_mse: 0.0207 - output_rs332_accuracy: 0.9259 - output_rs332_precision: 0.9454 - output_spm_rs332_mse: 39.6186 - output_spm_rs332_accuracy: 0.3644\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.4280 - output_rs332_loss: 0.2304 - output_spm_rs332_loss: 39.5209 - output_rs332_mse: 0.0182 - output_rs332_accuracy: 0.9378 - output_rs332_precision: 0.9509 - output_spm_rs332_mse: 39.5209 - output_spm_rs332_accuracy: 0.3704\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.4139 - output_rs332_loss: 0.2170 - output_spm_rs332_loss: 39.3818 - output_rs332_mse: 0.0167 - output_rs332_accuracy: 0.9319 - output_rs332_precision: 0.9570 - output_spm_rs332_mse: 39.3818 - output_spm_rs332_accuracy: 0.3807\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.3877 - output_rs332_loss: 0.1910 - output_spm_rs332_loss: 39.3433 - output_rs332_mse: 0.0155 - output_rs332_accuracy: 0.9437 - output_rs332_precision: 0.9528 - output_spm_rs332_mse: 39.3433 - output_spm_rs332_accuracy: 0.3689\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.3489 - output_rs332_loss: 0.1527 - output_spm_rs332_loss: 39.2318 - output_rs332_mse: 0.0115 - output_rs332_accuracy: 0.9630 - output_rs332_precision: 0.9726 - output_spm_rs332_mse: 39.2318 - output_spm_rs332_accuracy: 0.3822\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.3283 - output_rs332_loss: 0.1328 - output_spm_rs332_loss: 39.0901 - output_rs332_mse: 0.0099 - output_rs332_accuracy: 0.9704 - output_rs332_precision: 0.9773 - output_spm_rs332_mse: 39.0901 - output_spm_rs332_accuracy: 0.3822\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.3061 - output_rs332_loss: 0.1109 - output_spm_rs332_loss: 39.0516 - output_rs332_mse: 0.0079 - output_rs332_accuracy: 0.9763 - output_rs332_precision: 0.9879 - output_spm_rs332_mse: 39.0516 - output_spm_rs332_accuracy: 0.3748\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.2830 - output_rs332_loss: 0.0884 - output_spm_rs332_loss: 38.9192 - output_rs332_mse: 0.0063 - output_rs332_accuracy: 0.9793 - output_rs332_precision: 0.9836 - output_spm_rs332_mse: 38.9192 - output_spm_rs332_accuracy: 0.3748\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.2649 - output_rs332_loss: 0.0711 - output_spm_rs332_loss: 38.7641 - output_rs332_mse: 0.0047 - output_rs332_accuracy: 0.9896 - output_rs332_precision: 0.9910 - output_spm_rs332_mse: 38.7641 - output_spm_rs332_accuracy: 0.3763\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.2524 - output_rs332_loss: 0.0593 - output_spm_rs332_loss: 38.6111 - output_rs332_mse: 0.0040 - output_rs332_accuracy: 0.9867 - output_rs332_precision: 0.9896 - output_spm_rs332_mse: 38.6111 - output_spm_rs332_accuracy: 0.3630\n",
            "Score for fold 4: loss of 1.5812097787857056; output_rs332_loss of 1.3789480924606323;output_spm_rs332_loss of 40.45234680175781;output_rs332_mse of 0.0842985287308693\n",
            "rs332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "correct\n",
            "(None, 300)\n",
            "New rs332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 1.6779 - output_rs332_loss: 1.4712 - output_spm_rs332_loss: 41.3417 - output_rs332_mse: 0.1182 - output_rs332_accuracy: 0.4015 - output_rs332_precision: 0.7222 - output_spm_rs332_mse: 41.3417 - output_spm_rs332_accuracy: 0.0548\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 1.2563 - output_rs332_loss: 1.0500 - output_spm_rs332_loss: 41.2697 - output_rs332_mse: 0.0884 - output_rs332_accuracy: 0.6015 - output_rs332_precision: 0.7565 - output_spm_rs332_mse: 41.2697 - output_spm_rs332_accuracy: 0.2370\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 6s 262ms/step - loss: 1.1029 - output_rs332_loss: 0.8969 - output_spm_rs332_loss: 41.2067 - output_rs332_mse: 0.0765 - output_rs332_accuracy: 0.6622 - output_rs332_precision: 0.7568 - output_spm_rs332_mse: 41.2067 - output_spm_rs332_accuracy: 0.2785\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 1.0175 - output_rs332_loss: 0.8118 - output_spm_rs332_loss: 41.1365 - output_rs332_mse: 0.0691 - output_rs332_accuracy: 0.6874 - output_rs332_precision: 0.8067 - output_spm_rs332_mse: 41.1365 - output_spm_rs332_accuracy: 0.3111\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 6s 261ms/step - loss: 0.9356 - output_rs332_loss: 0.7302 - output_spm_rs332_loss: 41.0799 - output_rs332_mse: 0.0623 - output_rs332_accuracy: 0.7319 - output_rs332_precision: 0.8107 - output_spm_rs332_mse: 41.0799 - output_spm_rs332_accuracy: 0.3289\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.8890 - output_rs332_loss: 0.6838 - output_spm_rs332_loss: 41.0309 - output_rs332_mse: 0.0592 - output_rs332_accuracy: 0.7348 - output_rs332_precision: 0.8114 - output_spm_rs332_mse: 41.0309 - output_spm_rs332_accuracy: 0.3363\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.8083 - output_rs332_loss: 0.6035 - output_spm_rs332_loss: 40.9608 - output_rs332_mse: 0.0513 - output_rs332_accuracy: 0.7896 - output_rs332_precision: 0.8589 - output_spm_rs332_mse: 40.9608 - output_spm_rs332_accuracy: 0.3333\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 6s 262ms/step - loss: 0.7701 - output_rs332_loss: 0.5657 - output_spm_rs332_loss: 40.8852 - output_rs332_mse: 0.0482 - output_rs332_accuracy: 0.8044 - output_rs332_precision: 0.8406 - output_spm_rs332_mse: 40.8852 - output_spm_rs332_accuracy: 0.3437\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 6s 261ms/step - loss: 0.7298 - output_rs332_loss: 0.5257 - output_spm_rs332_loss: 40.8224 - output_rs332_mse: 0.0441 - output_rs332_accuracy: 0.8119 - output_rs332_precision: 0.8699 - output_spm_rs332_mse: 40.8224 - output_spm_rs332_accuracy: 0.3437\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.6710 - output_rs332_loss: 0.4671 - output_spm_rs332_loss: 40.7698 - output_rs332_mse: 0.0395 - output_rs332_accuracy: 0.8504 - output_rs332_precision: 0.8824 - output_spm_rs332_mse: 40.7698 - output_spm_rs332_accuracy: 0.3511\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.6494 - output_rs332_loss: 0.4458 - output_spm_rs332_loss: 40.7066 - output_rs332_mse: 0.0377 - output_rs332_accuracy: 0.8489 - output_rs332_precision: 0.8849 - output_spm_rs332_mse: 40.7066 - output_spm_rs332_accuracy: 0.3689\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.6033 - output_rs332_loss: 0.4001 - output_spm_rs332_loss: 40.6384 - output_rs332_mse: 0.0339 - output_rs332_accuracy: 0.8622 - output_rs332_precision: 0.8957 - output_spm_rs332_mse: 40.6384 - output_spm_rs332_accuracy: 0.3467\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.5532 - output_rs332_loss: 0.3505 - output_spm_rs332_loss: 40.5569 - output_rs332_mse: 0.0288 - output_rs332_accuracy: 0.8978 - output_rs332_precision: 0.9234 - output_spm_rs332_mse: 40.5569 - output_spm_rs332_accuracy: 0.3644\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.5075 - output_rs332_loss: 0.3051 - output_spm_rs332_loss: 40.4795 - output_rs332_mse: 0.0253 - output_rs332_accuracy: 0.9081 - output_rs332_precision: 0.9241 - output_spm_rs332_mse: 40.4795 - output_spm_rs332_accuracy: 0.3511\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 6s 262ms/step - loss: 0.5124 - output_rs332_loss: 0.3105 - output_spm_rs332_loss: 40.3834 - output_rs332_mse: 0.0264 - output_rs332_accuracy: 0.8904 - output_rs332_precision: 0.9114 - output_spm_rs332_mse: 40.3834 - output_spm_rs332_accuracy: 0.3630\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 6s 262ms/step - loss: 0.4506 - output_rs332_loss: 0.2489 - output_spm_rs332_loss: 40.3357 - output_rs332_mse: 0.0198 - output_rs332_accuracy: 0.9333 - output_rs332_precision: 0.9462 - output_spm_rs332_mse: 40.3357 - output_spm_rs332_accuracy: 0.3659\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.4227 - output_rs332_loss: 0.2215 - output_spm_rs332_loss: 40.2415 - output_rs332_mse: 0.0176 - output_rs332_accuracy: 0.9363 - output_rs332_precision: 0.9520 - output_spm_rs332_mse: 40.2415 - output_spm_rs332_accuracy: 0.3719\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.3996 - output_rs332_loss: 0.1990 - output_spm_rs332_loss: 40.1210 - output_rs332_mse: 0.0165 - output_rs332_accuracy: 0.9363 - output_rs332_precision: 0.9525 - output_spm_rs332_mse: 40.1210 - output_spm_rs332_accuracy: 0.3556\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.3764 - output_rs332_loss: 0.1763 - output_spm_rs332_loss: 40.0292 - output_rs332_mse: 0.0136 - output_rs332_accuracy: 0.9511 - output_rs332_precision: 0.9606 - output_spm_rs332_mse: 40.0292 - output_spm_rs332_accuracy: 0.3763\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.3630 - output_rs332_loss: 0.1631 - output_spm_rs332_loss: 39.9728 - output_rs332_mse: 0.0121 - output_rs332_accuracy: 0.9659 - output_rs332_precision: 0.9729 - output_spm_rs332_mse: 39.9728 - output_spm_rs332_accuracy: 0.3719\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 6s 262ms/step - loss: 0.3191 - output_rs332_loss: 0.1199 - output_spm_rs332_loss: 39.8494 - output_rs332_mse: 0.0090 - output_rs332_accuracy: 0.9704 - output_rs332_precision: 0.9746 - output_spm_rs332_mse: 39.8494 - output_spm_rs332_accuracy: 0.3644\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.3258 - output_rs332_loss: 0.1268 - output_spm_rs332_loss: 39.8052 - output_rs332_mse: 0.0100 - output_rs332_accuracy: 0.9644 - output_rs332_precision: 0.9758 - output_spm_rs332_mse: 39.8052 - output_spm_rs332_accuracy: 0.3644\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.2971 - output_rs332_loss: 0.0985 - output_spm_rs332_loss: 39.7256 - output_rs332_mse: 0.0073 - output_rs332_accuracy: 0.9748 - output_rs332_precision: 0.9762 - output_spm_rs332_mse: 39.7256 - output_spm_rs332_accuracy: 0.3644\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 6s 260ms/step - loss: 0.2749 - output_rs332_loss: 0.0771 - output_spm_rs332_loss: 39.5678 - output_rs332_mse: 0.0050 - output_rs332_accuracy: 0.9837 - output_rs332_precision: 0.9910 - output_spm_rs332_mse: 39.5678 - output_spm_rs332_accuracy: 0.3600\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 0.2754 - output_rs332_loss: 0.0782 - output_spm_rs332_loss: 39.4450 - output_rs332_mse: 0.0055 - output_rs332_accuracy: 0.9822 - output_rs332_precision: 0.9851 - output_spm_rs332_mse: 39.4450 - output_spm_rs332_accuracy: 0.3778\n",
            "Score for fold 5: loss of 1.7935200929641724; output_rs332_loss of 1.6047548055648804;output_spm_rs332_loss of 37.75299072265625;output_rs332_mse of 0.08961981534957886\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 1.450907826423645 - Accuracy: 0.668639063835144 - Precision: 0.6646341681480408%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 2.3135783672332764 - Accuracy: 0.6094674468040466 - Precision: 0.6219512224197388%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 1.6747496128082275 - Accuracy: 0.6745561957359314 - Precision: 0.6932515501976013%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 1.3789480924606323 - Accuracy: 0.6845238208770752 - Precision: 0.699999988079071%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 1.6047548055648804 - Accuracy: 0.6726190447807312 - Precision: 0.6871165633201599%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 0.6619611144065857 (+- 0.026763719561236916)\n",
            "> Loss: 1.6845877408981322\n",
            "> Precision: 0.6733906984329223\n",
            "------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BI2hVX0FjLhB"
      },
      "source": [
        "### Average of all five"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWSOo4UYBdgj",
        "outputId": "173c4ea3-d672-4e89-aa76-67a35e595ecc"
      },
      "source": [
        "loss,mse,acc,prec = kfold_validation(\"ensemble\",M1_ufc,M2_ufc,M3_ufc,M4_ufc,M5_ufc,Train_ufc_y,pca_SPM_cube_ufc_reloaded,32,30,1,5,'tanh')\n",
        "results_tanh[\"ensemble5\"] = np.array((loss,mse,acc,prec))\n",
        "filename = '/content/drive/MyDrive/ML_CSP774/Theory_project/3D-CNN Activity Recognition/Pickle/ensemble5_30epochs_tanh.pickle'\n",
        "with open(filename, 'wb') as f:\n",
        "    pickle.dump(results_tanh[\"ensemble5\"], f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "s332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "rs332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "correct\n",
            "(None, 300)\n",
            "m332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 12, 18, 12) (None, 6, 10, 18, 12)\n",
            "(None, 6, 27, 6, 4)\n",
            "(None, 6, 27, 1, 1)\n",
            "(None, 162)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "m322\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 7, 18, 12) (None, 6, 14, 18, 12) (None, 6, 12, 18, 12)\n",
            "(None, 6, 33, 6, 4)\n",
            "(None, 6, 33, 1, 1)\n",
            "(None, 198)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "m222\n",
            "(None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 8, 72, 54) (None, 2, 8, 72, 54)\n",
            "(None, 2, 9, 24, 18) (None, 2, 18, 24, 18) (None, 2, 16, 24, 18)\n",
            "(None, 6, 9, 18, 12) (None, 6, 18, 18, 12) (None, 6, 16, 18, 12)\n",
            "(None, 6, 43, 6, 4)\n",
            "(None, 6, 43, 1, 1)\n",
            "(None, 258)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New ensemble model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 1.5877 - mse: 0.1263 - accuracy: 0.3680 - precision_5: 0.5714\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 1.1813 - mse: 0.0993 - accuracy: 0.5697 - precision_5: 0.8085\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 1.0093 - mse: 0.0857 - accuracy: 0.6439 - precision_5: 0.8390\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.8519 - mse: 0.0722 - accuracy: 0.7270 - precision_5: 0.8880\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.7609 - mse: 0.0649 - accuracy: 0.7685 - precision_5: 0.8673\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.6714 - mse: 0.0577 - accuracy: 0.7923 - precision_5: 0.9116\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.6285 - mse: 0.0546 - accuracy: 0.8027 - precision_5: 0.8942\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.5405 - mse: 0.0473 - accuracy: 0.8353 - precision_5: 0.9038\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.5133 - mse: 0.0446 - accuracy: 0.8472 - precision_5: 0.9094\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.4890 - mse: 0.0426 - accuracy: 0.8680 - precision_5: 0.9165\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.4487 - mse: 0.0391 - accuracy: 0.8680 - precision_5: 0.9250\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.4367 - mse: 0.0390 - accuracy: 0.8694 - precision_5: 0.9165\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.4027 - mse: 0.0344 - accuracy: 0.8902 - precision_5: 0.9466\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3682 - mse: 0.0318 - accuracy: 0.9065 - precision_5: 0.9493\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3758 - mse: 0.0324 - accuracy: 0.9006 - precision_5: 0.9445\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3344 - mse: 0.0289 - accuracy: 0.9154 - precision_5: 0.9536\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3323 - mse: 0.0287 - accuracy: 0.9199 - precision_5: 0.9572\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3088 - mse: 0.0268 - accuracy: 0.9243 - precision_5: 0.9541\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2818 - mse: 0.0238 - accuracy: 0.9421 - precision_5: 0.9597\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2841 - mse: 0.0245 - accuracy: 0.9288 - precision_5: 0.9581\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2849 - mse: 0.0245 - accuracy: 0.9332 - precision_5: 0.9580\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2499 - mse: 0.0211 - accuracy: 0.9421 - precision_5: 0.9665\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2500 - mse: 0.0210 - accuracy: 0.9451 - precision_5: 0.9682\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2414 - mse: 0.0201 - accuracy: 0.9540 - precision_5: 0.9749\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2367 - mse: 0.0206 - accuracy: 0.9407 - precision_5: 0.9573\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2366 - mse: 0.0198 - accuracy: 0.9451 - precision_5: 0.9700\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2275 - mse: 0.0190 - accuracy: 0.9481 - precision_5: 0.9701\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2168 - mse: 0.0182 - accuracy: 0.9540 - precision_5: 0.9718\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2045 - mse: 0.0173 - accuracy: 0.9540 - precision_5: 0.9686\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2100 - mse: 0.0178 - accuracy: 0.9540 - precision_5: 0.9674\n",
            "Score for fold 1: loss of 0.7109414935112; mse of 0.0496211014688015;accuracy of 0.8165680766105652;precision_5 of 0.8541666865348816\n",
            "s332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "rs332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "correct\n",
            "(None, 300)\n",
            "m332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 12, 18, 12) (None, 6, 10, 18, 12)\n",
            "(None, 6, 27, 6, 4)\n",
            "(None, 6, 27, 1, 1)\n",
            "(None, 162)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "m322\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 7, 18, 12) (None, 6, 14, 18, 12) (None, 6, 12, 18, 12)\n",
            "(None, 6, 33, 6, 4)\n",
            "(None, 6, 33, 1, 1)\n",
            "(None, 198)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "m222\n",
            "(None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 8, 72, 54) (None, 2, 8, 72, 54)\n",
            "(None, 2, 9, 24, 18) (None, 2, 18, 24, 18) (None, 2, 16, 24, 18)\n",
            "(None, 6, 9, 18, 12) (None, 6, 18, 18, 12) (None, 6, 16, 18, 12)\n",
            "(None, 6, 43, 6, 4)\n",
            "(None, 6, 43, 1, 1)\n",
            "(None, 258)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New ensemble model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 1.5863 - mse: 0.1255 - accuracy: 0.3754 - precision_5: 1.0000\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 1.1026 - mse: 0.0913 - accuracy: 0.6128 - precision_5: 0.8390\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.9291 - mse: 0.0777 - accuracy: 0.6736 - precision_5: 0.8772\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.7941 - mse: 0.0676 - accuracy: 0.7240 - precision_5: 0.8665\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.7042 - mse: 0.0615 - accuracy: 0.7507 - precision_5: 0.8783\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.6419 - mse: 0.0561 - accuracy: 0.7938 - precision_5: 0.8944\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.5563 - mse: 0.0480 - accuracy: 0.8323 - precision_5: 0.9286\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.5201 - mse: 0.0460 - accuracy: 0.8309 - precision_5: 0.9140\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.4859 - mse: 0.0423 - accuracy: 0.8501 - precision_5: 0.9252\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.4417 - mse: 0.0379 - accuracy: 0.8813 - precision_5: 0.9363\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3964 - mse: 0.0342 - accuracy: 0.8887 - precision_5: 0.9398\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3839 - mse: 0.0331 - accuracy: 0.8843 - precision_5: 0.9358\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3580 - mse: 0.0306 - accuracy: 0.8947 - precision_5: 0.9403\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3308 - mse: 0.0279 - accuracy: 0.9184 - precision_5: 0.9618\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3103 - mse: 0.0260 - accuracy: 0.9258 - precision_5: 0.9639\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3123 - mse: 0.0266 - accuracy: 0.9273 - precision_5: 0.9578\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2792 - mse: 0.0230 - accuracy: 0.9318 - precision_5: 0.9727\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2711 - mse: 0.0225 - accuracy: 0.9273 - precision_5: 0.9602\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2456 - mse: 0.0205 - accuracy: 0.9407 - precision_5: 0.9666\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2481 - mse: 0.0203 - accuracy: 0.9377 - precision_5: 0.9622\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2301 - mse: 0.0192 - accuracy: 0.9407 - precision_5: 0.9671\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2235 - mse: 0.0184 - accuracy: 0.9496 - precision_5: 0.9767\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2246 - mse: 0.0190 - accuracy: 0.9392 - precision_5: 0.9626\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2103 - mse: 0.0175 - accuracy: 0.9496 - precision_5: 0.9659\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2101 - mse: 0.0175 - accuracy: 0.9525 - precision_5: 0.9659\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.1909 - mse: 0.0155 - accuracy: 0.9585 - precision_5: 0.9724\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.1883 - mse: 0.0155 - accuracy: 0.9599 - precision_5: 0.9751\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.1765 - mse: 0.0144 - accuracy: 0.9629 - precision_5: 0.9785\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.1791 - mse: 0.0150 - accuracy: 0.9540 - precision_5: 0.9709\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.1640 - mse: 0.0134 - accuracy: 0.9688 - precision_5: 0.9786\n",
            "Score for fold 2: loss of 1.139966368675232; mse of 0.07328949868679047;accuracy of 0.692307710647583;precision_5 of 0.7218543291091919\n",
            "s332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "rs332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "correct\n",
            "(None, 300)\n",
            "m332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 12, 18, 12) (None, 6, 10, 18, 12)\n",
            "(None, 6, 27, 6, 4)\n",
            "(None, 6, 27, 1, 1)\n",
            "(None, 162)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "m322\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 7, 18, 12) (None, 6, 14, 18, 12) (None, 6, 12, 18, 12)\n",
            "(None, 6, 33, 6, 4)\n",
            "(None, 6, 33, 1, 1)\n",
            "(None, 198)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "m222\n",
            "(None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 8, 72, 54) (None, 2, 8, 72, 54)\n",
            "(None, 2, 9, 24, 18) (None, 2, 18, 24, 18) (None, 2, 16, 24, 18)\n",
            "(None, 6, 9, 18, 12) (None, 6, 18, 18, 12) (None, 6, 16, 18, 12)\n",
            "(None, 6, 43, 6, 4)\n",
            "(None, 6, 43, 1, 1)\n",
            "(None, 258)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New ensemble model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 1.5552 - mse: 0.1240 - accuracy: 0.4095 - precision_5: 0.9231\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 1.1815 - mse: 0.0980 - accuracy: 0.5935 - precision_5: 0.8523\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 1.0048 - mse: 0.0851 - accuracy: 0.6736 - precision_5: 0.8555\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.8986 - mse: 0.0765 - accuracy: 0.7062 - precision_5: 0.8777\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.7874 - mse: 0.0673 - accuracy: 0.7359 - precision_5: 0.8634\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.7465 - mse: 0.0635 - accuracy: 0.7700 - precision_5: 0.8720\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.6696 - mse: 0.0579 - accuracy: 0.7938 - precision_5: 0.8925\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.6115 - mse: 0.0528 - accuracy: 0.8042 - precision_5: 0.8970\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.5643 - mse: 0.0479 - accuracy: 0.8383 - precision_5: 0.9148\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.5179 - mse: 0.0439 - accuracy: 0.8531 - precision_5: 0.9183\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.4862 - mse: 0.0416 - accuracy: 0.8620 - precision_5: 0.9204\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.4467 - mse: 0.0374 - accuracy: 0.8902 - precision_5: 0.9322\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.4101 - mse: 0.0345 - accuracy: 0.9065 - precision_5: 0.9469\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3872 - mse: 0.0325 - accuracy: 0.9050 - precision_5: 0.9422\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3546 - mse: 0.0292 - accuracy: 0.9228 - precision_5: 0.9570\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3391 - mse: 0.0282 - accuracy: 0.9125 - precision_5: 0.9507\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3210 - mse: 0.0264 - accuracy: 0.9303 - precision_5: 0.9552\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3012 - mse: 0.0246 - accuracy: 0.9421 - precision_5: 0.9601\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2980 - mse: 0.0256 - accuracy: 0.9184 - precision_5: 0.9487\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2610 - mse: 0.0210 - accuracy: 0.9555 - precision_5: 0.9688\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2593 - mse: 0.0204 - accuracy: 0.9451 - precision_5: 0.9669\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2319 - mse: 0.0184 - accuracy: 0.9585 - precision_5: 0.9660\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2278 - mse: 0.0184 - accuracy: 0.9525 - precision_5: 0.9633\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2270 - mse: 0.0186 - accuracy: 0.9496 - precision_5: 0.9675\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2086 - mse: 0.0168 - accuracy: 0.9659 - precision_5: 0.9770\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2055 - mse: 0.0167 - accuracy: 0.9599 - precision_5: 0.9736\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.1890 - mse: 0.0151 - accuracy: 0.9614 - precision_5: 0.9755\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.1952 - mse: 0.0156 - accuracy: 0.9599 - precision_5: 0.9801\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.1812 - mse: 0.0146 - accuracy: 0.9614 - precision_5: 0.9726\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.1837 - mse: 0.0150 - accuracy: 0.9585 - precision_5: 0.9740\n",
            "Score for fold 3: loss of 0.7409418821334839; mse of 0.05598434433341026;accuracy of 0.7810651063919067;precision_5 of 0.8417266011238098\n",
            "s332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "rs332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "correct\n",
            "(None, 300)\n",
            "m332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 12, 18, 12) (None, 6, 10, 18, 12)\n",
            "(None, 6, 27, 6, 4)\n",
            "(None, 6, 27, 1, 1)\n",
            "(None, 162)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "m322\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 7, 18, 12) (None, 6, 14, 18, 12) (None, 6, 12, 18, 12)\n",
            "(None, 6, 33, 6, 4)\n",
            "(None, 6, 33, 1, 1)\n",
            "(None, 198)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "m222\n",
            "(None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 8, 72, 54) (None, 2, 8, 72, 54)\n",
            "(None, 2, 9, 24, 18) (None, 2, 18, 24, 18) (None, 2, 16, 24, 18)\n",
            "(None, 6, 9, 18, 12) (None, 6, 18, 18, 12) (None, 6, 16, 18, 12)\n",
            "(None, 6, 43, 6, 4)\n",
            "(None, 6, 43, 1, 1)\n",
            "(None, 258)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New ensemble model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 1.5924 - mse: 0.1260 - accuracy: 0.3719 - precision_5: 0.6667\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 1.1364 - mse: 0.0943 - accuracy: 0.6207 - precision_5: 0.8028\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.9452 - mse: 0.0799 - accuracy: 0.6696 - precision_5: 0.8450\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.7966 - mse: 0.0680 - accuracy: 0.7393 - precision_5: 0.8665\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.6989 - mse: 0.0594 - accuracy: 0.7926 - precision_5: 0.8938\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.6302 - mse: 0.0542 - accuracy: 0.7956 - precision_5: 0.8948\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.5515 - mse: 0.0475 - accuracy: 0.8385 - precision_5: 0.9159\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.4850 - mse: 0.0420 - accuracy: 0.8637 - precision_5: 0.9298\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.4534 - mse: 0.0396 - accuracy: 0.8696 - precision_5: 0.9229\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.4076 - mse: 0.0350 - accuracy: 0.8830 - precision_5: 0.9353\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3813 - mse: 0.0332 - accuracy: 0.8904 - precision_5: 0.9286\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3517 - mse: 0.0304 - accuracy: 0.9156 - precision_5: 0.9438\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3238 - mse: 0.0274 - accuracy: 0.9215 - precision_5: 0.9511\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3171 - mse: 0.0268 - accuracy: 0.9348 - precision_5: 0.9562\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2952 - mse: 0.0249 - accuracy: 0.9333 - precision_5: 0.9565\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2811 - mse: 0.0242 - accuracy: 0.9319 - precision_5: 0.9511\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2722 - mse: 0.0228 - accuracy: 0.9348 - precision_5: 0.9634\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2467 - mse: 0.0201 - accuracy: 0.9556 - precision_5: 0.9842\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2516 - mse: 0.0209 - accuracy: 0.9407 - precision_5: 0.9700\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2148 - mse: 0.0175 - accuracy: 0.9644 - precision_5: 0.9784\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2194 - mse: 0.0176 - accuracy: 0.9659 - precision_5: 0.9828\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2096 - mse: 0.0165 - accuracy: 0.9630 - precision_5: 0.9814\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2086 - mse: 0.0170 - accuracy: 0.9541 - precision_5: 0.9705\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.1804 - mse: 0.0144 - accuracy: 0.9778 - precision_5: 0.9878\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.1908 - mse: 0.0156 - accuracy: 0.9600 - precision_5: 0.9784\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.1737 - mse: 0.0142 - accuracy: 0.9763 - precision_5: 0.9848\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.1758 - mse: 0.0140 - accuracy: 0.9807 - precision_5: 0.9923\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.1797 - mse: 0.0143 - accuracy: 0.9689 - precision_5: 0.9847\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.1579 - mse: 0.0123 - accuracy: 0.9867 - precision_5: 0.9924\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.1664 - mse: 0.0131 - accuracy: 0.9748 - precision_5: 0.9908\n",
            "Score for fold 4: loss of 0.8576427698135376; mse of 0.06227519363164902;accuracy of 0.738095223903656;precision_5 of 0.841269850730896\n",
            "s332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "rs332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "correct\n",
            "(None, 300)\n",
            "m332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 12, 18, 12) (None, 6, 10, 18, 12)\n",
            "(None, 6, 27, 6, 4)\n",
            "(None, 6, 27, 1, 1)\n",
            "(None, 162)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "m322\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 7, 18, 12) (None, 6, 14, 18, 12) (None, 6, 12, 18, 12)\n",
            "(None, 6, 33, 6, 4)\n",
            "(None, 6, 33, 1, 1)\n",
            "(None, 198)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "m222\n",
            "(None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 8, 72, 54) (None, 2, 8, 72, 54)\n",
            "(None, 2, 9, 24, 18) (None, 2, 18, 24, 18) (None, 2, 16, 24, 18)\n",
            "(None, 6, 9, 18, 12) (None, 6, 18, 18, 12) (None, 6, 16, 18, 12)\n",
            "(None, 6, 43, 6, 4)\n",
            "(None, 6, 43, 1, 1)\n",
            "(None, 258)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New ensemble model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 1.5803 - mse: 0.1250 - accuracy: 0.3852 - precision_5: 0.9231\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 1.1735 - mse: 0.0965 - accuracy: 0.6089 - precision_5: 0.8305\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.9864 - mse: 0.0813 - accuracy: 0.6696 - precision_5: 0.8893\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.8345 - mse: 0.0695 - accuracy: 0.7348 - precision_5: 0.8835\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.7199 - mse: 0.0610 - accuracy: 0.7778 - precision_5: 0.9023\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.6415 - mse: 0.0547 - accuracy: 0.7881 - precision_5: 0.9310\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.5828 - mse: 0.0498 - accuracy: 0.8296 - precision_5: 0.9238\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.5174 - mse: 0.0451 - accuracy: 0.8400 - precision_5: 0.9134\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.4940 - mse: 0.0425 - accuracy: 0.8681 - precision_5: 0.9267\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.4409 - mse: 0.0382 - accuracy: 0.8726 - precision_5: 0.9343\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.4019 - mse: 0.0348 - accuracy: 0.8904 - precision_5: 0.9415\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3984 - mse: 0.0343 - accuracy: 0.8993 - precision_5: 0.9472\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3534 - mse: 0.0307 - accuracy: 0.9052 - precision_5: 0.9475\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3571 - mse: 0.0308 - accuracy: 0.9007 - precision_5: 0.9513\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3486 - mse: 0.0293 - accuracy: 0.9141 - precision_5: 0.9518\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.3034 - mse: 0.0256 - accuracy: 0.9378 - precision_5: 0.9677\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2898 - mse: 0.0246 - accuracy: 0.9259 - precision_5: 0.9600\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2829 - mse: 0.0237 - accuracy: 0.9393 - precision_5: 0.9695\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2569 - mse: 0.0215 - accuracy: 0.9496 - precision_5: 0.9778\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2584 - mse: 0.0210 - accuracy: 0.9467 - precision_5: 0.9764\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2407 - mse: 0.0196 - accuracy: 0.9556 - precision_5: 0.9827\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2410 - mse: 0.0202 - accuracy: 0.9467 - precision_5: 0.9748\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2406 - mse: 0.0198 - accuracy: 0.9511 - precision_5: 0.9796\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2263 - mse: 0.0181 - accuracy: 0.9659 - precision_5: 0.9829\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2100 - mse: 0.0172 - accuracy: 0.9644 - precision_5: 0.9860\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2115 - mse: 0.0171 - accuracy: 0.9704 - precision_5: 0.9843\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2119 - mse: 0.0177 - accuracy: 0.9644 - precision_5: 0.9812\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.2118 - mse: 0.0171 - accuracy: 0.9615 - precision_5: 0.9844\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.1961 - mse: 0.0159 - accuracy: 0.9674 - precision_5: 0.9816\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.1968 - mse: 0.0159 - accuracy: 0.9733 - precision_5: 0.9860\n",
            "Score for fold 5: loss of 1.066394567489624; mse of 0.056998174637556076;accuracy of 0.7976190447807312;precision_5 of 0.8613138794898987\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 0.7109414935112 - Accuracy: 0.8165680766105652 - Precision: 0.8541666865348816%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 1.139966368675232 - Accuracy: 0.692307710647583 - Precision: 0.7218543291091919%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 0.7409418821334839 - Accuracy: 0.7810651063919067 - Precision: 0.8417266011238098%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 0.8576427698135376 - Accuracy: 0.738095223903656 - Precision: 0.841269850730896%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 1.066394567489624 - Accuracy: 0.7976190447807312 - Precision: 0.8613138794898987%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 0.7651310324668884 (+- 0.04469744133987264)\n",
            "> Loss: 0.9031774163246155\n",
            "> Precision: 0.8240662693977356\n",
            "------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3o3-YsqQavr",
        "outputId": "d7740c8d-bf0b-476c-9af8-f11c7f503edc"
      },
      "source": [
        "print(results_tanh)\n",
        "filename = '/content/drive/MyDrive/ML_CSP774/Theory_project/3D-CNN Activity Recognition/Pickle/all_tanh_RMSProp_30epochs.pickle'\n",
        "with open(filename, 'wb') as f:\n",
        "    pickle.dump(results_tanh, f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'m332': array([[2.23271036, 1.10481191, 0.89279789, 1.13916254, 1.12104595],\n",
            "       [0.10517897, 0.07734267, 0.06445088, 0.07845643, 0.06672353],\n",
            "       [0.61538464, 0.71005917, 0.76923078, 0.70833331, 0.75      ],\n",
            "       [0.63975155, 0.72222221, 0.77914113, 0.71515149, 0.75449103]]), 'm322': array([[1.50189686, 1.07385194, 1.15622187, 1.1340059 , 1.2498877 ],\n",
            "       [0.09038183, 0.07583959, 0.08103921, 0.08138732, 0.07879156],\n",
            "       [0.65680474, 0.69822484, 0.69230771, 0.68452382, 0.6964286 ],\n",
            "       [0.66463417, 0.71341461, 0.71974522, 0.69512194, 0.71428573]]), 'm222': array([[1.23433244, 1.07053387, 1.28994107, 1.2069459 , 1.59902668],\n",
            "       [0.06920992, 0.07525548, 0.08288603, 0.07261007, 0.09609405],\n",
            "       [0.76331359, 0.71005917, 0.69822484, 0.72619045, 0.63690478],\n",
            "       [0.77439022, 0.71604937, 0.71165645, 0.73456788, 0.65625   ]]), 'rs332': array([[1.45090783, 2.31357837, 1.67474961, 1.37894809, 1.60475481],\n",
            "       [0.09002029, 0.10770057, 0.08622731, 0.08429853, 0.08961982],\n",
            "       [0.66863906, 0.60946745, 0.6745562 , 0.68452382, 0.67261904],\n",
            "       [0.66463417, 0.62195122, 0.69325155, 0.69999999, 0.68711656]]), 'ensemble5': array([[0.71094149, 1.13996637, 0.74094188, 0.85764277, 1.06639457],\n",
            "       [0.0496211 , 0.0732895 , 0.05598434, 0.06227519, 0.05699817],\n",
            "       [0.81656808, 0.69230771, 0.78106511, 0.73809522, 0.79761904],\n",
            "       [0.85416669, 0.72185433, 0.8417266 , 0.84126985, 0.86131388]])}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1S42pNnjPHM"
      },
      "source": [
        "## Swish and RMSProp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6_CRGlJjS1W"
      },
      "source": [
        "### Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jfe_oYndQvD1"
      },
      "source": [
        "def swish(x):\n",
        "    return (keras.activations.sigmoid(x) * x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V4uAXRfjZJd"
      },
      "source": [
        "### Model s332"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkdrYNX7Rk-g",
        "outputId": "88636a39-e041-4cee-c16c-71d87f6007df"
      },
      "source": [
        "results_swish = {}\n",
        "loss,mse,acc,prec = kfold_validation(\"s332\",M1_ufc,M2_ufc,M3_ufc,M4_ufc,M5_ufc,Train_ufc_y,pca_SPM_cube_ufc_reloaded,32,25,1,None,\"swish\")\n",
        "results_swish[\"s332\"] = np.array((loss,mse,acc,prec))\n",
        "filename = '/content/drive/MyDrive/ML_CSP774/Theory_project/3D-CNN Activity Recognition/Pickle/s332_30epochs_swish.pickle'\n",
        "with open(filename, 'wb') as f:\n",
        "    pickle.dump(results_swish[\"s332\"], f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "s332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New s332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "22/22 [==============================] - 6s 259ms/step - loss: 1.5384 - mse: 0.1232 - accuracy: 0.3961 - precision: 0.6711\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 1.1724 - mse: 0.0993 - accuracy: 0.5415 - precision: 0.6711\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 1.0185 - mse: 0.0878 - accuracy: 0.6068 - precision: 0.7039\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 0.9118 - mse: 0.0794 - accuracy: 0.6513 - precision: 0.7394\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.7975 - mse: 0.0690 - accuracy: 0.7092 - precision: 0.7895\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 0.7300 - mse: 0.0629 - accuracy: 0.7463 - precision: 0.8225\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.6425 - mse: 0.0545 - accuracy: 0.7967 - precision: 0.8539\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 0.5852 - mse: 0.0502 - accuracy: 0.7938 - precision: 0.8439\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.5207 - mse: 0.0441 - accuracy: 0.8220 - precision: 0.8739\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.4830 - mse: 0.0414 - accuracy: 0.8220 - precision: 0.8679\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.4353 - mse: 0.0373 - accuracy: 0.8412 - precision: 0.8795\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.3701 - mse: 0.0326 - accuracy: 0.8650 - precision: 0.9097\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.3369 - mse: 0.0295 - accuracy: 0.8754 - precision: 0.9039\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 6s 253ms/step - loss: 0.2844 - mse: 0.0241 - accuracy: 0.9065 - precision: 0.9240\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.2635 - mse: 0.0227 - accuracy: 0.9065 - precision: 0.9187\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.2201 - mse: 0.0189 - accuracy: 0.9258 - precision: 0.9359\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.1961 - mse: 0.0169 - accuracy: 0.9362 - precision: 0.9528\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.1669 - mse: 0.0144 - accuracy: 0.9421 - precision: 0.9514\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.1315 - mse: 0.0108 - accuracy: 0.9599 - precision: 0.9729\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 0.1177 - mse: 0.0094 - accuracy: 0.9688 - precision: 0.9744\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.1079 - mse: 0.0090 - accuracy: 0.9674 - precision: 0.9669\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 0.0759 - mse: 0.0063 - accuracy: 0.9792 - precision: 0.9835\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 0.0647 - mse: 0.0051 - accuracy: 0.9807 - precision: 0.9850\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 0.0410 - mse: 0.0028 - accuracy: 0.9911 - precision: 0.9911\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 0.0260 - mse: 0.0015 - accuracy: 0.9955 - precision: 0.9955\n",
            "Score for fold 1: loss of 1.325236439704895; mse of 0.0657564103603363;accuracy of 0.7633135914802551;precision of 0.7633135914802551\n",
            "s332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New s332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 1.5570 - mse: 0.1235 - accuracy: 0.3383 - precision: 0.7368\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 6s 253ms/step - loss: 1.1669 - mse: 0.0966 - accuracy: 0.5415 - precision: 0.7992\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 0.9966 - mse: 0.0842 - accuracy: 0.6113 - precision: 0.7252\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 0.8563 - mse: 0.0738 - accuracy: 0.6766 - precision: 0.7773\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.7633 - mse: 0.0647 - accuracy: 0.7389 - precision: 0.8147\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 0.6997 - mse: 0.0602 - accuracy: 0.7433 - precision: 0.8192\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 0.6183 - mse: 0.0524 - accuracy: 0.7878 - precision: 0.8553\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 0.5742 - mse: 0.0485 - accuracy: 0.7982 - precision: 0.8688\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 0.5119 - mse: 0.0425 - accuracy: 0.8234 - precision: 0.8827\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 0.4525 - mse: 0.0382 - accuracy: 0.8412 - precision: 0.8905\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.4067 - mse: 0.0343 - accuracy: 0.8516 - precision: 0.8925\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 0.3751 - mse: 0.0323 - accuracy: 0.8605 - precision: 0.9019\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 0.3323 - mse: 0.0284 - accuracy: 0.8813 - precision: 0.9185\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.2892 - mse: 0.0247 - accuracy: 0.8961 - precision: 0.9238\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.2675 - mse: 0.0229 - accuracy: 0.9006 - precision: 0.9238\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 0.2282 - mse: 0.0199 - accuracy: 0.9110 - precision: 0.9291\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 0.1802 - mse: 0.0155 - accuracy: 0.9362 - precision: 0.9510\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.1486 - mse: 0.0131 - accuracy: 0.9407 - precision: 0.9545\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 0.1392 - mse: 0.0119 - accuracy: 0.9570 - precision: 0.9668\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.1122 - mse: 0.0091 - accuracy: 0.9688 - precision: 0.9758\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 0.0971 - mse: 0.0081 - accuracy: 0.9733 - precision: 0.9818\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.0731 - mse: 0.0059 - accuracy: 0.9807 - precision: 0.9821\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.0823 - mse: 0.0068 - accuracy: 0.9733 - precision: 0.9790\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 0.0386 - mse: 0.0025 - accuracy: 0.9926 - precision: 0.9941\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.0636 - mse: 0.0055 - accuracy: 0.9748 - precision: 0.9776\n",
            "Score for fold 2: loss of 1.735182523727417; mse of 0.08503926545381546;accuracy of 0.715976357460022;precision of 0.7202380895614624\n",
            "s332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New s332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 1.5043 - mse: 0.1207 - accuracy: 0.3872 - precision: 0.7647\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 1.1611 - mse: 0.0980 - accuracy: 0.5237 - precision: 0.7039\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 1.0254 - mse: 0.0882 - accuracy: 0.6053 - precision: 0.7187\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 0.8835 - mse: 0.0765 - accuracy: 0.6662 - precision: 0.7669\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.7871 - mse: 0.0674 - accuracy: 0.7166 - precision: 0.7874\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 0.7279 - mse: 0.0629 - accuracy: 0.7300 - precision: 0.8007\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.6328 - mse: 0.0548 - accuracy: 0.7596 - precision: 0.8064\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.6044 - mse: 0.0515 - accuracy: 0.7878 - precision: 0.8450\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.5495 - mse: 0.0470 - accuracy: 0.8145 - precision: 0.8525\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 0.5139 - mse: 0.0439 - accuracy: 0.8190 - precision: 0.8512\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.4471 - mse: 0.0369 - accuracy: 0.8472 - precision: 0.8849\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 0.4128 - mse: 0.0351 - accuracy: 0.8576 - precision: 0.8875\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 0.3711 - mse: 0.0311 - accuracy: 0.8739 - precision: 0.8970\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.3180 - mse: 0.0281 - accuracy: 0.8813 - precision: 0.9084\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 0.3042 - mse: 0.0262 - accuracy: 0.9006 - precision: 0.9215\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.2538 - mse: 0.0221 - accuracy: 0.9065 - precision: 0.9287\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.2196 - mse: 0.0185 - accuracy: 0.9243 - precision: 0.9334\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 0.1958 - mse: 0.0160 - accuracy: 0.9436 - precision: 0.9588\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 0.1955 - mse: 0.0160 - accuracy: 0.9392 - precision: 0.9486\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.1395 - mse: 0.0117 - accuracy: 0.9525 - precision: 0.9607\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.1328 - mse: 0.0111 - accuracy: 0.9585 - precision: 0.9652\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 0.0918 - mse: 0.0072 - accuracy: 0.9703 - precision: 0.9775\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.0947 - mse: 0.0076 - accuracy: 0.9688 - precision: 0.9789\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.0852 - mse: 0.0072 - accuracy: 0.9718 - precision: 0.9747\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.0593 - mse: 0.0043 - accuracy: 0.9837 - precision: 0.9866\n",
            "Score for fold 3: loss of 1.6956003904342651; mse of 0.08873724937438965;accuracy of 0.6804733872413635;precision of 0.6969696879386902\n",
            "s332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New s332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 1.5517 - mse: 0.1240 - accuracy: 0.3778 - precision: 0.6486\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 1.1535 - mse: 0.0965 - accuracy: 0.5674 - precision: 0.7031\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 0.9726 - mse: 0.0839 - accuracy: 0.6222 - precision: 0.7378\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 0.8439 - mse: 0.0731 - accuracy: 0.6770 - precision: 0.7705\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.7516 - mse: 0.0651 - accuracy: 0.7141 - precision: 0.8011\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.6548 - mse: 0.0571 - accuracy: 0.7630 - precision: 0.8151\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.5811 - mse: 0.0511 - accuracy: 0.7911 - precision: 0.8328\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.5196 - mse: 0.0453 - accuracy: 0.7896 - precision: 0.8472\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.4338 - mse: 0.0373 - accuracy: 0.8415 - precision: 0.8883\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.3939 - mse: 0.0337 - accuracy: 0.8519 - precision: 0.8952\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.3602 - mse: 0.0325 - accuracy: 0.8563 - precision: 0.8857\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 0.3103 - mse: 0.0259 - accuracy: 0.9007 - precision: 0.9234\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.2969 - mse: 0.0259 - accuracy: 0.8963 - precision: 0.9218\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.2418 - mse: 0.0203 - accuracy: 0.9200 - precision: 0.9300\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 0.2106 - mse: 0.0181 - accuracy: 0.9304 - precision: 0.9423\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 0.1816 - mse: 0.0157 - accuracy: 0.9348 - precision: 0.9498\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.1784 - mse: 0.0152 - accuracy: 0.9393 - precision: 0.9587\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.1180 - mse: 0.0099 - accuracy: 0.9659 - precision: 0.9745\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.1623 - mse: 0.0145 - accuracy: 0.9407 - precision: 0.9474\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.0872 - mse: 0.0069 - accuracy: 0.9733 - precision: 0.9791\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.0762 - mse: 0.0062 - accuracy: 0.9793 - precision: 0.9806\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.0981 - mse: 0.0085 - accuracy: 0.9659 - precision: 0.9687\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 6s 258ms/step - loss: 0.0726 - mse: 0.0065 - accuracy: 0.9763 - precision: 0.9777\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.0581 - mse: 0.0050 - accuracy: 0.9778 - precision: 0.9821\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.0513 - mse: 0.0042 - accuracy: 0.9837 - precision: 0.9837\n",
            "Score for fold 4: loss of 1.2571965456008911; mse of 0.07046305388212204;accuracy of 0.7559523582458496;precision of 0.7621951103210449\n",
            "s332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New s332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 1.5720 - mse: 0.1254 - accuracy: 0.3615 - precision: 0.7353\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 1.1056 - mse: 0.0915 - accuracy: 0.5985 - precision: 0.7939\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 0.8890 - mse: 0.0750 - accuracy: 0.6711 - precision: 0.7921\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.7837 - mse: 0.0663 - accuracy: 0.7170 - precision: 0.8019\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.6864 - mse: 0.0598 - accuracy: 0.7289 - precision: 0.8069\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 6s 253ms/step - loss: 0.5993 - mse: 0.0523 - accuracy: 0.7704 - precision: 0.8297\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.5406 - mse: 0.0461 - accuracy: 0.8119 - precision: 0.8475\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.4589 - mse: 0.0394 - accuracy: 0.8341 - precision: 0.8776\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.4071 - mse: 0.0348 - accuracy: 0.8652 - precision: 0.8906\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.3481 - mse: 0.0300 - accuracy: 0.8815 - precision: 0.8997\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.3230 - mse: 0.0269 - accuracy: 0.8889 - precision: 0.9214\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 0.2897 - mse: 0.0253 - accuracy: 0.8904 - precision: 0.9216\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 0.2420 - mse: 0.0215 - accuracy: 0.9067 - precision: 0.9202\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.1900 - mse: 0.0158 - accuracy: 0.9378 - precision: 0.9631\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 0.1870 - mse: 0.0154 - accuracy: 0.9467 - precision: 0.9505\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 0.1695 - mse: 0.0148 - accuracy: 0.9422 - precision: 0.9447\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 0.1112 - mse: 0.0088 - accuracy: 0.9674 - precision: 0.9746\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 0.1311 - mse: 0.0118 - accuracy: 0.9541 - precision: 0.9625\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.0900 - mse: 0.0071 - accuracy: 0.9719 - precision: 0.9776\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.0782 - mse: 0.0060 - accuracy: 0.9793 - precision: 0.9806\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 0.0626 - mse: 0.0051 - accuracy: 0.9793 - precision: 0.9822\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 6s 255ms/step - loss: 0.0682 - mse: 0.0050 - accuracy: 0.9837 - precision: 0.9837\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 0.0722 - mse: 0.0065 - accuracy: 0.9778 - precision: 0.9806\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 0.0583 - mse: 0.0049 - accuracy: 0.9822 - precision: 0.9851\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 0.0219 - mse: 0.0012 - accuracy: 0.9970 - precision: 0.9985\n",
            "Score for fold 5: loss of 1.4689048528671265; mse of 0.06800109148025513;accuracy of 0.761904776096344;precision of 0.761904776096344\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 1.325236439704895 - Accuracy: 0.7633135914802551 - Precision: 0.7633135914802551%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 1.735182523727417 - Accuracy: 0.715976357460022 - Precision: 0.7202380895614624%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 1.6956003904342651 - Accuracy: 0.6804733872413635 - Precision: 0.6969696879386902%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 1.2571965456008911 - Accuracy: 0.7559523582458496 - Precision: 0.7621951103210449%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 1.4689048528671265 - Accuracy: 0.761904776096344 - Precision: 0.761904776096344%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 0.7355240941047668 (+- 0.03255212698621552)\n",
            "> Loss: 1.496424150466919\n",
            "> Precision: 0.7409242510795593\n",
            "------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Z0uLdrmjbxR"
      },
      "source": [
        "### Model m332"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ViAHWs0Uw59",
        "outputId": "f0837b3b-6e66-4e27-8510-9de214e73f56"
      },
      "source": [
        "loss,mse,acc,prec = kfold_validation(\"m332\",M1_ufc,M2_ufc,M3_ufc,M4_ufc,M5_ufc,Train_ufc_y,pca_SPM_cube_ufc_reloaded,32,25,1,None,\"swish\")\n",
        "results_swish[\"m332\"] = np.array((loss,mse,acc,prec))\n",
        "filename = '/content/drive/MyDrive/ML_CSP774/Theory_project/3D-CNN Activity Recognition/Pickle/m332_30epochs_swish.pickle'\n",
        "with open(filename, 'wb') as f:\n",
        "    pickle.dump(results_swish[\"m332\"], f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "m332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 12, 18, 12) (None, 6, 10, 18, 12)\n",
            "(None, 6, 27, 6, 4)\n",
            "(None, 6, 27, 1, 1)\n",
            "(None, 162)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "22/22 [==============================] - 6s 253ms/step - loss: 1.5926 - mse: 0.1259 - accuracy: 0.3501 - precision: 0.7949\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 6s 252ms/step - loss: 1.1745 - mse: 0.0995 - accuracy: 0.5430 - precision: 0.7029\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 6s 252ms/step - loss: 1.0163 - mse: 0.0871 - accuracy: 0.6024 - precision: 0.7440\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.9090 - mse: 0.0783 - accuracy: 0.6647 - precision: 0.7577\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.8303 - mse: 0.0723 - accuracy: 0.6958 - precision: 0.7714\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 6s 253ms/step - loss: 0.7880 - mse: 0.0679 - accuracy: 0.7062 - precision: 0.7561\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 6s 253ms/step - loss: 0.7275 - mse: 0.0635 - accuracy: 0.7255 - precision: 0.8045\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 6s 252ms/step - loss: 0.6735 - mse: 0.0587 - accuracy: 0.7552 - precision: 0.8180\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 6s 252ms/step - loss: 0.5942 - mse: 0.0515 - accuracy: 0.7849 - precision: 0.8330\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 5s 250ms/step - loss: 0.6010 - mse: 0.0518 - accuracy: 0.7878 - precision: 0.8365\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 6s 250ms/step - loss: 0.5401 - mse: 0.0462 - accuracy: 0.8131 - precision: 0.8479\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.4926 - mse: 0.0421 - accuracy: 0.8190 - precision: 0.8670\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.4774 - mse: 0.0417 - accuracy: 0.8368 - precision: 0.8574\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 6s 250ms/step - loss: 0.4600 - mse: 0.0388 - accuracy: 0.8561 - precision: 0.8806\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 6s 250ms/step - loss: 0.4073 - mse: 0.0351 - accuracy: 0.8591 - precision: 0.8754\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 5s 250ms/step - loss: 0.3754 - mse: 0.0323 - accuracy: 0.8709 - precision: 0.8915\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.4007 - mse: 0.0332 - accuracy: 0.8709 - precision: 0.8830\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.3304 - mse: 0.0284 - accuracy: 0.8917 - precision: 0.9119\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.3054 - mse: 0.0260 - accuracy: 0.8902 - precision: 0.9097\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 6s 250ms/step - loss: 0.3151 - mse: 0.0250 - accuracy: 0.9080 - precision: 0.9212\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 6s 250ms/step - loss: 0.2734 - mse: 0.0225 - accuracy: 0.9184 - precision: 0.9299\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.2768 - mse: 0.0232 - accuracy: 0.9036 - precision: 0.9163\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 5s 250ms/step - loss: 0.2341 - mse: 0.0195 - accuracy: 0.9258 - precision: 0.9362\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.2044 - mse: 0.0166 - accuracy: 0.9392 - precision: 0.9481\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 5s 248ms/step - loss: 0.1823 - mse: 0.0149 - accuracy: 0.9421 - precision: 0.9630\n",
            "Score for fold 1: loss of 1.4683226346969604; mse of 0.08736539632081985;accuracy of 0.6863905191421509;precision of 0.6932515501976013\n",
            "m332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 12, 18, 12) (None, 6, 10, 18, 12)\n",
            "(None, 6, 27, 6, 4)\n",
            "(None, 6, 27, 1, 1)\n",
            "(None, 162)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 1.5765 - mse: 0.1247 - accuracy: 0.3353 - precision: 0.6625\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 1.2310 - mse: 0.1024 - accuracy: 0.5252 - precision: 0.6923\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 6s 250ms/step - loss: 1.0700 - mse: 0.0907 - accuracy: 0.5801 - precision: 0.7066\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.9608 - mse: 0.0831 - accuracy: 0.6335 - precision: 0.7429\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 6s 250ms/step - loss: 0.8473 - mse: 0.0732 - accuracy: 0.7062 - precision: 0.7829\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 5s 250ms/step - loss: 0.7794 - mse: 0.0679 - accuracy: 0.7122 - precision: 0.7840\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 5s 250ms/step - loss: 0.7051 - mse: 0.0605 - accuracy: 0.7418 - precision: 0.8220\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 5s 250ms/step - loss: 0.6456 - mse: 0.0564 - accuracy: 0.7493 - precision: 0.8153\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.6080 - mse: 0.0534 - accuracy: 0.7715 - precision: 0.8264\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.5729 - mse: 0.0505 - accuracy: 0.7804 - precision: 0.8350\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 5s 250ms/step - loss: 0.4902 - mse: 0.0428 - accuracy: 0.8205 - precision: 0.8654\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.4775 - mse: 0.0407 - accuracy: 0.8309 - precision: 0.8770\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 6s 250ms/step - loss: 0.4323 - mse: 0.0386 - accuracy: 0.8338 - precision: 0.8688\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.3903 - mse: 0.0346 - accuracy: 0.8442 - precision: 0.8875\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.3470 - mse: 0.0311 - accuracy: 0.8665 - precision: 0.8998\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 6s 250ms/step - loss: 0.3212 - mse: 0.0290 - accuracy: 0.8872 - precision: 0.9044\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.2846 - mse: 0.0254 - accuracy: 0.9036 - precision: 0.9249\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 5s 250ms/step - loss: 0.2730 - mse: 0.0241 - accuracy: 0.9036 - precision: 0.9159\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 6s 250ms/step - loss: 0.2570 - mse: 0.0230 - accuracy: 0.9050 - precision: 0.9243\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.2137 - mse: 0.0190 - accuracy: 0.9288 - precision: 0.9363\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 5s 250ms/step - loss: 0.2159 - mse: 0.0195 - accuracy: 0.9199 - precision: 0.9316\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 6s 250ms/step - loss: 0.1701 - mse: 0.0151 - accuracy: 0.9392 - precision: 0.9482\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 6s 250ms/step - loss: 0.1621 - mse: 0.0140 - accuracy: 0.9481 - precision: 0.9634\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.1627 - mse: 0.0143 - accuracy: 0.9481 - precision: 0.9559\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 5s 249ms/step - loss: 0.1206 - mse: 0.0101 - accuracy: 0.9570 - precision: 0.9682\n",
            "Score for fold 2: loss of 1.4290847778320312; mse of 0.09060841053724289;accuracy of 0.6627218723297119;precision of 0.6666666865348816\n",
            "m332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 12, 18, 12) (None, 6, 10, 18, 12)\n",
            "(None, 6, 27, 6, 4)\n",
            "(None, 6, 27, 1, 1)\n",
            "(None, 162)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 6s 250ms/step - loss: 1.5279 - mse: 0.1217 - accuracy: 0.3947 - precision: 0.6667\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 5s 250ms/step - loss: 1.1044 - mse: 0.0933 - accuracy: 0.5564 - precision: 0.7215\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.9129 - mse: 0.0768 - accuracy: 0.6929 - precision: 0.7719\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.7542 - mse: 0.0640 - accuracy: 0.7315 - precision: 0.8313\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 6s 250ms/step - loss: 0.7157 - mse: 0.0600 - accuracy: 0.7567 - precision: 0.8011\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 6s 250ms/step - loss: 0.6357 - mse: 0.0550 - accuracy: 0.7582 - precision: 0.8214\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 5s 250ms/step - loss: 0.5830 - mse: 0.0489 - accuracy: 0.7893 - precision: 0.8438\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 6s 250ms/step - loss: 0.5239 - mse: 0.0453 - accuracy: 0.8116 - precision: 0.8392\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.4786 - mse: 0.0406 - accuracy: 0.8353 - precision: 0.8760\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.4486 - mse: 0.0380 - accuracy: 0.8561 - precision: 0.8800\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.4475 - mse: 0.0381 - accuracy: 0.8427 - precision: 0.8722\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 5s 250ms/step - loss: 0.4105 - mse: 0.0359 - accuracy: 0.8605 - precision: 0.8887\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 6s 250ms/step - loss: 0.3796 - mse: 0.0327 - accuracy: 0.8680 - precision: 0.8910\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.3231 - mse: 0.0273 - accuracy: 0.8932 - precision: 0.9134\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.3564 - mse: 0.0303 - accuracy: 0.8813 - precision: 0.9061\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 5s 250ms/step - loss: 0.3313 - mse: 0.0281 - accuracy: 0.8991 - precision: 0.9174\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 6s 250ms/step - loss: 0.2979 - mse: 0.0259 - accuracy: 0.9050 - precision: 0.9243\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 5s 250ms/step - loss: 0.2615 - mse: 0.0218 - accuracy: 0.9199 - precision: 0.9312\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 5s 250ms/step - loss: 0.2563 - mse: 0.0215 - accuracy: 0.9214 - precision: 0.9271\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 6s 250ms/step - loss: 0.2526 - mse: 0.0219 - accuracy: 0.9139 - precision: 0.9302\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 6s 250ms/step - loss: 0.2465 - mse: 0.0209 - accuracy: 0.9199 - precision: 0.9342\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 5s 250ms/step - loss: 0.2131 - mse: 0.0175 - accuracy: 0.9392 - precision: 0.9497\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 5s 250ms/step - loss: 0.1741 - mse: 0.0150 - accuracy: 0.9407 - precision: 0.9513\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 6s 250ms/step - loss: 0.1667 - mse: 0.0145 - accuracy: 0.9481 - precision: 0.9532\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 5s 250ms/step - loss: 0.1697 - mse: 0.0142 - accuracy: 0.9421 - precision: 0.9498\n",
            "Score for fold 3: loss of 1.5367908477783203; mse of 0.09104301780462265;accuracy of 0.692307710647583;precision of 0.6962025165557861\n",
            "m332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 12, 18, 12) (None, 6, 10, 18, 12)\n",
            "(None, 6, 27, 6, 4)\n",
            "(None, 6, 27, 1, 1)\n",
            "(None, 162)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 1.5580 - mse: 0.1242 - accuracy: 0.3778 - precision: 0.6216\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 5s 250ms/step - loss: 1.2222 - mse: 0.1003 - accuracy: 0.5467 - precision: 0.7532\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 6s 250ms/step - loss: 1.0747 - mse: 0.0916 - accuracy: 0.5748 - precision: 0.7160\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 6s 250ms/step - loss: 0.9684 - mse: 0.0841 - accuracy: 0.6089 - precision: 0.7423\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 6s 250ms/step - loss: 0.8937 - mse: 0.0768 - accuracy: 0.6607 - precision: 0.7770\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.7947 - mse: 0.0678 - accuracy: 0.7185 - precision: 0.8113\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.7448 - mse: 0.0648 - accuracy: 0.7126 - precision: 0.7907\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 6s 253ms/step - loss: 0.6642 - mse: 0.0579 - accuracy: 0.7467 - precision: 0.8284\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 5s 250ms/step - loss: 0.6239 - mse: 0.0544 - accuracy: 0.7689 - precision: 0.8470\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.5735 - mse: 0.0499 - accuracy: 0.7793 - precision: 0.8409\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.5079 - mse: 0.0439 - accuracy: 0.8163 - precision: 0.8645\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 6s 252ms/step - loss: 0.4710 - mse: 0.0409 - accuracy: 0.8207 - precision: 0.8789\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.4526 - mse: 0.0389 - accuracy: 0.8267 - precision: 0.8777\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.4251 - mse: 0.0373 - accuracy: 0.8415 - precision: 0.8842\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 6s 252ms/step - loss: 0.3813 - mse: 0.0341 - accuracy: 0.8430 - precision: 0.8778\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.3374 - mse: 0.0300 - accuracy: 0.8770 - precision: 0.9103\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.3274 - mse: 0.0289 - accuracy: 0.8785 - precision: 0.9079\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.2905 - mse: 0.0254 - accuracy: 0.9052 - precision: 0.9280\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 6s 253ms/step - loss: 0.2803 - mse: 0.0241 - accuracy: 0.9022 - precision: 0.9269\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.2327 - mse: 0.0204 - accuracy: 0.9200 - precision: 0.9401\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.2305 - mse: 0.0200 - accuracy: 0.9185 - precision: 0.9400\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.1992 - mse: 0.0167 - accuracy: 0.9422 - precision: 0.9514\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 6s 252ms/step - loss: 0.1941 - mse: 0.0170 - accuracy: 0.9304 - precision: 0.9392\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.1673 - mse: 0.0146 - accuracy: 0.9467 - precision: 0.9560\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 6s 250ms/step - loss: 0.1375 - mse: 0.0119 - accuracy: 0.9600 - precision: 0.9610\n",
            "Score for fold 4: loss of 1.1843732595443726; mse of 0.07995820045471191;accuracy of 0.7023809552192688;precision of 0.71875\n",
            "m332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 12, 18, 12) (None, 6, 10, 18, 12)\n",
            "(None, 6, 27, 6, 4)\n",
            "(None, 6, 27, 1, 1)\n",
            "(None, 162)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 1.5140 - mse: 0.1199 - accuracy: 0.4059 - precision: 0.7129\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 6s 252ms/step - loss: 1.0511 - mse: 0.0871 - accuracy: 0.6000 - precision: 0.7788\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 6s 250ms/step - loss: 0.9070 - mse: 0.0782 - accuracy: 0.6474 - precision: 0.7780\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 6s 252ms/step - loss: 0.7984 - mse: 0.0686 - accuracy: 0.6889 - precision: 0.7930\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.7200 - mse: 0.0629 - accuracy: 0.7200 - precision: 0.7954\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.6583 - mse: 0.0569 - accuracy: 0.7630 - precision: 0.8264\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.5975 - mse: 0.0514 - accuracy: 0.7748 - precision: 0.8571\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 6s 252ms/step - loss: 0.5557 - mse: 0.0487 - accuracy: 0.7896 - precision: 0.8524\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 6s 252ms/step - loss: 0.4847 - mse: 0.0420 - accuracy: 0.8252 - precision: 0.8714\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.4503 - mse: 0.0390 - accuracy: 0.8444 - precision: 0.8876\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 6s 252ms/step - loss: 0.4214 - mse: 0.0363 - accuracy: 0.8504 - precision: 0.8914\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 6s 252ms/step - loss: 0.3758 - mse: 0.0314 - accuracy: 0.8770 - precision: 0.9151\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 6s 253ms/step - loss: 0.3355 - mse: 0.0286 - accuracy: 0.8889 - precision: 0.9148\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 0.3074 - mse: 0.0266 - accuracy: 0.8919 - precision: 0.9219\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 6s 252ms/step - loss: 0.2982 - mse: 0.0253 - accuracy: 0.8933 - precision: 0.9264\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.2419 - mse: 0.0209 - accuracy: 0.9170 - precision: 0.9436\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 6s 250ms/step - loss: 0.2433 - mse: 0.0209 - accuracy: 0.9185 - precision: 0.9316\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.1981 - mse: 0.0167 - accuracy: 0.9422 - precision: 0.9513\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 6s 251ms/step - loss: 0.1948 - mse: 0.0164 - accuracy: 0.9393 - precision: 0.9497\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 6s 252ms/step - loss: 0.1653 - mse: 0.0138 - accuracy: 0.9496 - precision: 0.9617\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 6s 252ms/step - loss: 0.1519 - mse: 0.0124 - accuracy: 0.9570 - precision: 0.9625\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 6s 252ms/step - loss: 0.1272 - mse: 0.0104 - accuracy: 0.9630 - precision: 0.9729\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 6s 252ms/step - loss: 0.1550 - mse: 0.0125 - accuracy: 0.9556 - precision: 0.9653\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 6s 252ms/step - loss: 0.0893 - mse: 0.0070 - accuracy: 0.9733 - precision: 0.9820\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 6s 252ms/step - loss: 0.0978 - mse: 0.0082 - accuracy: 0.9719 - precision: 0.9746\n",
            "Score for fold 5: loss of 1.395328164100647; mse of 0.07980555295944214;accuracy of 0.7083333134651184;precision of 0.7134146094322205\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 1.4683226346969604 - Accuracy: 0.6863905191421509 - Precision: 0.6932515501976013%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 1.4290847778320312 - Accuracy: 0.6627218723297119 - Precision: 0.6666666865348816%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 1.5367908477783203 - Accuracy: 0.692307710647583 - Precision: 0.6962025165557861%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 1.1843732595443726 - Accuracy: 0.7023809552192688 - Precision: 0.71875%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 1.395328164100647 - Accuracy: 0.7083333134651184 - Precision: 0.7134146094322205%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 0.6904268741607666 (+- 0.01581731618637539)\n",
            "> Loss: 1.4027799367904663\n",
            "> Precision: 0.6976570725440979\n",
            "------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zFgXnNgjfQE"
      },
      "source": [
        "### Model m322"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QIe9F7FNX6N_",
        "outputId": "1a40df83-4099-412f-da9a-eac48ed419e1"
      },
      "source": [
        "loss,mse,acc,prec = kfold_validation(\"m322\",M1_ufc,M2_ufc,M3_ufc,M4_ufc,M5_ufc,Train_ufc_y,pca_SPM_cube_ufc_reloaded,32,25,1,None,\"swish\")\n",
        "results_swish[\"m322\"] = np.array((loss,mse,acc,prec))\n",
        "filename = '/content/drive/MyDrive/ML_CSP774/Theory_project/3D-CNN Activity Recognition/Pickle/m322_30epochs_swish.pickle'\n",
        "with open(filename, 'wb') as f:\n",
        "    pickle.dump(results_swish[\"m322\"], f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "m322\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 7, 18, 12) (None, 6, 14, 18, 12) (None, 6, 12, 18, 12)\n",
            "(None, 6, 33, 6, 4)\n",
            "(None, 6, 33, 1, 1)\n",
            "(None, 198)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m322 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "22/22 [==============================] - 6s 257ms/step - loss: 1.5901 - mse: 0.1267 - accuracy: 0.3294 - precision: 0.7419\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 1.1433 - mse: 0.0961 - accuracy: 0.5742 - precision: 0.7167\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.9720 - mse: 0.0825 - accuracy: 0.6454 - precision: 0.7554\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.8536 - mse: 0.0731 - accuracy: 0.6780 - precision: 0.7692\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.7632 - mse: 0.0659 - accuracy: 0.7181 - precision: 0.7829\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.6667 - mse: 0.0578 - accuracy: 0.7596 - precision: 0.8142\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.6346 - mse: 0.0553 - accuracy: 0.7582 - precision: 0.8229\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.5805 - mse: 0.0510 - accuracy: 0.7804 - precision: 0.8345\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.5401 - mse: 0.0471 - accuracy: 0.8056 - precision: 0.8463\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.4936 - mse: 0.0429 - accuracy: 0.8205 - precision: 0.8635\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.4749 - mse: 0.0410 - accuracy: 0.8279 - precision: 0.8727\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.4487 - mse: 0.0396 - accuracy: 0.8398 - precision: 0.8722\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.4076 - mse: 0.0357 - accuracy: 0.8650 - precision: 0.8859\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.4055 - mse: 0.0348 - accuracy: 0.8650 - precision: 0.8894\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.3641 - mse: 0.0321 - accuracy: 0.8709 - precision: 0.8965\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.3528 - mse: 0.0304 - accuracy: 0.8828 - precision: 0.9054\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.3239 - mse: 0.0284 - accuracy: 0.8858 - precision: 0.9131\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 5s 243ms/step - loss: 0.2852 - mse: 0.0248 - accuracy: 0.9036 - precision: 0.9187\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.2798 - mse: 0.0243 - accuracy: 0.8961 - precision: 0.9199\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.2471 - mse: 0.0214 - accuracy: 0.9214 - precision: 0.9382\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.2268 - mse: 0.0200 - accuracy: 0.9214 - precision: 0.9368\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.2205 - mse: 0.0187 - accuracy: 0.9214 - precision: 0.9403\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.2022 - mse: 0.0175 - accuracy: 0.9362 - precision: 0.9467\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.1825 - mse: 0.0154 - accuracy: 0.9436 - precision: 0.9516\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.1726 - mse: 0.0153 - accuracy: 0.9362 - precision: 0.9396\n",
            "Score for fold 1: loss of 1.4869107007980347; mse of 0.09457463026046753;accuracy of 0.6331360936164856;precision of 0.6474359035491943\n",
            "m322\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 7, 18, 12) (None, 6, 14, 18, 12) (None, 6, 12, 18, 12)\n",
            "(None, 6, 33, 6, 4)\n",
            "(None, 6, 33, 1, 1)\n",
            "(None, 198)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m322 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 1.6015 - mse: 0.1274 - accuracy: 0.3546 - precision: 0.7500\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 1.1269 - mse: 0.0947 - accuracy: 0.5742 - precision: 0.7117\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 5s 243ms/step - loss: 0.9735 - mse: 0.0832 - accuracy: 0.6202 - precision: 0.7457\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.8477 - mse: 0.0724 - accuracy: 0.7047 - precision: 0.7821\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.7896 - mse: 0.0676 - accuracy: 0.7122 - precision: 0.7976\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.6645 - mse: 0.0569 - accuracy: 0.7478 - precision: 0.8355\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.6723 - mse: 0.0564 - accuracy: 0.7730 - precision: 0.8237\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.5957 - mse: 0.0502 - accuracy: 0.7997 - precision: 0.8584\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.5484 - mse: 0.0464 - accuracy: 0.8145 - precision: 0.8583\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.5189 - mse: 0.0445 - accuracy: 0.8056 - precision: 0.8517\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.4738 - mse: 0.0400 - accuracy: 0.8457 - precision: 0.8795\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.4545 - mse: 0.0386 - accuracy: 0.8398 - precision: 0.8746\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.4270 - mse: 0.0358 - accuracy: 0.8620 - precision: 0.8974\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.3947 - mse: 0.0338 - accuracy: 0.8605 - precision: 0.8937\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.3702 - mse: 0.0325 - accuracy: 0.8754 - precision: 0.9045\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.3462 - mse: 0.0294 - accuracy: 0.8887 - precision: 0.9091\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.3363 - mse: 0.0287 - accuracy: 0.8932 - precision: 0.9114\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.3035 - mse: 0.0265 - accuracy: 0.8858 - precision: 0.9098\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.3080 - mse: 0.0263 - accuracy: 0.9021 - precision: 0.9230\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.2595 - mse: 0.0217 - accuracy: 0.9139 - precision: 0.9280\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.2509 - mse: 0.0224 - accuracy: 0.9080 - precision: 0.9238\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.2579 - mse: 0.0216 - accuracy: 0.9169 - precision: 0.9343\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.2206 - mse: 0.0183 - accuracy: 0.9199 - precision: 0.9470\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.2438 - mse: 0.0210 - accuracy: 0.9199 - precision: 0.9324\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.1745 - mse: 0.0138 - accuracy: 0.9496 - precision: 0.9533\n",
            "Score for fold 2: loss of 1.3565988540649414; mse of 0.08298196643590927;accuracy of 0.692307710647583;precision of 0.7090908885002136\n",
            "m322\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 7, 18, 12) (None, 6, 14, 18, 12) (None, 6, 12, 18, 12)\n",
            "(None, 6, 33, 6, 4)\n",
            "(None, 6, 33, 1, 1)\n",
            "(None, 198)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m322 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 1.6287 - mse: 0.1295 - accuracy: 0.3264 - precision: 0.8571\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 1.1644 - mse: 0.0971 - accuracy: 0.5697 - precision: 0.7393\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.9996 - mse: 0.0859 - accuracy: 0.6187 - precision: 0.7299\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.8919 - mse: 0.0766 - accuracy: 0.6677 - precision: 0.7828\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.8446 - mse: 0.0729 - accuracy: 0.6766 - precision: 0.7756\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.7837 - mse: 0.0667 - accuracy: 0.7315 - precision: 0.7849\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.7077 - mse: 0.0615 - accuracy: 0.7418 - precision: 0.8040\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.6754 - mse: 0.0592 - accuracy: 0.7270 - precision: 0.8098\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.6180 - mse: 0.0533 - accuracy: 0.7908 - precision: 0.8325\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.5738 - mse: 0.0492 - accuracy: 0.7849 - precision: 0.8540\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.5132 - mse: 0.0444 - accuracy: 0.8175 - precision: 0.8479\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.4824 - mse: 0.0423 - accuracy: 0.8264 - precision: 0.8658\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.4323 - mse: 0.0366 - accuracy: 0.8546 - precision: 0.8882\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.4130 - mse: 0.0352 - accuracy: 0.8501 - precision: 0.8715\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.3913 - mse: 0.0351 - accuracy: 0.8516 - precision: 0.8760\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.3798 - mse: 0.0323 - accuracy: 0.8650 - precision: 0.8939\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.3240 - mse: 0.0279 - accuracy: 0.8843 - precision: 0.9132\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.3252 - mse: 0.0275 - accuracy: 0.8872 - precision: 0.9076\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.2962 - mse: 0.0259 - accuracy: 0.8858 - precision: 0.9084\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.2899 - mse: 0.0243 - accuracy: 0.9036 - precision: 0.9249\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.2548 - mse: 0.0222 - accuracy: 0.9050 - precision: 0.9176\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.2394 - mse: 0.0208 - accuracy: 0.9169 - precision: 0.9417\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.2314 - mse: 0.0203 - accuracy: 0.9184 - precision: 0.9331\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.2080 - mse: 0.0183 - accuracy: 0.9228 - precision: 0.9305\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.1924 - mse: 0.0165 - accuracy: 0.9362 - precision: 0.9484\n",
            "Score for fold 3: loss of 1.3059219121932983; mse of 0.07862702757120132;accuracy of 0.6863905191421509;precision of 0.6904761791229248\n",
            "m322\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 7, 18, 12) (None, 6, 14, 18, 12) (None, 6, 12, 18, 12)\n",
            "(None, 6, 33, 6, 4)\n",
            "(None, 6, 33, 1, 1)\n",
            "(None, 198)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m322 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 1.6725 - mse: 0.1315 - accuracy: 0.3052 - precision: 0.9091\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 1.2837 - mse: 0.1053 - accuracy: 0.5081 - precision: 0.7487\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 1.0832 - mse: 0.0890 - accuracy: 0.6148 - precision: 0.7754\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.9449 - mse: 0.0786 - accuracy: 0.6593 - precision: 0.7865\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.8223 - mse: 0.0678 - accuracy: 0.7304 - precision: 0.8201\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.7544 - mse: 0.0627 - accuracy: 0.7422 - precision: 0.8175\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.6902 - mse: 0.0567 - accuracy: 0.7778 - precision: 0.8472\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.6238 - mse: 0.0521 - accuracy: 0.7896 - precision: 0.8339\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 5s 243ms/step - loss: 0.5755 - mse: 0.0485 - accuracy: 0.8015 - precision: 0.8648\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.5307 - mse: 0.0446 - accuracy: 0.8281 - precision: 0.8739\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.4820 - mse: 0.0401 - accuracy: 0.8533 - precision: 0.8827\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.4314 - mse: 0.0359 - accuracy: 0.8578 - precision: 0.8892\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.4012 - mse: 0.0337 - accuracy: 0.8681 - precision: 0.8873\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.3586 - mse: 0.0301 - accuracy: 0.8741 - precision: 0.8976\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.3362 - mse: 0.0273 - accuracy: 0.8904 - precision: 0.9160\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.2944 - mse: 0.0248 - accuracy: 0.9037 - precision: 0.9221\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 5s 247ms/step - loss: 0.2746 - mse: 0.0227 - accuracy: 0.9022 - precision: 0.9317\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.2584 - mse: 0.0214 - accuracy: 0.9200 - precision: 0.9301\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.2283 - mse: 0.0183 - accuracy: 0.9378 - precision: 0.9571\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.2038 - mse: 0.0174 - accuracy: 0.9319 - precision: 0.9478\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.1985 - mse: 0.0169 - accuracy: 0.9378 - precision: 0.9498\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.1789 - mse: 0.0146 - accuracy: 0.9407 - precision: 0.9516\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.1484 - mse: 0.0119 - accuracy: 0.9556 - precision: 0.9623\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.1586 - mse: 0.0136 - accuracy: 0.9496 - precision: 0.9521\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.1263 - mse: 0.0105 - accuracy: 0.9600 - precision: 0.9655\n",
            "Score for fold 4: loss of 1.2844213247299194; mse of 0.08654192835092545;accuracy of 0.6726190447807312;precision of 0.6851851940155029\n",
            "m322\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 14, 24, 18) (None, 2, 12, 24, 18)\n",
            "(None, 6, 7, 18, 12) (None, 6, 14, 18, 12) (None, 6, 12, 18, 12)\n",
            "(None, 6, 33, 6, 4)\n",
            "(None, 6, 33, 1, 1)\n",
            "(None, 198)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m322 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 1.6358 - mse: 0.1295 - accuracy: 0.3081 - precision: 0.7241\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 1.2385 - mse: 0.1024 - accuracy: 0.5304 - precision: 0.7265\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 1.0287 - mse: 0.0855 - accuracy: 0.6104 - precision: 0.7869\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.9286 - mse: 0.0772 - accuracy: 0.6593 - precision: 0.8087\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.8580 - mse: 0.0719 - accuracy: 0.6889 - precision: 0.8215\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.7538 - mse: 0.0634 - accuracy: 0.7170 - precision: 0.8218\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.7018 - mse: 0.0594 - accuracy: 0.7526 - precision: 0.8150\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.6469 - mse: 0.0549 - accuracy: 0.7763 - precision: 0.8506\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 5s 244ms/step - loss: 0.5979 - mse: 0.0507 - accuracy: 0.7867 - precision: 0.8537\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.5494 - mse: 0.0470 - accuracy: 0.8074 - precision: 0.8488\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.5116 - mse: 0.0441 - accuracy: 0.8222 - precision: 0.8548\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.4803 - mse: 0.0417 - accuracy: 0.8267 - precision: 0.8746\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.4370 - mse: 0.0372 - accuracy: 0.8607 - precision: 0.8832\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.4204 - mse: 0.0369 - accuracy: 0.8430 - precision: 0.8786\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.3818 - mse: 0.0331 - accuracy: 0.8548 - precision: 0.8954\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.3802 - mse: 0.0335 - accuracy: 0.8622 - precision: 0.8918\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.3158 - mse: 0.0271 - accuracy: 0.8919 - precision: 0.9214\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.3617 - mse: 0.0304 - accuracy: 0.8874 - precision: 0.9091\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.2806 - mse: 0.0242 - accuracy: 0.9022 - precision: 0.9306\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.2734 - mse: 0.0241 - accuracy: 0.9067 - precision: 0.9195\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.2667 - mse: 0.0235 - accuracy: 0.8993 - precision: 0.9226\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.2450 - mse: 0.0201 - accuracy: 0.9170 - precision: 0.9340\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.2191 - mse: 0.0188 - accuracy: 0.9244 - precision: 0.9433\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 5s 245ms/step - loss: 0.2444 - mse: 0.0207 - accuracy: 0.9156 - precision: 0.9315\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 5s 246ms/step - loss: 0.1692 - mse: 0.0143 - accuracy: 0.9422 - precision: 0.9559\n",
            "Score for fold 5: loss of 0.9725102782249451; mse of 0.06786171346902847;accuracy of 0.738095223903656;precision of 0.7560975551605225\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 1.4869107007980347 - Accuracy: 0.6331360936164856 - Precision: 0.6474359035491943%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 1.3565988540649414 - Accuracy: 0.692307710647583 - Precision: 0.7090908885002136%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 1.3059219121932983 - Accuracy: 0.6863905191421509 - Precision: 0.6904761791229248%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 1.2844213247299194 - Accuracy: 0.6726190447807312 - Precision: 0.6851851940155029%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 0.9725102782249451 - Accuracy: 0.738095223903656 - Precision: 0.7560975551605225%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 0.6845097184181214 (+- 0.03381239399133013)\n",
            "> Loss: 1.2812726140022277\n",
            "> Precision: 0.6976571440696716\n",
            "------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-576d1743c5c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkfold_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"m322\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mM1_ufc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mM2_ufc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mM3_ufc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mM4_ufc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mM5_ufc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTrain_ufc_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpca_SPM_cube_ufc_reloaded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"swish\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresults_swish\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"m322\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/ML_CSP774/Theory_project/3D-CNN Activity Recognition/Pickle/m322_30epochs_swish.pickle'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_swish\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"m322\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'results_swish' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjYZQmQajh4I"
      },
      "source": [
        "### Model m222"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1jStO5Pes1I",
        "outputId": "f13debdb-f125-45f4-bbf8-3564a29170bf"
      },
      "source": [
        "loss,mse,acc,prec = kfold_validation(\"m222\",M1_ufc,M2_ufc,M3_ufc,M4_ufc,M5_ufc,Train_ufc_y,pca_SPM_cube_ufc_reloaded,32,25,1,None,\"swish\")\n",
        "results_swish[\"m222\"] = np.array((loss,mse,acc,prec))\n",
        "filename = '/content/drive/MyDrive/ML_CSP774/Theory_project/3D-CNN Activity Recognition/Pickle/m222_30epochs_swish.pickle'\n",
        "with open(filename, 'wb') as f:\n",
        "    pickle.dump(results_swish[\"m222\"], f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "m222\n",
            "(None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 8, 72, 54) (None, 2, 8, 72, 54)\n",
            "(None, 2, 9, 24, 18) (None, 2, 18, 24, 18) (None, 2, 16, 24, 18)\n",
            "(None, 6, 9, 18, 12) (None, 6, 18, 18, 12) (None, 6, 16, 18, 12)\n",
            "(None, 6, 43, 6, 4)\n",
            "(None, 6, 43, 1, 1)\n",
            "(None, 258)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m222 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "22/22 [==============================] - 4s 191ms/step - loss: 1.6345 - mse: 0.1291 - accuracy: 0.3501 - precision: 0.9000\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 4s 179ms/step - loss: 1.1567 - mse: 0.0956 - accuracy: 0.5653 - precision: 0.7658\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.9627 - mse: 0.0816 - accuracy: 0.6588 - precision: 0.7624\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 4s 178ms/step - loss: 0.8384 - mse: 0.0718 - accuracy: 0.6869 - precision: 0.7966\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 4s 179ms/step - loss: 0.7719 - mse: 0.0663 - accuracy: 0.7240 - precision: 0.8123\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 4s 178ms/step - loss: 0.7075 - mse: 0.0601 - accuracy: 0.7567 - precision: 0.8299\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.6469 - mse: 0.0556 - accuracy: 0.7700 - precision: 0.8471\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.5980 - mse: 0.0522 - accuracy: 0.7774 - precision: 0.8379\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 4s 181ms/step - loss: 0.5690 - mse: 0.0496 - accuracy: 0.8071 - precision: 0.8476\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 4s 180ms/step - loss: 0.5250 - mse: 0.0462 - accuracy: 0.8042 - precision: 0.8498\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 4s 181ms/step - loss: 0.4812 - mse: 0.0424 - accuracy: 0.8249 - precision: 0.8642\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 4s 178ms/step - loss: 0.4660 - mse: 0.0400 - accuracy: 0.8368 - precision: 0.8799\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 4s 178ms/step - loss: 0.4197 - mse: 0.0366 - accuracy: 0.8516 - precision: 0.8841\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.3907 - mse: 0.0346 - accuracy: 0.8739 - precision: 0.8969\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 4s 179ms/step - loss: 0.3639 - mse: 0.0314 - accuracy: 0.8754 - precision: 0.9069\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 4s 176ms/step - loss: 0.3479 - mse: 0.0310 - accuracy: 0.8694 - precision: 0.8875\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.3165 - mse: 0.0269 - accuracy: 0.8932 - precision: 0.9143\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 4s 178ms/step - loss: 0.2893 - mse: 0.0256 - accuracy: 0.9006 - precision: 0.9211\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 4s 178ms/step - loss: 0.2861 - mse: 0.0246 - accuracy: 0.8976 - precision: 0.9194\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.2644 - mse: 0.0231 - accuracy: 0.9065 - precision: 0.9177\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 4s 175ms/step - loss: 0.2442 - mse: 0.0212 - accuracy: 0.9214 - precision: 0.9367\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 4s 176ms/step - loss: 0.2404 - mse: 0.0211 - accuracy: 0.9110 - precision: 0.9256\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.2171 - mse: 0.0188 - accuracy: 0.9303 - precision: 0.9435\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 4s 176ms/step - loss: 0.1929 - mse: 0.0160 - accuracy: 0.9510 - precision: 0.9556\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 4s 175ms/step - loss: 0.1751 - mse: 0.0148 - accuracy: 0.9407 - precision: 0.9530\n",
            "Score for fold 1: loss of 1.4597742557525635; mse of 0.09561602771282196;accuracy of 0.6213017702102661;precision of 0.6415094137191772\n",
            "m222\n",
            "(None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 8, 72, 54) (None, 2, 8, 72, 54)\n",
            "(None, 2, 9, 24, 18) (None, 2, 18, 24, 18) (None, 2, 16, 24, 18)\n",
            "(None, 6, 9, 18, 12) (None, 6, 18, 18, 12) (None, 6, 16, 18, 12)\n",
            "(None, 6, 43, 6, 4)\n",
            "(None, 6, 43, 1, 1)\n",
            "(None, 258)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m222 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 4s 176ms/step - loss: 1.6392 - mse: 0.1290 - accuracy: 0.3516 - precision: 0.7273\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 1.1678 - mse: 0.0973 - accuracy: 0.5475 - precision: 0.7686\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 4s 176ms/step - loss: 0.9596 - mse: 0.0821 - accuracy: 0.6231 - precision: 0.7464\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 4s 176ms/step - loss: 0.8597 - mse: 0.0750 - accuracy: 0.6662 - precision: 0.7697\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.7509 - mse: 0.0667 - accuracy: 0.6914 - precision: 0.7815\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 4s 178ms/step - loss: 0.6769 - mse: 0.0604 - accuracy: 0.7344 - precision: 0.8125\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.6193 - mse: 0.0541 - accuracy: 0.7745 - precision: 0.8385\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 4s 178ms/step - loss: 0.5617 - mse: 0.0498 - accuracy: 0.7982 - precision: 0.8443\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.5281 - mse: 0.0471 - accuracy: 0.8042 - precision: 0.8429\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 4s 179ms/step - loss: 0.4868 - mse: 0.0438 - accuracy: 0.8071 - precision: 0.8529\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 4s 178ms/step - loss: 0.4313 - mse: 0.0385 - accuracy: 0.8353 - precision: 0.8748\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 4s 176ms/step - loss: 0.4301 - mse: 0.0378 - accuracy: 0.8353 - precision: 0.8732\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.3832 - mse: 0.0331 - accuracy: 0.8694 - precision: 0.8975\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 4s 178ms/step - loss: 0.3824 - mse: 0.0327 - accuracy: 0.8739 - precision: 0.8942\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.3317 - mse: 0.0281 - accuracy: 0.8947 - precision: 0.9105\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 4s 176ms/step - loss: 0.3083 - mse: 0.0254 - accuracy: 0.8976 - precision: 0.9155\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.3081 - mse: 0.0271 - accuracy: 0.8932 - precision: 0.9198\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 4s 176ms/step - loss: 0.2611 - mse: 0.0226 - accuracy: 0.9125 - precision: 0.9223\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.2523 - mse: 0.0223 - accuracy: 0.9169 - precision: 0.9255\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.2340 - mse: 0.0202 - accuracy: 0.9243 - precision: 0.9335\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.2287 - mse: 0.0197 - accuracy: 0.9169 - precision: 0.9386\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.1899 - mse: 0.0160 - accuracy: 0.9347 - precision: 0.9529\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 4s 176ms/step - loss: 0.1783 - mse: 0.0151 - accuracy: 0.9377 - precision: 0.9515\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.1641 - mse: 0.0143 - accuracy: 0.9436 - precision: 0.9502\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 4s 176ms/step - loss: 0.1474 - mse: 0.0119 - accuracy: 0.9510 - precision: 0.9649\n",
            "Score for fold 2: loss of 0.8964771628379822; mse of 0.06718378514051437;accuracy of 0.7455621361732483;precision of 0.7575757503509521\n",
            "m222\n",
            "(None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 8, 72, 54) (None, 2, 8, 72, 54)\n",
            "(None, 2, 9, 24, 18) (None, 2, 18, 24, 18) (None, 2, 16, 24, 18)\n",
            "(None, 6, 9, 18, 12) (None, 6, 18, 18, 12) (None, 6, 16, 18, 12)\n",
            "(None, 6, 43, 6, 4)\n",
            "(None, 6, 43, 1, 1)\n",
            "(None, 258)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m222 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 4s 175ms/step - loss: 1.6324 - mse: 0.1290 - accuracy: 0.3309 - precision: 0.8000\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 4s 178ms/step - loss: 1.2258 - mse: 0.1015 - accuracy: 0.5401 - precision: 0.7232\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 4s 176ms/step - loss: 1.0424 - mse: 0.0878 - accuracy: 0.6098 - precision: 0.7649\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 4s 176ms/step - loss: 0.9519 - mse: 0.0803 - accuracy: 0.6454 - precision: 0.7523\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 4s 178ms/step - loss: 0.8360 - mse: 0.0706 - accuracy: 0.7062 - precision: 0.8238\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.7530 - mse: 0.0632 - accuracy: 0.7300 - precision: 0.8066\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 4s 176ms/step - loss: 0.7115 - mse: 0.0601 - accuracy: 0.7478 - precision: 0.8225\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.6451 - mse: 0.0538 - accuracy: 0.7789 - precision: 0.8574\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.5835 - mse: 0.0496 - accuracy: 0.7864 - precision: 0.8514\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.5800 - mse: 0.0501 - accuracy: 0.7878 - precision: 0.8482\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 4s 178ms/step - loss: 0.5257 - mse: 0.0446 - accuracy: 0.8116 - precision: 0.8722\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.5002 - mse: 0.0425 - accuracy: 0.8309 - precision: 0.8741\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.4492 - mse: 0.0384 - accuracy: 0.8576 - precision: 0.8844\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.4260 - mse: 0.0372 - accuracy: 0.8427 - precision: 0.8830\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 4s 178ms/step - loss: 0.4246 - mse: 0.0363 - accuracy: 0.8546 - precision: 0.8900\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.3744 - mse: 0.0318 - accuracy: 0.8754 - precision: 0.9095\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.3543 - mse: 0.0297 - accuracy: 0.8917 - precision: 0.9128\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.3253 - mse: 0.0274 - accuracy: 0.8991 - precision: 0.9252\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.3079 - mse: 0.0257 - accuracy: 0.9036 - precision: 0.9251\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.3107 - mse: 0.0266 - accuracy: 0.8932 - precision: 0.9101\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.2771 - mse: 0.0242 - accuracy: 0.9021 - precision: 0.9282\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.2496 - mse: 0.0211 - accuracy: 0.9154 - precision: 0.9336\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 4s 178ms/step - loss: 0.2613 - mse: 0.0224 - accuracy: 0.9110 - precision: 0.9253\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.2091 - mse: 0.0178 - accuracy: 0.9392 - precision: 0.9436\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 4s 176ms/step - loss: 0.2213 - mse: 0.0192 - accuracy: 0.9258 - precision: 0.9407\n",
            "Score for fold 3: loss of 1.478886604309082; mse of 0.08892802149057388;accuracy of 0.6863905191421509;precision of 0.6918238997459412\n",
            "m222\n",
            "(None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 8, 72, 54) (None, 2, 8, 72, 54)\n",
            "(None, 2, 9, 24, 18) (None, 2, 18, 24, 18) (None, 2, 16, 24, 18)\n",
            "(None, 6, 9, 18, 12) (None, 6, 18, 18, 12) (None, 6, 16, 18, 12)\n",
            "(None, 6, 43, 6, 4)\n",
            "(None, 6, 43, 1, 1)\n",
            "(None, 258)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m222 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 4s 188ms/step - loss: 1.6012 - mse: 0.1271 - accuracy: 0.3333 - precision: 0.7188\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 4s 178ms/step - loss: 1.1637 - mse: 0.0978 - accuracy: 0.5793 - precision: 0.7434\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 4s 178ms/step - loss: 0.9720 - mse: 0.0833 - accuracy: 0.6341 - precision: 0.7566\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.8567 - mse: 0.0738 - accuracy: 0.6859 - precision: 0.7800\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.7508 - mse: 0.0654 - accuracy: 0.7393 - precision: 0.8173\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 4s 179ms/step - loss: 0.6717 - mse: 0.0589 - accuracy: 0.7541 - precision: 0.8187\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.6033 - mse: 0.0527 - accuracy: 0.7822 - precision: 0.8382\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.5490 - mse: 0.0477 - accuracy: 0.8104 - precision: 0.8554\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 4s 178ms/step - loss: 0.4834 - mse: 0.0426 - accuracy: 0.8252 - precision: 0.8689\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 4s 179ms/step - loss: 0.4528 - mse: 0.0398 - accuracy: 0.8385 - precision: 0.8784\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 4s 179ms/step - loss: 0.3952 - mse: 0.0346 - accuracy: 0.8607 - precision: 0.9003\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.3819 - mse: 0.0343 - accuracy: 0.8519 - precision: 0.8867\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.3391 - mse: 0.0300 - accuracy: 0.8756 - precision: 0.8936\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 4s 178ms/step - loss: 0.3088 - mse: 0.0272 - accuracy: 0.8919 - precision: 0.9132\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.2698 - mse: 0.0232 - accuracy: 0.9170 - precision: 0.9362\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.2638 - mse: 0.0234 - accuracy: 0.9081 - precision: 0.9217\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 4s 178ms/step - loss: 0.2209 - mse: 0.0186 - accuracy: 0.9304 - precision: 0.9458\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.2101 - mse: 0.0183 - accuracy: 0.9274 - precision: 0.9405\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.1908 - mse: 0.0169 - accuracy: 0.9274 - precision: 0.9423\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 4s 178ms/step - loss: 0.1883 - mse: 0.0162 - accuracy: 0.9452 - precision: 0.9543\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 4s 178ms/step - loss: 0.1493 - mse: 0.0119 - accuracy: 0.9644 - precision: 0.9699\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 4s 178ms/step - loss: 0.1359 - mse: 0.0116 - accuracy: 0.9526 - precision: 0.9593\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.1399 - mse: 0.0119 - accuracy: 0.9556 - precision: 0.9609\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.1030 - mse: 0.0080 - accuracy: 0.9763 - precision: 0.9821\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.0945 - mse: 0.0075 - accuracy: 0.9719 - precision: 0.9718\n",
            "Score for fold 4: loss of 2.751896381378174; mse of 0.1342192441225052;accuracy of 0.5357142686843872;precision of 0.5304877758026123\n",
            "m222\n",
            "(None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 9, 72, 54) (None, 2, 8, 72, 54) (None, 2, 8, 72, 54)\n",
            "(None, 2, 9, 24, 18) (None, 2, 18, 24, 18) (None, 2, 16, 24, 18)\n",
            "(None, 6, 9, 18, 12) (None, 6, 18, 18, 12) (None, 6, 16, 18, 12)\n",
            "(None, 6, 43, 6, 4)\n",
            "(None, 6, 43, 1, 1)\n",
            "(None, 258)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "New m222 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 1.6608 - mse: 0.1305 - accuracy: 0.3215 - precision: 0.7368\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 4s 178ms/step - loss: 1.1340 - mse: 0.0939 - accuracy: 0.5793 - precision: 0.8057\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 4s 178ms/step - loss: 0.9254 - mse: 0.0796 - accuracy: 0.6459 - precision: 0.7663\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.8080 - mse: 0.0692 - accuracy: 0.6963 - precision: 0.7798\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.7094 - mse: 0.0611 - accuracy: 0.7393 - precision: 0.8053\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 4s 178ms/step - loss: 0.6322 - mse: 0.0535 - accuracy: 0.7778 - precision: 0.8464\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 4s 178ms/step - loss: 0.5660 - mse: 0.0481 - accuracy: 0.7837 - precision: 0.8652\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.5029 - mse: 0.0427 - accuracy: 0.8370 - precision: 0.8640\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 4s 181ms/step - loss: 0.4357 - mse: 0.0365 - accuracy: 0.8533 - precision: 0.8931\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 4s 178ms/step - loss: 0.4089 - mse: 0.0338 - accuracy: 0.8667 - precision: 0.9005\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 4s 178ms/step - loss: 0.3754 - mse: 0.0311 - accuracy: 0.8815 - precision: 0.9069\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.3416 - mse: 0.0283 - accuracy: 0.8978 - precision: 0.9211\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 4s 176ms/step - loss: 0.3031 - mse: 0.0255 - accuracy: 0.9052 - precision: 0.9280\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 4s 178ms/step - loss: 0.2931 - mse: 0.0247 - accuracy: 0.8978 - precision: 0.9141\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.2453 - mse: 0.0199 - accuracy: 0.9170 - precision: 0.9457\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.2292 - mse: 0.0198 - accuracy: 0.9259 - precision: 0.9344\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.2100 - mse: 0.0176 - accuracy: 0.9333 - precision: 0.9494\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 4s 178ms/step - loss: 0.1902 - mse: 0.0169 - accuracy: 0.9333 - precision: 0.9480\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 4s 176ms/step - loss: 0.1564 - mse: 0.0134 - accuracy: 0.9481 - precision: 0.9560\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 4s 178ms/step - loss: 0.1292 - mse: 0.0105 - accuracy: 0.9674 - precision: 0.9744\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.1379 - mse: 0.0115 - accuracy: 0.9615 - precision: 0.9698\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 4s 178ms/step - loss: 0.1064 - mse: 0.0088 - accuracy: 0.9689 - precision: 0.9761\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.0802 - mse: 0.0056 - accuracy: 0.9867 - precision: 0.9896\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 4s 176ms/step - loss: 0.0900 - mse: 0.0070 - accuracy: 0.9793 - precision: 0.9806\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.0819 - mse: 0.0067 - accuracy: 0.9793 - precision: 0.9792\n",
            "Score for fold 5: loss of 1.7651499509811401; mse of 0.08680965006351471;accuracy of 0.6904761791229248;precision of 0.6927710771560669\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 1.4597742557525635 - Accuracy: 0.6213017702102661 - Precision: 0.6415094137191772%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 0.8964771628379822 - Accuracy: 0.7455621361732483 - Precision: 0.7575757503509521%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 1.478886604309082 - Accuracy: 0.6863905191421509 - Precision: 0.6918238997459412%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 2.751896381378174 - Accuracy: 0.5357142686843872 - Precision: 0.5304877758026123%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 1.7651499509811401 - Accuracy: 0.6904761791229248 - Precision: 0.6927710771560669%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 0.6558889746665955 (+- 0.07184167243614334)\n",
            "> Loss: 1.6704368710517883\n",
            "> Precision: 0.6628335833549499\n",
            "------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsoDhd0-hxbI",
        "outputId": "147025c6-dfa1-4129-d167-2bd28533a990"
      },
      "source": [
        "loss,mse,acc,prec = kfold_validation(\"rs332\",M1_ufc,M2_ufc,M3_ufc,M4_ufc,M5_ufc,Train_ufc_y,pca_SPM_cube_ufc_reloaded,32,25,1,None,\"swish\")\n",
        "results_swish[\"rs332\"] = np.array((loss,mse,acc,prec))\n",
        "filename = '/content/drive/MyDrive/ML_CSP774/Theory_project/3D-CNN Activity Recognition/Pickle/rs332_30epochs_swish.pickle'\n",
        "with open(filename, 'wb') as f:\n",
        "    pickle.dump(results_swish[\"rs332\"], f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rs332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "correct\n",
            "(None, 300)\n",
            "New rs332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 1.7718 - output_rs332_loss: 1.5676 - output_spm_rs332_loss: 40.8470 - output_rs332_mse: 0.1253 - output_rs332_accuracy: 0.3665 - output_rs332_precision_1: 0.7027 - output_spm_rs332_mse: 40.8470 - output_spm_rs332_accuracy: 0.0074\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 1.3883 - output_rs332_loss: 1.1842 - output_spm_rs332_loss: 40.8190 - output_rs332_mse: 0.0998 - output_rs332_accuracy: 0.5223 - output_rs332_precision_1: 0.7137 - output_spm_rs332_mse: 40.8190 - output_spm_rs332_accuracy: 0.1306\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 6s 263ms/step - loss: 1.2029 - output_rs332_loss: 0.9991 - output_spm_rs332_loss: 40.7634 - output_rs332_mse: 0.0852 - output_rs332_accuracy: 0.6142 - output_rs332_precision_1: 0.7338 - output_spm_rs332_mse: 40.7634 - output_spm_rs332_accuracy: 0.2062\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 1.0569 - output_rs332_loss: 0.8534 - output_spm_rs332_loss: 40.6962 - output_rs332_mse: 0.0730 - output_rs332_accuracy: 0.6751 - output_rs332_precision_1: 0.7626 - output_spm_rs332_mse: 40.6962 - output_spm_rs332_accuracy: 0.2240\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 6s 262ms/step - loss: 0.9886 - output_rs332_loss: 0.7856 - output_spm_rs332_loss: 40.6040 - output_rs332_mse: 0.0664 - output_rs332_accuracy: 0.7240 - output_rs332_precision_1: 0.7891 - output_spm_rs332_mse: 40.6040 - output_spm_rs332_accuracy: 0.2181\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 6s 262ms/step - loss: 0.9180 - output_rs332_loss: 0.7151 - output_spm_rs332_loss: 40.5616 - output_rs332_mse: 0.0622 - output_rs332_accuracy: 0.7211 - output_rs332_precision_1: 0.7947 - output_spm_rs332_mse: 40.5616 - output_spm_rs332_accuracy: 0.2285\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 6s 261ms/step - loss: 0.8772 - output_rs332_loss: 0.6749 - output_spm_rs332_loss: 40.4552 - output_rs332_mse: 0.0580 - output_rs332_accuracy: 0.7493 - output_rs332_precision_1: 0.8122 - output_spm_rs332_mse: 40.4552 - output_spm_rs332_accuracy: 0.2270\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 6s 263ms/step - loss: 0.7854 - output_rs332_loss: 0.5835 - output_spm_rs332_loss: 40.3875 - output_rs332_mse: 0.0507 - output_rs332_accuracy: 0.7715 - output_rs332_precision_1: 0.8368 - output_spm_rs332_mse: 40.3875 - output_spm_rs332_accuracy: 0.2255\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.7639 - output_rs332_loss: 0.5627 - output_spm_rs332_loss: 40.2567 - output_rs332_mse: 0.0480 - output_rs332_accuracy: 0.8131 - output_rs332_precision_1: 0.8545 - output_spm_rs332_mse: 40.2567 - output_spm_rs332_accuracy: 0.2404\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 6s 265ms/step - loss: 0.6806 - output_rs332_loss: 0.4796 - output_spm_rs332_loss: 40.1824 - output_rs332_mse: 0.0419 - output_rs332_accuracy: 0.8264 - output_rs332_precision_1: 0.8609 - output_spm_rs332_mse: 40.1824 - output_spm_rs332_accuracy: 0.2404\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 6s 263ms/step - loss: 0.6853 - output_rs332_loss: 0.4852 - output_spm_rs332_loss: 40.0204 - output_rs332_mse: 0.0421 - output_rs332_accuracy: 0.8279 - output_rs332_precision_1: 0.8505 - output_spm_rs332_mse: 40.0204 - output_spm_rs332_accuracy: 0.2493\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 6s 263ms/step - loss: 0.6063 - output_rs332_loss: 0.4068 - output_spm_rs332_loss: 39.8936 - output_rs332_mse: 0.0343 - output_rs332_accuracy: 0.8665 - output_rs332_precision_1: 0.8946 - output_spm_rs332_mse: 39.8936 - output_spm_rs332_accuracy: 0.2478\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 6s 263ms/step - loss: 0.5487 - output_rs332_loss: 0.3500 - output_spm_rs332_loss: 39.7469 - output_rs332_mse: 0.0300 - output_rs332_accuracy: 0.8783 - output_rs332_precision_1: 0.9006 - output_spm_rs332_mse: 39.7469 - output_spm_rs332_accuracy: 0.2507\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.5299 - output_rs332_loss: 0.3320 - output_spm_rs332_loss: 39.5697 - output_rs332_mse: 0.0294 - output_rs332_accuracy: 0.8769 - output_rs332_precision_1: 0.8983 - output_spm_rs332_mse: 39.5697 - output_spm_rs332_accuracy: 0.2463\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.4810 - output_rs332_loss: 0.2839 - output_spm_rs332_loss: 39.4342 - output_rs332_mse: 0.0250 - output_rs332_accuracy: 0.9021 - output_rs332_precision_1: 0.9124 - output_spm_rs332_mse: 39.4342 - output_spm_rs332_accuracy: 0.2567\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 6s 263ms/step - loss: 0.4656 - output_rs332_loss: 0.2696 - output_spm_rs332_loss: 39.2023 - output_rs332_mse: 0.0224 - output_rs332_accuracy: 0.9169 - output_rs332_precision_1: 0.9338 - output_spm_rs332_mse: 39.2023 - output_spm_rs332_accuracy: 0.2671\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.4507 - output_rs332_loss: 0.2558 - output_spm_rs332_loss: 38.9768 - output_rs332_mse: 0.0220 - output_rs332_accuracy: 0.9199 - output_rs332_precision_1: 0.9240 - output_spm_rs332_mse: 38.9768 - output_spm_rs332_accuracy: 0.2656\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 6s 267ms/step - loss: 0.4004 - output_rs332_loss: 0.2062 - output_spm_rs332_loss: 38.8448 - output_rs332_mse: 0.0183 - output_rs332_accuracy: 0.9273 - output_rs332_precision_1: 0.9378 - output_spm_rs332_mse: 38.8448 - output_spm_rs332_accuracy: 0.2641\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.4298 - output_rs332_loss: 0.2364 - output_spm_rs332_loss: 38.6858 - output_rs332_mse: 0.0209 - output_rs332_accuracy: 0.9154 - output_rs332_precision_1: 0.9230 - output_spm_rs332_mse: 38.6858 - output_spm_rs332_accuracy: 0.2656\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 6s 263ms/step - loss: 0.3407 - output_rs332_loss: 0.1482 - output_spm_rs332_loss: 38.4956 - output_rs332_mse: 0.0131 - output_rs332_accuracy: 0.9496 - output_rs332_precision_1: 0.9522 - output_spm_rs332_mse: 38.4956 - output_spm_rs332_accuracy: 0.2641\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.3178 - output_rs332_loss: 0.1269 - output_spm_rs332_loss: 38.1753 - output_rs332_mse: 0.0108 - output_rs332_accuracy: 0.9585 - output_rs332_precision_1: 0.9655 - output_spm_rs332_mse: 38.1753 - output_spm_rs332_accuracy: 0.2671\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 6s 262ms/step - loss: 0.3276 - output_rs332_loss: 0.1379 - output_spm_rs332_loss: 37.9573 - output_rs332_mse: 0.0129 - output_rs332_accuracy: 0.9407 - output_rs332_precision_1: 0.9532 - output_spm_rs332_mse: 37.9573 - output_spm_rs332_accuracy: 0.2582\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 6s 263ms/step - loss: 0.3027 - output_rs332_loss: 0.1131 - output_spm_rs332_loss: 37.9197 - output_rs332_mse: 0.0095 - output_rs332_accuracy: 0.9585 - output_rs332_precision_1: 0.9655 - output_spm_rs332_mse: 37.9197 - output_spm_rs332_accuracy: 0.2700\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.3099 - output_rs332_loss: 0.1211 - output_spm_rs332_loss: 37.7519 - output_rs332_mse: 0.0102 - output_rs332_accuracy: 0.9614 - output_rs332_precision_1: 0.9655 - output_spm_rs332_mse: 37.7519 - output_spm_rs332_accuracy: 0.2864\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 6s 261ms/step - loss: 0.2882 - output_rs332_loss: 0.1002 - output_spm_rs332_loss: 37.6020 - output_rs332_mse: 0.0091 - output_rs332_accuracy: 0.9629 - output_rs332_precision_1: 0.9628 - output_spm_rs332_mse: 37.6020 - output_spm_rs332_accuracy: 0.2834\n",
            "Score for fold 1: loss of 1.7723561525344849; output_rs332_loss of 1.5792253017425537;output_spm_rs332_loss of 38.62618637084961;output_rs332_mse of 0.08123145252466202\n",
            "rs332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "correct\n",
            "(None, 300)\n",
            "New rs332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 6s 263ms/step - loss: 1.7762 - output_rs332_loss: 1.5704 - output_spm_rs332_loss: 41.1615 - output_rs332_mse: 0.1243 - output_rs332_accuracy: 0.3546 - output_rs332_precision: 0.8200 - output_spm_rs332_mse: 41.1615 - output_spm_rs332_accuracy: 0.0074\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 6s 263ms/step - loss: 1.3570 - output_rs332_loss: 1.1513 - output_spm_rs332_loss: 41.1347 - output_rs332_mse: 0.0964 - output_rs332_accuracy: 0.5460 - output_rs332_precision: 0.7547 - output_spm_rs332_mse: 41.1347 - output_spm_rs332_accuracy: 0.1291\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 1.1819 - output_rs332_loss: 0.9765 - output_spm_rs332_loss: 41.0788 - output_rs332_mse: 0.0835 - output_rs332_accuracy: 0.5950 - output_rs332_precision: 0.7526 - output_spm_rs332_mse: 41.0788 - output_spm_rs332_accuracy: 0.2493\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 6s 272ms/step - loss: 1.0061 - output_rs332_loss: 0.8009 - output_spm_rs332_loss: 41.0211 - output_rs332_mse: 0.0680 - output_rs332_accuracy: 0.7033 - output_rs332_precision: 0.8104 - output_spm_rs332_mse: 41.0211 - output_spm_rs332_accuracy: 0.3101\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 6s 263ms/step - loss: 0.8905 - output_rs332_loss: 0.6857 - output_spm_rs332_loss: 40.9609 - output_rs332_mse: 0.0589 - output_rs332_accuracy: 0.7596 - output_rs332_precision: 0.8241 - output_spm_rs332_mse: 40.9609 - output_spm_rs332_accuracy: 0.3398\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 6s 262ms/step - loss: 0.8108 - output_rs332_loss: 0.6065 - output_spm_rs332_loss: 40.8772 - output_rs332_mse: 0.0526 - output_rs332_accuracy: 0.7745 - output_rs332_precision: 0.8299 - output_spm_rs332_mse: 40.8772 - output_spm_rs332_accuracy: 0.3427\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.7569 - output_rs332_loss: 0.5528 - output_spm_rs332_loss: 40.8293 - output_rs332_mse: 0.0477 - output_rs332_accuracy: 0.7923 - output_rs332_precision: 0.8480 - output_spm_rs332_mse: 40.8293 - output_spm_rs332_accuracy: 0.3828\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.6952 - output_rs332_loss: 0.4914 - output_spm_rs332_loss: 40.7593 - output_rs332_mse: 0.0424 - output_rs332_accuracy: 0.8205 - output_rs332_precision: 0.8786 - output_spm_rs332_mse: 40.7593 - output_spm_rs332_accuracy: 0.3680\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.6604 - output_rs332_loss: 0.4572 - output_spm_rs332_loss: 40.6396 - output_rs332_mse: 0.0393 - output_rs332_accuracy: 0.8398 - output_rs332_precision: 0.8738 - output_spm_rs332_mse: 40.6396 - output_spm_rs332_accuracy: 0.3783\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 6s 263ms/step - loss: 0.5923 - output_rs332_loss: 0.3896 - output_spm_rs332_loss: 40.5545 - output_rs332_mse: 0.0343 - output_rs332_accuracy: 0.8635 - output_rs332_precision: 0.8946 - output_spm_rs332_mse: 40.5545 - output_spm_rs332_accuracy: 0.3917\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.5439 - output_rs332_loss: 0.3417 - output_spm_rs332_loss: 40.4377 - output_rs332_mse: 0.0294 - output_rs332_accuracy: 0.8754 - output_rs332_precision: 0.9130 - output_spm_rs332_mse: 40.4377 - output_spm_rs332_accuracy: 0.3858\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 6s 271ms/step - loss: 0.5108 - output_rs332_loss: 0.3089 - output_spm_rs332_loss: 40.3639 - output_rs332_mse: 0.0255 - output_rs332_accuracy: 0.9050 - output_rs332_precision: 0.9212 - output_spm_rs332_mse: 40.3639 - output_spm_rs332_accuracy: 0.3783\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 6s 265ms/step - loss: 0.4734 - output_rs332_loss: 0.2721 - output_spm_rs332_loss: 40.2694 - output_rs332_mse: 0.0227 - output_rs332_accuracy: 0.9125 - output_rs332_precision: 0.9262 - output_spm_rs332_mse: 40.2694 - output_spm_rs332_accuracy: 0.3947\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 6s 265ms/step - loss: 0.4203 - output_rs332_loss: 0.2199 - output_spm_rs332_loss: 40.0807 - output_rs332_mse: 0.0181 - output_rs332_accuracy: 0.9332 - output_rs332_precision: 0.9466 - output_spm_rs332_mse: 40.0807 - output_spm_rs332_accuracy: 0.3828\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 6s 265ms/step - loss: 0.4040 - output_rs332_loss: 0.2047 - output_spm_rs332_loss: 39.8678 - output_rs332_mse: 0.0164 - output_rs332_accuracy: 0.9347 - output_rs332_precision: 0.9470 - output_spm_rs332_mse: 39.8678 - output_spm_rs332_accuracy: 0.3872\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.3717 - output_rs332_loss: 0.1733 - output_spm_rs332_loss: 39.6852 - output_rs332_mse: 0.0149 - output_rs332_accuracy: 0.9436 - output_rs332_precision: 0.9517 - output_spm_rs332_mse: 39.6852 - output_spm_rs332_accuracy: 0.3724\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.3448 - output_rs332_loss: 0.1467 - output_spm_rs332_loss: 39.6226 - output_rs332_mse: 0.0122 - output_rs332_accuracy: 0.9525 - output_rs332_precision: 0.9607 - output_spm_rs332_mse: 39.6226 - output_spm_rs332_accuracy: 0.3843\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 6s 265ms/step - loss: 0.3240 - output_rs332_loss: 0.1266 - output_spm_rs332_loss: 39.4826 - output_rs332_mse: 0.0101 - output_rs332_accuracy: 0.9599 - output_rs332_precision: 0.9684 - output_spm_rs332_mse: 39.4826 - output_spm_rs332_accuracy: 0.3843\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 6s 266ms/step - loss: 0.3234 - output_rs332_loss: 0.1268 - output_spm_rs332_loss: 39.3221 - output_rs332_mse: 0.0108 - output_rs332_accuracy: 0.9629 - output_rs332_precision: 0.9642 - output_spm_rs332_mse: 39.3221 - output_spm_rs332_accuracy: 0.3783\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.2681 - output_rs332_loss: 0.0724 - output_spm_rs332_loss: 39.1320 - output_rs332_mse: 0.0057 - output_rs332_accuracy: 0.9792 - output_rs332_precision: 0.9806 - output_spm_rs332_mse: 39.1320 - output_spm_rs332_accuracy: 0.3813\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 6s 265ms/step - loss: 0.2804 - output_rs332_loss: 0.0857 - output_spm_rs332_loss: 38.9346 - output_rs332_mse: 0.0071 - output_rs332_accuracy: 0.9763 - output_rs332_precision: 0.9806 - output_spm_rs332_mse: 38.9346 - output_spm_rs332_accuracy: 0.3872\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 6s 265ms/step - loss: 0.2636 - output_rs332_loss: 0.0702 - output_spm_rs332_loss: 38.6766 - output_rs332_mse: 0.0057 - output_rs332_accuracy: 0.9792 - output_rs332_precision: 0.9850 - output_spm_rs332_mse: 38.6766 - output_spm_rs332_accuracy: 0.3843\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 6s 265ms/step - loss: 0.2568 - output_rs332_loss: 0.0643 - output_spm_rs332_loss: 38.4987 - output_rs332_mse: 0.0056 - output_rs332_accuracy: 0.9718 - output_rs332_precision: 0.9805 - output_spm_rs332_mse: 38.4987 - output_spm_rs332_accuracy: 0.3872\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.2196 - output_rs332_loss: 0.0279 - output_spm_rs332_loss: 38.3311 - output_rs332_mse: 0.0017 - output_rs332_accuracy: 0.9955 - output_rs332_precision: 0.9955 - output_spm_rs332_mse: 38.3311 - output_spm_rs332_accuracy: 0.3917\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.2656 - output_rs332_loss: 0.0749 - output_spm_rs332_loss: 38.1395 - output_rs332_mse: 0.0065 - output_rs332_accuracy: 0.9733 - output_rs332_precision: 0.9747 - output_spm_rs332_mse: 38.1395 - output_spm_rs332_accuracy: 0.3783\n",
            "Score for fold 2: loss of 1.7261461019515991; output_rs332_loss of 1.5385395288467407;output_spm_rs332_loss of 37.52127456665039;output_rs332_mse of 0.0736745148897171\n",
            "rs332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "correct\n",
            "(None, 300)\n",
            "New rs332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 6s 267ms/step - loss: 1.7618 - output_rs332_loss: 1.5589 - output_spm_rs332_loss: 40.5798 - output_rs332_mse: 0.1245 - output_rs332_accuracy: 0.3576 - output_rs332_precision: 0.7143 - output_spm_rs332_mse: 40.5798 - output_spm_rs332_accuracy: 0.0015\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 6s 265ms/step - loss: 1.3512 - output_rs332_loss: 1.1484 - output_spm_rs332_loss: 40.5695 - output_rs332_mse: 0.0969 - output_rs332_accuracy: 0.5579 - output_rs332_precision: 0.7373 - output_spm_rs332_mse: 40.5695 - output_spm_rs332_accuracy: 0.0326\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 1.1390 - output_rs332_loss: 0.9363 - output_spm_rs332_loss: 40.5432 - output_rs332_mse: 0.0801 - output_rs332_accuracy: 0.6484 - output_rs332_precision: 0.7415 - output_spm_rs332_mse: 40.5432 - output_spm_rs332_accuracy: 0.0846\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 1.0185 - output_rs332_loss: 0.8160 - output_spm_rs332_loss: 40.4961 - output_rs332_mse: 0.0707 - output_rs332_accuracy: 0.6958 - output_rs332_precision: 0.7838 - output_spm_rs332_mse: 40.4961 - output_spm_rs332_accuracy: 0.1662\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 6s 265ms/step - loss: 0.9088 - output_rs332_loss: 0.7069 - output_spm_rs332_loss: 40.3810 - output_rs332_mse: 0.0609 - output_rs332_accuracy: 0.7448 - output_rs332_precision: 0.8120 - output_spm_rs332_mse: 40.3810 - output_spm_rs332_accuracy: 0.2315\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 6s 265ms/step - loss: 0.8189 - output_rs332_loss: 0.6174 - output_spm_rs332_loss: 40.2865 - output_rs332_mse: 0.0527 - output_rs332_accuracy: 0.7700 - output_rs332_precision: 0.8445 - output_spm_rs332_mse: 40.2865 - output_spm_rs332_accuracy: 0.3056\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.7744 - output_rs332_loss: 0.5735 - output_spm_rs332_loss: 40.1702 - output_rs332_mse: 0.0494 - output_rs332_accuracy: 0.7864 - output_rs332_precision: 0.8520 - output_spm_rs332_mse: 40.1702 - output_spm_rs332_accuracy: 0.3591\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.6984 - output_rs332_loss: 0.4983 - output_spm_rs332_loss: 40.0104 - output_rs332_mse: 0.0434 - output_rs332_accuracy: 0.8131 - output_rs332_precision: 0.8612 - output_spm_rs332_mse: 40.0104 - output_spm_rs332_accuracy: 0.3665\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 6s 266ms/step - loss: 0.6233 - output_rs332_loss: 0.4239 - output_spm_rs332_loss: 39.8946 - output_rs332_mse: 0.0362 - output_rs332_accuracy: 0.8472 - output_rs332_precision: 0.8922 - output_spm_rs332_mse: 39.8946 - output_spm_rs332_accuracy: 0.3872\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 6s 265ms/step - loss: 0.5789 - output_rs332_loss: 0.3803 - output_spm_rs332_loss: 39.7237 - output_rs332_mse: 0.0326 - output_rs332_accuracy: 0.8680 - output_rs332_precision: 0.9024 - output_spm_rs332_mse: 39.7237 - output_spm_rs332_accuracy: 0.3902\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 6s 266ms/step - loss: 0.5407 - output_rs332_loss: 0.3431 - output_spm_rs332_loss: 39.5250 - output_rs332_mse: 0.0295 - output_rs332_accuracy: 0.8769 - output_rs332_precision: 0.9108 - output_spm_rs332_mse: 39.5250 - output_spm_rs332_accuracy: 0.3902\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 6s 265ms/step - loss: 0.4765 - output_rs332_loss: 0.2803 - output_spm_rs332_loss: 39.2312 - output_rs332_mse: 0.0240 - output_rs332_accuracy: 0.9110 - output_rs332_precision: 0.9344 - output_spm_rs332_mse: 39.2312 - output_spm_rs332_accuracy: 0.3932\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 6s 263ms/step - loss: 0.4462 - output_rs332_loss: 0.2510 - output_spm_rs332_loss: 39.0445 - output_rs332_mse: 0.0216 - output_rs332_accuracy: 0.9199 - output_rs332_precision: 0.9266 - output_spm_rs332_mse: 39.0445 - output_spm_rs332_accuracy: 0.4139\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 6s 265ms/step - loss: 0.4248 - output_rs332_loss: 0.2307 - output_spm_rs332_loss: 38.8162 - output_rs332_mse: 0.0199 - output_rs332_accuracy: 0.9243 - output_rs332_precision: 0.9376 - output_spm_rs332_mse: 38.8162 - output_spm_rs332_accuracy: 0.3976\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 6s 265ms/step - loss: 0.3638 - output_rs332_loss: 0.1712 - output_spm_rs332_loss: 38.5081 - output_rs332_mse: 0.0141 - output_rs332_accuracy: 0.9481 - output_rs332_precision: 0.9575 - output_spm_rs332_mse: 38.5081 - output_spm_rs332_accuracy: 0.4050\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.3650 - output_rs332_loss: 0.1736 - output_spm_rs332_loss: 38.2654 - output_rs332_mse: 0.0146 - output_rs332_accuracy: 0.9451 - output_rs332_precision: 0.9545 - output_spm_rs332_mse: 38.2654 - output_spm_rs332_accuracy: 0.4036\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 6s 266ms/step - loss: 0.3196 - output_rs332_loss: 0.1294 - output_spm_rs332_loss: 38.0367 - output_rs332_mse: 0.0109 - output_rs332_accuracy: 0.9570 - output_rs332_precision: 0.9726 - output_spm_rs332_mse: 38.0367 - output_spm_rs332_accuracy: 0.3783\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 6s 269ms/step - loss: 0.3081 - output_rs332_loss: 0.1193 - output_spm_rs332_loss: 37.7711 - output_rs332_mse: 0.0104 - output_rs332_accuracy: 0.9585 - output_rs332_precision: 0.9654 - output_spm_rs332_mse: 37.7711 - output_spm_rs332_accuracy: 0.4095\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 6s 267ms/step - loss: 0.2963 - output_rs332_loss: 0.1087 - output_spm_rs332_loss: 37.5175 - output_rs332_mse: 0.0092 - output_rs332_accuracy: 0.9614 - output_rs332_precision: 0.9641 - output_spm_rs332_mse: 37.5175 - output_spm_rs332_accuracy: 0.3976\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 6s 266ms/step - loss: 0.2547 - output_rs332_loss: 0.0679 - output_spm_rs332_loss: 37.3600 - output_rs332_mse: 0.0051 - output_rs332_accuracy: 0.9852 - output_rs332_precision: 0.9864 - output_spm_rs332_mse: 37.3600 - output_spm_rs332_accuracy: 0.4095\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 6s 265ms/step - loss: 0.3176 - output_rs332_loss: 0.1318 - output_spm_rs332_loss: 37.1514 - output_rs332_mse: 0.0111 - output_rs332_accuracy: 0.9570 - output_rs332_precision: 0.9583 - output_spm_rs332_mse: 37.1514 - output_spm_rs332_accuracy: 0.3887\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.2179 - output_rs332_loss: 0.0333 - output_spm_rs332_loss: 36.9176 - output_rs332_mse: 0.0021 - output_rs332_accuracy: 0.9941 - output_rs332_precision: 0.9941 - output_spm_rs332_mse: 36.9176 - output_spm_rs332_accuracy: 0.4065\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 6s 266ms/step - loss: 0.2873 - output_rs332_loss: 0.1030 - output_spm_rs332_loss: 36.8607 - output_rs332_mse: 0.0081 - output_rs332_accuracy: 0.9718 - output_rs332_precision: 0.9731 - output_spm_rs332_mse: 36.8607 - output_spm_rs332_accuracy: 0.4006\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 6s 263ms/step - loss: 0.2105 - output_rs332_loss: 0.0282 - output_spm_rs332_loss: 36.4595 - output_rs332_mse: 0.0020 - output_rs332_accuracy: 0.9941 - output_rs332_precision: 0.9941 - output_spm_rs332_mse: 36.4595 - output_spm_rs332_accuracy: 0.3961\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.2355 - output_rs332_loss: 0.0535 - output_spm_rs332_loss: 36.4074 - output_rs332_mse: 0.0040 - output_rs332_accuracy: 0.9866 - output_rs332_precision: 0.9881 - output_spm_rs332_mse: 36.4074 - output_spm_rs332_accuracy: 0.4125\n",
            "Score for fold 3: loss of 1.870429277420044; output_rs332_loss of 1.6701059341430664;output_spm_rs332_loss of 40.064697265625;output_rs332_mse of 0.07113725692033768\n",
            "rs332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "correct\n",
            "(None, 300)\n",
            "New rs332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 6s 267ms/step - loss: 1.7473 - output_rs332_loss: 1.5443 - output_spm_rs332_loss: 40.6042 - output_rs332_mse: 0.1234 - output_rs332_accuracy: 0.3822 - output_rs332_precision: 0.6709 - output_spm_rs332_mse: 40.6042 - output_spm_rs332_accuracy: 0.0637\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 1.3014 - output_rs332_loss: 1.0987 - output_spm_rs332_loss: 40.5506 - output_rs332_mse: 0.0926 - output_rs332_accuracy: 0.5867 - output_rs332_precision: 0.7289 - output_spm_rs332_mse: 40.5506 - output_spm_rs332_accuracy: 0.2119\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 6s 263ms/step - loss: 1.1069 - output_rs332_loss: 0.9046 - output_spm_rs332_loss: 40.4682 - output_rs332_mse: 0.0766 - output_rs332_accuracy: 0.6607 - output_rs332_precision: 0.7719 - output_spm_rs332_mse: 40.4682 - output_spm_rs332_accuracy: 0.2385\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 6s 266ms/step - loss: 0.9322 - output_rs332_loss: 0.7306 - output_spm_rs332_loss: 40.3268 - output_rs332_mse: 0.0625 - output_rs332_accuracy: 0.7496 - output_rs332_precision: 0.8247 - output_spm_rs332_mse: 40.3268 - output_spm_rs332_accuracy: 0.2578\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 6s 263ms/step - loss: 0.8504 - output_rs332_loss: 0.6495 - output_spm_rs332_loss: 40.1666 - output_rs332_mse: 0.0554 - output_rs332_accuracy: 0.7733 - output_rs332_precision: 0.8160 - output_spm_rs332_mse: 40.1666 - output_spm_rs332_accuracy: 0.3022\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 6s 266ms/step - loss: 0.7527 - output_rs332_loss: 0.5527 - output_spm_rs332_loss: 39.9997 - output_rs332_mse: 0.0474 - output_rs332_accuracy: 0.7985 - output_rs332_precision: 0.8508 - output_spm_rs332_mse: 39.9997 - output_spm_rs332_accuracy: 0.3333\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 6s 266ms/step - loss: 0.7158 - output_rs332_loss: 0.5166 - output_spm_rs332_loss: 39.8467 - output_rs332_mse: 0.0446 - output_rs332_accuracy: 0.8104 - output_rs332_precision: 0.8465 - output_spm_rs332_mse: 39.8467 - output_spm_rs332_accuracy: 0.3467\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 6s 265ms/step - loss: 0.6558 - output_rs332_loss: 0.4574 - output_spm_rs332_loss: 39.6816 - output_rs332_mse: 0.0396 - output_rs332_accuracy: 0.8385 - output_rs332_precision: 0.8732 - output_spm_rs332_mse: 39.6816 - output_spm_rs332_accuracy: 0.3481\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 6s 266ms/step - loss: 0.5895 - output_rs332_loss: 0.3922 - output_spm_rs332_loss: 39.4682 - output_rs332_mse: 0.0339 - output_rs332_accuracy: 0.8681 - output_rs332_precision: 0.8968 - output_spm_rs332_mse: 39.4682 - output_spm_rs332_accuracy: 0.3837\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.5348 - output_rs332_loss: 0.3386 - output_spm_rs332_loss: 39.2469 - output_rs332_mse: 0.0285 - output_rs332_accuracy: 0.8859 - output_rs332_precision: 0.9147 - output_spm_rs332_mse: 39.2469 - output_spm_rs332_accuracy: 0.3674\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.5002 - output_rs332_loss: 0.3050 - output_spm_rs332_loss: 39.0380 - output_rs332_mse: 0.0265 - output_rs332_accuracy: 0.9022 - output_rs332_precision: 0.9207 - output_spm_rs332_mse: 39.0380 - output_spm_rs332_accuracy: 0.3644\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.4468 - output_rs332_loss: 0.2526 - output_spm_rs332_loss: 38.8445 - output_rs332_mse: 0.0211 - output_rs332_accuracy: 0.9200 - output_rs332_precision: 0.9339 - output_spm_rs332_mse: 38.8445 - output_spm_rs332_accuracy: 0.3793\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 6s 263ms/step - loss: 0.4265 - output_rs332_loss: 0.2333 - output_spm_rs332_loss: 38.6331 - output_rs332_mse: 0.0206 - output_rs332_accuracy: 0.9215 - output_rs332_precision: 0.9290 - output_spm_rs332_mse: 38.6331 - output_spm_rs332_accuracy: 0.3956\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.3844 - output_rs332_loss: 0.1920 - output_spm_rs332_loss: 38.4706 - output_rs332_mse: 0.0168 - output_rs332_accuracy: 0.9348 - output_rs332_precision: 0.9437 - output_spm_rs332_mse: 38.4706 - output_spm_rs332_accuracy: 0.4015\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 6s 276ms/step - loss: 0.3687 - output_rs332_loss: 0.1775 - output_spm_rs332_loss: 38.2360 - output_rs332_mse: 0.0145 - output_rs332_accuracy: 0.9407 - output_rs332_precision: 0.9546 - output_spm_rs332_mse: 38.2360 - output_spm_rs332_accuracy: 0.3941\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 6s 265ms/step - loss: 0.3264 - output_rs332_loss: 0.1366 - output_spm_rs332_loss: 37.9614 - output_rs332_mse: 0.0109 - output_rs332_accuracy: 0.9585 - output_rs332_precision: 0.9668 - output_spm_rs332_mse: 37.9614 - output_spm_rs332_accuracy: 0.3881\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.3045 - output_rs332_loss: 0.1157 - output_spm_rs332_loss: 37.7702 - output_rs332_mse: 0.0090 - output_rs332_accuracy: 0.9674 - output_rs332_precision: 0.9716 - output_spm_rs332_mse: 37.7702 - output_spm_rs332_accuracy: 0.3852\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 6s 263ms/step - loss: 0.3187 - output_rs332_loss: 0.1313 - output_spm_rs332_loss: 37.4786 - output_rs332_mse: 0.0119 - output_rs332_accuracy: 0.9511 - output_rs332_precision: 0.9521 - output_spm_rs332_mse: 37.4786 - output_spm_rs332_accuracy: 0.4044\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.2557 - output_rs332_loss: 0.0690 - output_spm_rs332_loss: 37.3252 - output_rs332_mse: 0.0053 - output_rs332_accuracy: 0.9837 - output_rs332_precision: 0.9866 - output_spm_rs332_mse: 37.3252 - output_spm_rs332_accuracy: 0.3956\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 6s 265ms/step - loss: 0.2967 - output_rs332_loss: 0.1109 - output_spm_rs332_loss: 37.1588 - output_rs332_mse: 0.0095 - output_rs332_accuracy: 0.9630 - output_rs332_precision: 0.9672 - output_spm_rs332_mse: 37.1588 - output_spm_rs332_accuracy: 0.3985\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.2386 - output_rs332_loss: 0.0531 - output_spm_rs332_loss: 37.0843 - output_rs332_mse: 0.0041 - output_rs332_accuracy: 0.9881 - output_rs332_precision: 0.9896 - output_spm_rs332_mse: 37.0843 - output_spm_rs332_accuracy: 0.3837\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 6s 265ms/step - loss: 0.2596 - output_rs332_loss: 0.0748 - output_spm_rs332_loss: 36.9702 - output_rs332_mse: 0.0059 - output_rs332_accuracy: 0.9763 - output_rs332_precision: 0.9762 - output_spm_rs332_mse: 36.9702 - output_spm_rs332_accuracy: 0.3985\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.2115 - output_rs332_loss: 0.0271 - output_spm_rs332_loss: 36.8742 - output_rs332_mse: 0.0018 - output_rs332_accuracy: 0.9956 - output_rs332_precision: 0.9956 - output_spm_rs332_mse: 36.8742 - output_spm_rs332_accuracy: 0.4030\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 6s 268ms/step - loss: 0.2589 - output_rs332_loss: 0.0755 - output_spm_rs332_loss: 36.6791 - output_rs332_mse: 0.0054 - output_rs332_accuracy: 0.9793 - output_rs332_precision: 0.9792 - output_spm_rs332_mse: 36.6791 - output_spm_rs332_accuracy: 0.4074\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 6s 263ms/step - loss: 0.2061 - output_rs332_loss: 0.0243 - output_spm_rs332_loss: 36.3686 - output_rs332_mse: 0.0016 - output_rs332_accuracy: 0.9941 - output_rs332_precision: 0.9941 - output_spm_rs332_mse: 36.3686 - output_spm_rs332_accuracy: 0.4089\n",
            "Score for fold 4: loss of 1.9768645763397217; output_rs332_loss of 1.780394434928894;output_spm_rs332_loss of 39.29401397705078;output_rs332_mse of 0.07080598920583725\n",
            "rs332\n",
            "(None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 7, 72, 54) (None, 2, 6, 72, 54) (None, 2, 6, 72, 54)\n",
            "(None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 7, 24, 18) (None, 2, 6, 24, 18) (None, 2, 6, 24, 18)\n",
            "(None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 5, 18, 12) (None, 6, 4, 18, 12) (None, 6, 4, 18, 12)\n",
            "(None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 5, 6, 4) (None, 6, 4, 6, 4) (None, 6, 4, 6, 4)\n",
            "(None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 5, 1, 1) (None, 6, 4, 1, 1) (None, 6, 4, 1, 1)\n",
            "(None, 6, 23, 1, 1)\n",
            "(None, 138)\n",
            "(None, 128)\n",
            "(None, 6)\n",
            "correct\n",
            "(None, 300)\n",
            "New rs332 model initialised\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 6s 265ms/step - loss: 1.6288 - output_rs332_loss: 1.4208 - output_spm_rs332_loss: 41.5997 - output_rs332_mse: 0.1155 - output_rs332_accuracy: 0.4444 - output_rs332_precision: 0.6846 - output_spm_rs332_mse: 41.5997 - output_spm_rs332_accuracy: 0.1141\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 1.2554 - output_rs332_loss: 1.0479 - output_spm_rs332_loss: 41.4998 - output_rs332_mse: 0.0892 - output_rs332_accuracy: 0.5926 - output_rs332_precision: 0.7268 - output_spm_rs332_mse: 41.4998 - output_spm_rs332_accuracy: 0.3111\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 6s 266ms/step - loss: 1.1443 - output_rs332_loss: 0.9372 - output_spm_rs332_loss: 41.4108 - output_rs332_mse: 0.0808 - output_rs332_accuracy: 0.6326 - output_rs332_precision: 0.7345 - output_spm_rs332_mse: 41.4108 - output_spm_rs332_accuracy: 0.3230\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 6s 265ms/step - loss: 1.0479 - output_rs332_loss: 0.8411 - output_spm_rs332_loss: 41.3423 - output_rs332_mse: 0.0728 - output_rs332_accuracy: 0.6919 - output_rs332_precision: 0.7822 - output_spm_rs332_mse: 41.3423 - output_spm_rs332_accuracy: 0.3319\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.9437 - output_rs332_loss: 0.7374 - output_spm_rs332_loss: 41.2625 - output_rs332_mse: 0.0641 - output_rs332_accuracy: 0.7141 - output_rs332_precision: 0.7965 - output_spm_rs332_mse: 41.2625 - output_spm_rs332_accuracy: 0.3274\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 6s 265ms/step - loss: 0.8775 - output_rs332_loss: 0.6717 - output_spm_rs332_loss: 41.1498 - output_rs332_mse: 0.0576 - output_rs332_accuracy: 0.7615 - output_rs332_precision: 0.8419 - output_spm_rs332_mse: 41.1498 - output_spm_rs332_accuracy: 0.3393\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.7995 - output_rs332_loss: 0.5943 - output_spm_rs332_loss: 41.0408 - output_rs332_mse: 0.0513 - output_rs332_accuracy: 0.7941 - output_rs332_precision: 0.8451 - output_spm_rs332_mse: 41.0408 - output_spm_rs332_accuracy: 0.3393\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 6s 265ms/step - loss: 0.7212 - output_rs332_loss: 0.5167 - output_spm_rs332_loss: 40.8965 - output_rs332_mse: 0.0447 - output_rs332_accuracy: 0.8089 - output_rs332_precision: 0.8591 - output_spm_rs332_mse: 40.8965 - output_spm_rs332_accuracy: 0.3585\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.6785 - output_rs332_loss: 0.4749 - output_spm_rs332_loss: 40.7257 - output_rs332_mse: 0.0407 - output_rs332_accuracy: 0.8311 - output_rs332_precision: 0.8758 - output_spm_rs332_mse: 40.7257 - output_spm_rs332_accuracy: 0.3793\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.6462 - output_rs332_loss: 0.4433 - output_spm_rs332_loss: 40.5792 - output_rs332_mse: 0.0365 - output_rs332_accuracy: 0.8548 - output_rs332_precision: 0.8958 - output_spm_rs332_mse: 40.5792 - output_spm_rs332_accuracy: 0.3837\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.5647 - output_rs332_loss: 0.3624 - output_spm_rs332_loss: 40.4452 - output_rs332_mse: 0.0300 - output_rs332_accuracy: 0.8652 - output_rs332_precision: 0.9100 - output_spm_rs332_mse: 40.4452 - output_spm_rs332_accuracy: 0.3985\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 6s 265ms/step - loss: 0.5090 - output_rs332_loss: 0.3079 - output_spm_rs332_loss: 40.2253 - output_rs332_mse: 0.0261 - output_rs332_accuracy: 0.8993 - output_rs332_precision: 0.9245 - output_spm_rs332_mse: 40.2253 - output_spm_rs332_accuracy: 0.4030\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 6s 267ms/step - loss: 0.4876 - output_rs332_loss: 0.2876 - output_spm_rs332_loss: 40.0033 - output_rs332_mse: 0.0247 - output_rs332_accuracy: 0.8993 - output_rs332_precision: 0.9195 - output_spm_rs332_mse: 40.0033 - output_spm_rs332_accuracy: 0.4074\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.4454 - output_rs332_loss: 0.2461 - output_spm_rs332_loss: 39.8551 - output_rs332_mse: 0.0198 - output_rs332_accuracy: 0.9348 - output_rs332_precision: 0.9565 - output_spm_rs332_mse: 39.8551 - output_spm_rs332_accuracy: 0.3941\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 6s 266ms/step - loss: 0.3971 - output_rs332_loss: 0.1993 - output_spm_rs332_loss: 39.5624 - output_rs332_mse: 0.0162 - output_rs332_accuracy: 0.9378 - output_rs332_precision: 0.9472 - output_spm_rs332_mse: 39.5624 - output_spm_rs332_accuracy: 0.4193\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 6s 266ms/step - loss: 0.3999 - output_rs332_loss: 0.2026 - output_spm_rs332_loss: 39.4688 - output_rs332_mse: 0.0175 - output_rs332_accuracy: 0.9259 - output_rs332_precision: 0.9418 - output_spm_rs332_mse: 39.4688 - output_spm_rs332_accuracy: 0.4133\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 6s 267ms/step - loss: 0.3584 - output_rs332_loss: 0.1629 - output_spm_rs332_loss: 39.0937 - output_rs332_mse: 0.0133 - output_rs332_accuracy: 0.9467 - output_rs332_precision: 0.9550 - output_spm_rs332_mse: 39.0937 - output_spm_rs332_accuracy: 0.4119\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 6s 268ms/step - loss: 0.3324 - output_rs332_loss: 0.1380 - output_spm_rs332_loss: 38.8845 - output_rs332_mse: 0.0109 - output_rs332_accuracy: 0.9600 - output_rs332_precision: 0.9654 - output_spm_rs332_mse: 38.8845 - output_spm_rs332_accuracy: 0.4133\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 6s 268ms/step - loss: 0.3180 - output_rs332_loss: 0.1251 - output_spm_rs332_loss: 38.5754 - output_rs332_mse: 0.0102 - output_rs332_accuracy: 0.9615 - output_rs332_precision: 0.9670 - output_spm_rs332_mse: 38.5754 - output_spm_rs332_accuracy: 0.4193\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 6s 265ms/step - loss: 0.2942 - output_rs332_loss: 0.1016 - output_spm_rs332_loss: 38.5137 - output_rs332_mse: 0.0080 - output_rs332_accuracy: 0.9704 - output_rs332_precision: 0.9747 - output_spm_rs332_mse: 38.5137 - output_spm_rs332_accuracy: 0.4193\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 6s 268ms/step - loss: 0.2794 - output_rs332_loss: 0.0883 - output_spm_rs332_loss: 38.2217 - output_rs332_mse: 0.0075 - output_rs332_accuracy: 0.9748 - output_rs332_precision: 0.9776 - output_spm_rs332_mse: 38.2217 - output_spm_rs332_accuracy: 0.4163\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 6s 265ms/step - loss: 0.2751 - output_rs332_loss: 0.0851 - output_spm_rs332_loss: 37.9988 - output_rs332_mse: 0.0064 - output_rs332_accuracy: 0.9793 - output_rs332_precision: 0.9793 - output_spm_rs332_mse: 37.9988 - output_spm_rs332_accuracy: 0.4148\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 6s 265ms/step - loss: 0.2376 - output_rs332_loss: 0.0491 - output_spm_rs332_loss: 37.6871 - output_rs332_mse: 0.0037 - output_rs332_accuracy: 0.9867 - output_rs332_precision: 0.9881 - output_spm_rs332_mse: 37.6871 - output_spm_rs332_accuracy: 0.4222\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.2266 - output_rs332_loss: 0.0386 - output_spm_rs332_loss: 37.6162 - output_rs332_mse: 0.0028 - output_rs332_accuracy: 0.9911 - output_rs332_precision: 0.9911 - output_spm_rs332_mse: 37.6162 - output_spm_rs332_accuracy: 0.4326\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 6s 266ms/step - loss: 0.2175 - output_rs332_loss: 0.0310 - output_spm_rs332_loss: 37.3011 - output_rs332_mse: 0.0022 - output_rs332_accuracy: 0.9911 - output_rs332_precision: 0.9926 - output_spm_rs332_mse: 37.3011 - output_spm_rs332_accuracy: 0.4311\n",
            "Score for fold 5: loss of 2.149137020111084; output_rs332_loss of 1.9757888317108154;output_spm_rs332_loss of 34.66962432861328;output_rs332_mse of 0.07716471701860428\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 1.5792253017425537 - Accuracy: 0.7100591659545898 - Precision: 0.7065868377685547%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 1.5385395288467407 - Accuracy: 0.7278106212615967 - Precision: 0.7305389046669006%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 1.6701059341430664 - Accuracy: 0.7396449446678162 - Precision: 0.7530120611190796%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 1.780394434928894 - Accuracy: 0.7559523582458496 - Precision: 0.7650602459907532%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 1.9757888317108154 - Accuracy: 0.75 - Precision: 0.7530120611190796%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 0.7366934180259704 (+- 0.016401041878496524)\n",
            "> Loss: 1.708810806274414\n",
            "> Precision: 0.7416420221328736\n",
            "------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgV7OTNH9esr"
      },
      "source": [
        "# Completed"
      ]
    }
  ]
}